{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model for CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsmanral/Author-Prediction-Using-Deep-Learning-Models/blob/master/Model_for_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf551sNgP6-_",
        "colab_type": "code",
        "outputId": "e9528730-8e12-4e7c-a520-8fcefe36253b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Conv1D\n",
        "from keras.layers import Flatten, GlobalAveragePooling1D\n",
        "from keras.layers import Embedding, TimeDistributed, MaxPooling1D\n",
        "import keras.utils\n",
        "from keras.callbacks import ModelCheckpoint  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTzWEGw7P6_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## extra imports to set GPU options\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        " \n",
        "###################################\n",
        "# TensorFlow wizardry\n",
        "config = tf.ConfigProto()\n",
        " \n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config.gpu_options.allow_growth = True\n",
        " \n",
        "# Only allow a total of half the GPU memory to be allocated\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
        " \n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
        "###################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8_BYAoNRnSG",
        "colab_type": "code",
        "outputId": "0ee3734a-f3f1-498c-96f4-febbb6d6a1d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\"\"\"\n",
        "DON'T MODIFY ANYTHING IN THIS CELL\n",
        "\"\"\"\n",
        "from distutils.version import LooseVersion\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check TensorFlow Version\n",
        "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
        "print('TensorFlow Version: {}'.format(tf.__version__))\n",
        "\n",
        "# Check for a GPU\n",
        "if not tf.test.gpu_device_name():\n",
        "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
        "else:\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 1.6.0\n",
            "Default GPU Device: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiPMI72GQR6A",
        "colab_type": "code",
        "outputId": "34437738-9142-4967-e4f8-3314c1dd540c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3349
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('~/data_clean')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1W_ncgu50M_LR65A4jVvCuFklmosjIfpz' in parents\"}).GetList()\n",
        "\n",
        "data = []\n",
        "for f in file_list:\n",
        "  # 3. Create & download by id.\n",
        "  print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  print('downloading to {}'.format(fname))\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)\n",
        "  with open(fname, 'r', encoding = \"ISO-8859-1\") as file:\n",
        "    data.append([f['title'].split('-')[0], file.read()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: Humphrey Ward - 14.txt, id: 1KQ8TIQFtWWWJhsp6QIpn5RGhYO7NQ3wk\n",
            "downloading to /content/data_clean/Humphrey Ward - 14.txt\n",
            "title: Humphrey Ward - 16.txt, id: 1Xx6zE79WHWVFowU477l1YPGYMnEd4uCn\n",
            "downloading to /content/data_clean/Humphrey Ward - 16.txt\n",
            "title: Humphrey Ward - 19.txt, id: 1T9QE_hSZUx17oa7QGekYM23SIgLSfsE4\n",
            "downloading to /content/data_clean/Humphrey Ward - 19.txt\n",
            "title: Humphrey Ward - 17.txt, id: 1xx-umzzZFNncv9X8OWWj4auY60ShAE-8\n",
            "downloading to /content/data_clean/Humphrey Ward - 17.txt\n",
            "title: Humphrey Ward - 15.txt, id: 1CsLYGbi6pirecPBPNwli90Sb-XSM8q33\n",
            "downloading to /content/data_clean/Humphrey Ward - 15.txt\n",
            "title: Humphrey Ward - 18.txt, id: 1EULi5tNbF07SbrhycdDj_u58MVe8te2N\n",
            "downloading to /content/data_clean/Humphrey Ward - 18.txt\n",
            "title: Humphrey Ward - 13.txt, id: 15za4_hyAnLyw9xALmmp3R54m-ZfGtnjv\n",
            "downloading to /content/data_clean/Humphrey Ward - 13.txt\n",
            "title: Humphrey Ward - 9.txt, id: 1ZwNeiFvLOHUXsAJHUvC2PIJupsxT89Ne\n",
            "downloading to /content/data_clean/Humphrey Ward - 9.txt\n",
            "title: Humphrey Ward - 11.txt, id: 1A0I1VqoMZTQmD1i9J2B_iQ5ARaBCphB4\n",
            "downloading to /content/data_clean/Humphrey Ward - 11.txt\n",
            "title: Humphrey Ward - 10.txt, id: 1HzmiudAiqrLqLaVjmuK3WqO7HX-0oZQ1\n",
            "downloading to /content/data_clean/Humphrey Ward - 10.txt\n",
            "title: Humphrey Ward - 12.txt, id: 1ouAgIQh-OBJkBRoig3uZEd2sdmxqCO9o\n",
            "downloading to /content/data_clean/Humphrey Ward - 12.txt\n",
            "title: Humphrey Ward - 6.txt, id: 1wPKz83q7C4A8K2AxfdsnUfuq60EM5Tj5\n",
            "downloading to /content/data_clean/Humphrey Ward - 6.txt\n",
            "title: Humphrey Ward - 5.txt, id: 1Brl1tJ74VlqMAaCjNcMseq1sECNHzgdc\n",
            "downloading to /content/data_clean/Humphrey Ward - 5.txt\n",
            "title: Humphrey Ward - 8.txt, id: 1BD-iCAjxymPFEz47fmeuMIao9geQcbv1\n",
            "downloading to /content/data_clean/Humphrey Ward - 8.txt\n",
            "title: Humphrey Ward - 7.txt, id: 1muFCBLPJplzxXNLcBSOAcPIp9a_-Kgay\n",
            "downloading to /content/data_clean/Humphrey Ward - 7.txt\n",
            "title: Humphrey Ward - 2.txt, id: 1oCkTEh2zHv0yS8hnb-5nMBExM4zfRgX6\n",
            "downloading to /content/data_clean/Humphrey Ward - 2.txt\n",
            "title: Henry Rider Haggard - 21.txt, id: 1L-O6-Q1TywHEukBEc28hROVcVY5F0hqV\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 21.txt\n",
            "title: Henry Rider Haggard - 17.txt, id: 1Vjw6yEjBSaSGECCU1It2Ym9RZYA6WnVy\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 17.txt\n",
            "title: Henry Rider Haggard - 25.txt, id: 1lwZ0h18H8cwnJ3dHx9zBeHaLkS4xDgKz\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 25.txt\n",
            "title: Henry Rider Haggard - 20.txt, id: 1-qfUAK7GzY_vrMzRrizb9P6dfuO-GQsP\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 20.txt\n",
            "title: Henry Rider Haggard - 18.txt, id: 1_2t1uXV3UPZMgkpHmYS_G2_B0TkNJJEh\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 18.txt\n",
            "title: Henry Rider Haggard - 23.txt, id: 1xFNFH3iay3NlpUy69f3pHK73POsKaGi3\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 23.txt\n",
            "title: Henry Rider Haggard - 22.txt, id: 1e7bGSVPFRhOVh172FN1AkSDstV4U0J8U\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 22.txt\n",
            "title: Henry Rider Haggard - 24.txt, id: 152eBKnhP6-9HFuPLDfpVnK-TTN-CRSln\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 24.txt\n",
            "title: Henry Rider Haggard - 19.txt, id: 1UeoqO6QsMKPUFakL9fJ-ZIC_d5jg7DLf\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 19.txt\n",
            "title: Humphrey Ward - 1.txt, id: 1nH8uYiaeQKlUudMvhkxWldhzUN6if5lZ\n",
            "downloading to /content/data_clean/Humphrey Ward - 1.txt\n",
            "title: Henry Rider Haggard - 14.txt, id: 1BsWOEQreFMnBY-kzbhYsg3ogf8DRvua6\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 14.txt\n",
            "title: Henry Rider Haggard - 9.txt, id: 19TiaWpvLyWA--sSgVHzrkPzSHH7-vbLm\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 9.txt\n",
            "title: Henry Rider Haggard - 8.txt, id: 1QtM3jbr1PDawsgIpZZRyDJW8mGPU6_oV\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 8.txt\n",
            "title: Henry Rider Haggard - 15.txt, id: 1Zpe96YaYs5x0BQBVKSOjdLRvJ8_Xmte1\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 15.txt\n",
            "title: Henry Rider Haggard - 12.txt, id: 18KKKhnwmUlzBVdJtWSVGD0baAkKQvanb\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 12.txt\n",
            "title: Henry Rider Haggard - 7.txt, id: 1SKXDWCyZ8SiVZmNo-6S1FHOqANnpjSbm\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 7.txt\n",
            "title: Henry Rider Haggard - 16.txt, id: 1-P7XJDOVF1bBFaVik1otdsfwtN0cao5L\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 16.txt\n",
            "title: Henry Rider Haggard - 10.txt, id: 13R7Ta5tNwCQRoZMmScEfd_gMQ-EP7E1w\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 10.txt\n",
            "title: Henry Rider Haggard - 11.txt, id: 1ZViWuYsDXue1a1jg0jQ5vCXzuYPFjlHW\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 11.txt\n",
            "title: Henry Rider Haggard - 13.txt, id: 11jY6MowIlcceSBZ-EE-hJMJNV-_2SN-Q\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 13.txt\n",
            "title: Gilbert Parker - 13.txt, id: 1QlyOQla-s2CoG080MJO7_n-KqNFDptoe\n",
            "downloading to /content/data_clean/Gilbert Parker - 13.txt\n",
            "title: Henry Rider Haggard - 5.txt, id: 13He6ly3Y4pyig8UGIf6IQbn5KSIbohsH\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 5.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "title: Henry Rider Haggard - 2.txt, id: 182DLelFZVUwgVCXgMYqyljcdeVekKLyg\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 2.txt\n",
            "title: Henry Rider Haggard - 4.txt, id: 1RW0VikO9suP-fdX6U9WlmPnC47Pw_gTV\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 4.txt\n",
            "title: Gilbert Parker - 14.txt, id: 1PtwJLsc_phb72-juruLNQWBWJgzbY2gk\n",
            "downloading to /content/data_clean/Gilbert Parker - 14.txt\n",
            "title: Henry Rider Haggard - 6.txt, id: 103UEqkdS8kQsRH9WWQqY2I3jM0pwHRj1\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 6.txt\n",
            "title: Henry Rider Haggard - 1.txt, id: 1kxRrRkIluKMT-OZLdo6vqoWiUcGX23qN\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 1.txt\n",
            "title: Gilbert Parker - 16.txt, id: 17na4xSvHKXD5OmCeJYiHVyf3YWnONGNs\n",
            "downloading to /content/data_clean/Gilbert Parker - 16.txt\n",
            "title: Henry Rider Haggard - 3.txt, id: 10P8MfJtE9KcHf9DwutglKBuSFVbi3GTx\n",
            "downloading to /content/data_clean/Henry Rider Haggard - 3.txt\n",
            "title: Gilbert Parker - 15.txt, id: 1RsBp3uXa_WruUJeYPAP0svEuCIBg5kwi\n",
            "downloading to /content/data_clean/Gilbert Parker - 15.txt\n",
            "title: Gilbert Parker - 11.txt, id: 1i4fchySMiERQY6ptNNw8TU1_8ceqTKwC\n",
            "downloading to /content/data_clean/Gilbert Parker - 11.txt\n",
            "title: Gilbert Parker - 8.txt, id: 1GKxe6ZSJVgyCrYS_8hIbFad-LW_TuOKn\n",
            "downloading to /content/data_clean/Gilbert Parker - 8.txt\n",
            "title: Gilbert Parker - 10.txt, id: 12lFEmqTn36_p-pBdgyH_gu4p4nL_Z4-5\n",
            "downloading to /content/data_clean/Gilbert Parker - 10.txt\n",
            "title: Gilbert Parker - 6.txt, id: 1ob-M3KnGiWzzXEo9l9c3tdV_vAMagZ4H\n",
            "downloading to /content/data_clean/Gilbert Parker - 6.txt\n",
            "title: Gilbert Parker - 12.txt, id: 1_BapBE9mljdDc5nqoyzKLjSLx8N_2jo7\n",
            "downloading to /content/data_clean/Gilbert Parker - 12.txt\n",
            "title: Gilbert Parker - 7.txt, id: 1jBQtz4fHy1cUutetlIwm72WUmLoqmyS0\n",
            "downloading to /content/data_clean/Gilbert Parker - 7.txt\n",
            "title: Gilbert Parker - 3.txt, id: 1ONT6lTjx-UgyCfz8NVax1lg5oHyAEyVS\n",
            "downloading to /content/data_clean/Gilbert Parker - 3.txt\n",
            "title: Gilbert Parker - 5.txt, id: 1eFE8vr5aUrvTnMieYkjH2SQn8v_soyUp\n",
            "downloading to /content/data_clean/Gilbert Parker - 5.txt\n",
            "title: Gilbert Parker - 4.txt, id: 1uRipDKiYhWTMRQ-asVIsR4dHJGekXi4f\n",
            "downloading to /content/data_clean/Gilbert Parker - 4.txt\n",
            "title: Gilbert Parker - 9.txt, id: 1nQ0mzZhWYXy1NMRZQglJThHN5KcU31P3\n",
            "downloading to /content/data_clean/Gilbert Parker - 9.txt\n",
            "title: George Gissing - 13.txt, id: 12p8h3dh4mXQm17GH07ChmgMw911HC1wN\n",
            "downloading to /content/data_clean/George Gissing - 13.txt\n",
            "title: George Gissing - 20.txt, id: 1IB5poZZh2b3hmp2xhrtlTWpfIBYXnN_c\n",
            "downloading to /content/data_clean/George Gissing - 20.txt\n",
            "title: George Gissing - 17.txt, id: 1hMF0td1t39E_AjSldaO-s67fh3rwAUdM\n",
            "downloading to /content/data_clean/George Gissing - 17.txt\n",
            "title: George Gissing - 15.txt, id: 1DE2fFFfy8uMHm67Glvh3tKtAZgQZCvAR\n",
            "downloading to /content/data_clean/George Gissing - 15.txt\n",
            "title: Gilbert Parker - 1.txt, id: 1cJ_2qRYVOqxIG5Thgkw333U2m5C8f9DO\n",
            "downloading to /content/data_clean/Gilbert Parker - 1.txt\n",
            "title: George Gissing - 19.txt, id: 1Fj8qRS1K2JINSp_o9_Li7cHlDavFIJng\n",
            "downloading to /content/data_clean/George Gissing - 19.txt\n",
            "title: George Gissing - 14.txt, id: 1c4tj1Sp37efyyla4M4Pce5RxCdHYqGYr\n",
            "downloading to /content/data_clean/George Gissing - 14.txt\n",
            "title: Gilbert Parker - 2.txt, id: 1ga0yYTaRg5QU9FZdigIILC98nM5YkEz4\n",
            "downloading to /content/data_clean/Gilbert Parker - 2.txt\n",
            "title: George Gissing - 18.txt, id: 1eDoTPHX6rKX52gOUob7qy9Y1xW6MkxWk\n",
            "downloading to /content/data_clean/George Gissing - 18.txt\n",
            "title: George Gissing - 16.txt, id: 1auWKlkRnJwZyPLaB-3IuDe9UcSRG2gh5\n",
            "downloading to /content/data_clean/George Gissing - 16.txt\n",
            "title: George Gissing - 6.txt, id: 1DK6-2NU-3Ev5wFM5KRfc7jK5_FfGq2Yg\n",
            "downloading to /content/data_clean/George Gissing - 6.txt\n",
            "title: George Gissing - 7.txt, id: 1OgoYhROqoSRtVBFGQ_ktrhbY9KqtgiLz\n",
            "downloading to /content/data_clean/George Gissing - 7.txt\n",
            "title: George Gissing - 4.txt, id: 1rH_lnxxdaGds1E3ZYa8BjTAAhHbq2QgL\n",
            "downloading to /content/data_clean/George Gissing - 4.txt\n",
            "title: George Gissing - 9.txt, id: 1nbPjR7xETQnWotWkscru4SBlZ9vyTREX\n",
            "downloading to /content/data_clean/George Gissing - 9.txt\n",
            "title: George Gissing - 5.txt, id: 1v9xZZ_WcL0JA2Ulv-K_btyLYUYhPC_wF\n",
            "downloading to /content/data_clean/George Gissing - 5.txt\n",
            "title: George Gissing - 3.txt, id: 1uZGkRA-RPjwZrkoMGODLA-XDfFw6Ch6G\n",
            "downloading to /content/data_clean/George Gissing - 3.txt\n",
            "title: George Gissing - 10.txt, id: 19pxsGO71AfMZUBLRf2sy0eBKZrldFJwx\n",
            "downloading to /content/data_clean/George Gissing - 10.txt\n",
            "title: George Gissing - 8.txt, id: 10ZCWwZFr6bc9KXxq3i5OkTLlw6mDKVq-\n",
            "downloading to /content/data_clean/George Gissing - 8.txt\n",
            "title: George Gissing - 11.txt, id: 1MUdmv1Pips-3kN4QaUHPgzzsDaXATRev\n",
            "downloading to /content/data_clean/George Gissing - 11.txt\n",
            "title: George Gissing - 12.txt, id: 1cyXJ3-UUbJXSxhD2cn-aGwe3gMX4dcBI\n",
            "downloading to /content/data_clean/George Gissing - 12.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "title: George Gissing - 2.txt, id: 1TgeehcW7iqntOfbRLH8iy1I15XBVdaxj\n",
            "downloading to /content/data_clean/George Gissing - 2.txt\n",
            "title: George Gissing - 1.txt, id: 1KDkLX5NHiTSltmuM62AjHLvysn9YIOsr\n",
            "downloading to /content/data_clean/George Gissing - 1.txt\n",
            "title: Arthur Conan Doyle - 16.txt, id: 1x7aFEQd4B22hXRhgcXtFqpFynrELXh_1\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 16.txt\n",
            "title: Arthur Conan Doyle - 11.txt, id: 1r5sFr40dIr6fRkcxLSKnGFGAAAA6S5pT\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 11.txt\n",
            "title: Arthur Conan Doyle - 14.txt, id: 1Il1phCs0DRuvcGPWCeTBZxBhyrzuNvJd\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 14.txt\n",
            "title: Arthur Conan Doyle - 17.txt, id: 1WO8c4eGI0PrkbgPKuycecVefuVn8PRfK\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 17.txt\n",
            "title: Arthur Conan Doyle - 13.txt, id: 1FePgEn_ZEgdeqWtdJyI5PNR8RXAlSCas\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 13.txt\n",
            "title: Arthur Conan Doyle - 12.txt, id: 1BU0YcOr-_2EbjkxSrPuwqKiz2_bM4SL-\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 12.txt\n",
            "title: Arthur Conan Doyle - 15.txt, id: 1twl0Vmkb7muMtMKS1NwDOGzacOXTiPAs\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 15.txt\n",
            "title: Arthur Conan Doyle - 18.txt, id: 1w6pQHM7gZtL3vEd9tcpjntj81u1LDg_E\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 18.txt\n",
            "title: Arthur Conan Doyle - 2.txt, id: 1-ICV-ZUMj13-enMhUeaqsW8fqYKTnj40\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 2.txt\n",
            "title: Humphrey Ward - 4.txt, id: 1Wsd7n_qR3JYkpTwAEoqB_DuNRHsuAhV9\n",
            "downloading to /content/data_clean/Humphrey Ward - 4.txt\n",
            "title: Arthur Conan Doyle - 6.txt, id: 1ucaa3xIrW9ML0Ni0hw6GiPwGsECDSLVE\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 6.txt\n",
            "title: Arthur Conan Doyle - 5.txt, id: 1zxx0ZTpoOwop84M-jKtYh3Qyq4GpiNP8\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 5.txt\n",
            "title: Arthur Conan Doyle - 10.txt, id: 1lhoE0CpW-Ol6m_4rEKCXtezDm1Ng_7jd\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 10.txt\n",
            "title: Arthur Conan Doyle - 4.txt, id: 11vsZdrNuc0g1Fkjoz5z7rL1aaIMyUTU3\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 4.txt\n",
            "title: Humphrey Ward - 3.txt, id: 1PL-JDlMvNxQ3X6CTHBjQ_KtB1HmphQsv\n",
            "downloading to /content/data_clean/Humphrey Ward - 3.txt\n",
            "title: Arthur Conan Doyle - 9.txt, id: 1iGZzu8pnzuRZ-4gSeQsyxT_t8DJ-ZB7P\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 9.txt\n",
            "title: Arthur Conan Doyle - 3.txt, id: 13G0xwqXi7wIJP2v-zMzFPjiDhR5wqwC3\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 3.txt\n",
            "title: Arthur Conan Doyle - 1.txt, id: 179V02FZkDN2y_lveiS3LdtPgbGmqz-rL\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 1.txt\n",
            "title: Arthur Conan Doyle - 8.txt, id: 1nbIlSwMx5Ce7tiM3nV862xbV-Cam6IlT\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 8.txt\n",
            "title: Arthur Conan Doyle - 7.txt, id: 1MiigKKiSP_L5WVZEPKd2LyTxFNL1PC_d\n",
            "downloading to /content/data_clean/Arthur Conan Doyle - 7.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7scs2nBQV7n",
        "colab_type": "code",
        "outputId": "7d066c65-2322-487c-aa01-346d54786868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = []\n",
        "for _,c in data:\n",
        "    X.append(c.lower())\n",
        "    \n",
        "Y = []\n",
        "for i,_ in data:\n",
        "    Y.append(i.lower())\n",
        "\n",
        "X1 = []\n",
        "Y_data1 = []\n",
        "\n",
        "for text in X:\n",
        "  c = text.strip().split()\n",
        "  X1.append(c)\n",
        "\n",
        "print(len(X))\n",
        "X_data1 = []\n",
        "count = 0\n",
        "for i in X1:\n",
        "  m=0\n",
        "  n=1000\n",
        "  times = len(i)//1000\n",
        "  for j in range(times):\n",
        "    X_data1.append(i[m:n])\n",
        "    m = m + 1000\n",
        "    n = n + 1000\n",
        "    Y_data1.append(Y[count]) \n",
        "  X_data1.append(i[m:len(i)+1])\n",
        "  Y_data1.append(Y[count])\n",
        "  count = count + 1 \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4BqBBbv_blc",
        "colab_type": "code",
        "outputId": "d7c118ba-85cc-4df6-f734-22a85696014b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "temp_list = []\n",
        "for i in range(len(X_data1)):\n",
        "  temp_list.append([X_data1[i], Y_data1[i]])\n",
        "print(len(temp_list))\n",
        "print(temp_list[0][1])\n",
        "\n",
        "import random\n",
        "\n",
        "random.shuffle(temp_list)\n",
        "print(len(temp_list))\n",
        "print(temp_list[0][1])\n",
        "\n",
        "X_data = []\n",
        "Y_data = []\n",
        "for i in range(len(temp_list)):\n",
        "  X_data.append(temp_list[i][0])\n",
        "  Y_data.append(temp_list[i][1])\n",
        "print(len(X_data), len(Y_data))\n",
        "print(X_data[0], Y_data[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10078\n",
            "humphrey ward \n",
            "10078\n",
            "george gissing \n",
            "10078 10078\n",
            "['to', 'a', 'pitying', 'shrug', 'of', 'the', 'shoulders', 'but', 'he', 'could', 'not', 'speak', 'otherwise', 'than', 'vigorously', 'and', 'at', 'times', 'his', 'words', 'were', 'eloquent', 'we', 'know', 'not', 'how', 'things', 'may', 'improve', 'in', 'the', 'future', 'thus', 'he', 'perorated', 'but', 'let', 'celibate', 'ladies', 'of', 'the', 'present', 'bear', 'in', 'mind', 'that', 'the', 'chances', 'are', 'enormously', 'against', 'their', 'making', 'a', 'marriage', 'worthy', 'of', 'the', 'name', 'oh', 'from', 'some', 'man', 'at', 'the', 'back', 'let', 'them', 'remember', 'too', 'if', 'they', 'are', 'disposed', 'to', 'altruism', 'that', 'though', 'most', 'men', 'manage', 'to', 'find', 'a', 'wife', 'very', 'few', 'indeed', 'as', 'things', 'are', 'do', 'not', 'ultimately', 'wish', 'that', 'they', 'had', 'remained', 'single', 'a', 'roar', 'of', 'laughter', 'and', 'many', 'protests', 'this', 'being', 'so', 'let', 'women', 'who', 'have', 'no', 'family', 'of', 'their', 'own', 'devote', 'themselves', 'whenever', 'possible', 'to', 'the', 'generous', 'and', 'high', 'task', 'of', 'training', 'the', 'new', 'female', 'generation', 'so', 'that', 'they', 'may', 'help', 'to', 'mitigate', 'one', 'of', 'the', 'greatest', 'ills', 'of', 'civilized', 'existence', 'and', 'prepare', 'for', 'women', 'of', 'the', 'future', 'the', 'possibility', 'of', 'a', 'life', 'truly', 'emancipated', 'denzil', 'sat', 'down', 'with', 'a', 'glow', 'of', 'exulting', 'triumph', 'his', 'lecture', 'was', 'a', 'success', 'not', 'a', 'doubt', 'of', 'it', 'he', 'saw', 'the', 'chairman', 'rise', 'and', 'heard', 'slow', 'languid', 'phrases', 'which', 'contrasted', 'strangely', 'with', 'his', 'own', 'fire', 'and', 'rush', 'a', 'vote', 'of', 'thanks', 'was', 'being', 'proposed', 'when', 'silence', 'carne', 'he', 'was', 'aware', 'of', 'some', 'fluster', 'in', 'the', 'body', 'of', 'the', 'hall', 'people', 'were', 'whispering', 'tittering', 'turning', 'round', 'to', 'look', 'two', 'persons', 'had', 'stood', 'up', 'with', 'the', 'intention', 'of', 'seconding', 'the', 'vote', 'of', 'gratitude', 'one', 'was', 'mr', 'chown', 'the', 'other', 'that', 'lady', 'who', 'had', 'a', 'place', 'in', 'the', 'middle', 'of', 'the', 'assemblage', 'and', 'who', 'seemed', 'to', 'be', 'so', 'well', 'known', 'the', 'radical', 'draper', 'did', 'not', 'immediately', 'give', 'way', 'but', 'his', 'neighbours', 'reminded', 'him', 'of', 'propriety', 'quarrier', 'had', 'just', 'scrutinized', 'the', 'person', 'of', 'the', 'lady', 'about', 'to', 'speak', 'when', 'her', 'voice', 'fell', 'upon', 'his', 'ears', 'with', 'a', 'pleasant', 'distinctness', 'as', 'it', 'is', 'certainly', 'right', 'she', 'began', 'that', 'a', 'woman', 'should', 'be', 'one', 'of', 'those', 'who', 'return', 'thanks', 'to', 'our', 'lecturer', 'and', 'as', 'i', 'fear', 'that', 'no', 'other', 'woman', 'present', 'will', 'be', 'inclined', 'to', 'undertake', 'this', 'duty', 'i', 'will', 'make', 'no', 'apology', 'for', 'trying', 'to', 'perform', 'it', 'and', 'that', 'in', 'very', 'few', 'words', 'speaking', 'for', 'myself', 'i', 'cannot', 'pretend', 'to', 'agree', 'with', 'the', 'whole', 'of', 'mr', 'quarriers', 'address', 'i', 'think', 'his', 'views', 'were', 'frequently', 'timid', 'laughter', 'and', 'hushingfrequently', 'timid', 'and', 'occasionally', 'quite', 'too', 'masculine', 'i', 'heard', 'once', 'of', 'a', 'lady', 'who', 'proposed', 'to', 'give', 'a', 'series', 'of', 'lectures', 'on', 'astronomy', 'from', 'a', 'female', 'point', 'of', 'view', 'a', 'laugh', 'from', 'two', 'or', 'three', 'people', 'only', 'and', 'i', 'should', 'prefer', 'to', 'entitle', 'mr', 'quarriers', 'lecture', 'woman', 'from', 'a', 'male', 'point', 'of', 'view', 'however', 'it', 'was', 'certainly', 'wellmeaning', 'undoubtedly', 'eloquent', 'and', 'on', 'the', 'whole', 'in', 'this', 'time', 'of', 'small', 'mercies', 'something', 'for', 'which', 'a', 'member', 'of', 'the', 'struggling', 'sex', 'may', 'reasonably', 'be', 'grateful', 'i', 'wish', 'therefore', 'to', 'add', 'my', 'voice', 'to', 'the', 'proposal', 'that', 'a', 'vote', 'of', 'thanks', 'be', 'offered', 'to', 'our', 'lecturer', 'with', 'all', 'sincerity', 'and', 'all', 'heartiness', 'a', 'devilish', 'good', 'little', 'speech', 'denzil', 'murmured', 'to', 'himself', 'as', 'the', 'applause', 'and', 'merriment', 'broke', 'forth', 'the', 'show', 'of', 'hands', 'seemed', 'to', 'be', 'universal', 'denzil', 'was', 'enjoying', 'an', 'enormous', 'happiness', 'he', 'had', 'proved', 'to', 'himself', 'that', 'he', 'could', 'speak', 'and', 'henceforth', 'the', 'platform', 'was', 'his', 'own', 'now', 'let', 'the', 'dissolution', 'of', 'parliament', 'come', 'with', 'all', 'convenient', 'speed', 'he', 'longed', 'to', 'begin', 'the', 'political', 'conflict', 'committeemen', 'crowded', 'about', 'him', 'offering', 'hands', 'and', 'brimming', 'with', 'facetious', 'eulogy', 'you', 'were', 'on', 'very', 'thin', 'ice', 'now', 'and', 'then', 'said', 'mr', 'liversedge', 'you', 'made', 'me', 'shake', 'in', 'my', 'shoes', 'but', 'the', 'skating', 'was', 'admirable', 'i', 'never', 'knew', 'mrs', 'wade', 'so', 'complimentary', 'remarked', 'old', 'mr', 'toft', 'i', 'expected', 'half', 'an', 'hours', 'diatribe', 'the', 'rapt', 'oration', 'flowing', 'free', 'as', 'tennyson', 'says', 'you', 'have', 'taught', 'her', 'good', 'manners', 'down', 'in', 'the', 'hall', 'was', 'proceeding', 'an', 'animated', 'conversazione', 'in', 'one', 'group', 'stood', 'the', 'mayor', 'and', 'his', 'wife', 'miss', 'mumbray', 'and', 'ivy', 'glazzard', 'serena', 'was', 'turning', 'aside', 'to', 'throw', 'a', 'shawl', 'over', 'her', 'shoulders', 'when', 'eustace', 'glazzard', 'stepped', 'up', 'pray', 'let', 'me', 'assist', 'you', 'miss', 'mumbray', 'he', 'placed', 'the', 'wrap', 'i', 'hope', 'you', 'have', 'been', 'amused', 'i', 'have', 'really', 'answered', 'the', 'girl', 'with', 'a', 'glance', 'towards', 'ivy', 'who', 'had', 'heard', 'her', 'uncles', 'voice', 'you', 'ivy', 'he', 'continued', 'are', 'rather', 'on', 'mrs', 'wades', 'side', 'i', 'think', 'oh', 'unclehow', 'can', 'you', 'mr', 'mumbray', 'was', 'looking', 'on', 'trying', 'to', 'determine', 'who', 'the', 'gentleman', 'might', 'be', 'glazzard', 'desirous', 'of', 'presentation', 'to', 'the', 'mayor', 'gave', 'ivy', 'a', 'glance', 'and', 'she', 'with', 'much', 'nervousness', 'uncertain', 'whether', 'she', 'might', 'do', 'such', 'a', 'thing', 'said', 'to', 'her', 'friends', 'father', 'i', 'think', 'mr', 'mumbray', 'you', 'dont', 'know', 'my', 'uncle', 'mr', 'eustace', 'glazzard', 'ha', 'very', 'glad', 'to', 'meet', 'you', 'mr', 'glazzard', 'my', 'love', 'he', 'turned', 'to', 'the', 'mayoress', 'let', 'me', 'present', 'to', 'you', 'mr', 'eustace', 'glazzardmr', 'williams', 'brother', 'the', 'mayoress', 'laid', 'her', 'fan', 'on', 'her', 'bosom', 'and', 'inclined', 'graciously', 'she', 'was', 'a', 'portly', 'and', 'highcoloured', 'woman', 'with', 'hanging', 'nether', 'lip', 'glazzard', 'conversed', 'with', 'her', 'and', 'her', 'husband', 'in', 'a', 'tone', 'of', 'amiable', 'liveliness', 'remarkable', 'he', 'said', 'smiling', 'to', 'the', 'mayoress', 'how', 'patiently', 'women', 'in', 'general', 'support', 'this', 'ancient', 'yoke', 'of', 'tyranny', 'mrs', 'mumbray', 'looked', 'at', 'him', 'with', 'condescending', 'eyes', 'in', 'doubt', 'as', 'to', 'his', 'real', 'meaning', 'her', 'husband', 'ponderously', 'literal', 'answered', 'in', 'his', 'headvoice', 'i', 'fail', 'to', 'recognize', 'the', 'grievance', 'how', 'do', 'you', 'do', 'mr', 'lovett', 'i', 'am', 'conscious', 'of', 'no', 'tyranny', 'but', 'that', 'is', 'just', 'what', 'mr', 'glazzard', 'meant', 'papa', 'put', 'in', 'serena', 'with', 'scarcely', 'disguised', 'contempt', 'ha', 'oh', 'to', 'be', 'sureto', 'be', 'sure', 'quite', 'so', 'mr', 'glazzard', 'a', 'very', 'amoosing', 'lecture', 'all', 'the', 'same', 'not', 'of', 'course', 'to', 'be', 'taken', 'seriously', 'good', 'evening', 'mr', 'glazzardgood', 'evening', 'the', 'mayoress', 'again', 'inclined', 'serena', 'gave', 'her', 'acquaintance', 'an', 'enigmatic', 'look', 'murmured', 'a', 'leavetaking', 'and', 'with', 'an', 'affectionate', 'nod', 'to', 'ivy', 'passed', 'on', 'glazzard', 'drew', 'near', 'to', 'his', 'niece', 'your', 'friend', 'is', 'not', 'a', 'disciple', 'of', 'mrs', 'wade', 'oh', 'dear', 'no', 'uncle', 'not', 'just', 'a', 'little', 'bit', 'he', 'smiled', 'encouragingly', 'perhaps', 'she', 'would', 'agree', 'with', 'what', 'mr', 'quarrier', 'said', 'about', 'girls', 'having', 'a', 'right', 'to', 'better'] george gissing \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqFD6XAJP7AV",
        "colab_type": "code",
        "outputId": "ead71b69-24d6-4bbd-84eb-0fbf2baa27df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# Converting Output values to One Hot Vector\n",
        "print(\"Converting to One hot vector(training set)...\")\n",
        "Y_data = np.array(Y_data)\n",
        "#print(train_values)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_integer_encoded = label_encoder.fit_transform(Y_data)\n",
        "print(train_integer_encoded)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting to One hot vector(training set)...\n",
            "[1 1 3 ... 4 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5xvDme2P7Ak",
        "colab_type": "code",
        "outputId": "0f7635cd-ae05-40e4-ea92-7180b628e5b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_onehot_encoded = keras.utils.to_categorical(train_integer_encoded)\n",
        "print(train_onehot_encoded[2841,:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk61HNO9P7Ar",
        "colab_type": "code",
        "outputId": "b9867750-9a66-48c8-8063-6943c17abbfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# prepare tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(X_data)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ABcYEUhP7Ay",
        "colab_type": "code",
        "outputId": "e1890969-f59f-42ef-b45e-902699eedd36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# integer encode the documents\n",
        "encoded_docs = t.texts_to_sequences(X_data)\n",
        "print(encoded_docs[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4, 5, 10819, 4993, 3, 1, 680, 21, 8, 55, 22, 235, 1206, 81, 7120, 2, 20, 439, 14, 207, 39, 5897, 45, 72, 22, 88, 157, 129, 7926, 7, 1, 735, 390, 8, 57481, 21, 149, 37749, 997, 3, 1, 417, 545, 7, 150, 10, 1, 2206, 58, 7069, 182, 61, 475, 5, 535, 1477, 3, 1, 259, 172, 32, 67, 60, 20, 1, 100, 149, 49, 352, 139, 46, 35, 58, 2884, 4, 17954, 10, 128, 177, 136, 2273, 4, 227, 5, 247, 66, 187, 196, 19, 157, 58, 57, 22, 4934, 301, 10, 35, 16, 675, 1148, 5, 2251, 3, 1291, 2, 168, 10820, 33, 238, 37, 149, 299, 44, 26, 38, 584, 3, 61, 105, 5951, 410, 2009, 402, 4, 1, 2734, 2, 364, 1405, 3, 3256, 1, 228, 2998, 2971, 37, 10, 35, 129, 286, 4, 22556, 42, 3, 1, 2239, 11141, 3, 9195, 1533, 2, 4025, 18, 299, 3, 1, 735, 1, 2274, 3, 5, 109, 1805, 11337, 3600, 239, 85, 17, 5, 2197, 3, 18569, 1659, 14, 3861, 9, 5, 1182, 22, 5, 338, 3, 11, 8, 138, 1, 6088, 1052, 2, 185, 1337, 5584, 3257, 30, 7927, 1887, 17, 14, 105, 331, 2, 1524, 5, 4337, 3, 1925, 9, 238, 2391, 53, 329, 44245, 8, 9, 961, 3, 67, 57482, 7, 1, 454, 3, 1, 563, 164, 39, 4259, 33625, 684, 208, 4, 137, 99, 1608, 16, 180, 62, 17, 1, 2040, 3, 33626, 1, 4337, 3, 2233, 42, 9, 130, 15217, 1, 90, 10, 144, 44, 16, 5, 195, 7, 1, 1234, 3, 1, 18570, 2, 44, 142, 4, 25, 37, 75, 366, 1, 3768, 17955, 70, 22, 1369, 198, 115, 21, 14, 3392, 2854, 23, 3, 9420, 3475, 16, 145, 22557, 1, 568, 3, 1, 144, 71, 4, 235, 53, 12, 158, 289, 54, 14, 799, 17, 5, 926, 13891, 19, 11, 24, 538, 204, 15, 248, 10, 5, 161, 76, 25, 42, 3, 152, 44, 499, 1925, 4, 117, 8369, 2, 19, 6, 334, 10, 38, 90, 161, 417, 52, 25, 1840, 4, 5024, 33, 839, 6, 52, 146, 38, 5772, 18, 854, 4, 6839, 11, 2, 10, 7, 66, 187, 207, 573, 18, 258, 6, 362, 3393, 4, 2570, 17, 1, 298, 3, 130, 10651, 1282, 6, 87, 14, 2080, 39, 2756, 3616, 1291, 2, 57483, 3616, 2, 1943, 224, 139, 7305, 6, 185, 140, 3, 5, 144, 44, 2391, 4, 198, 5, 3716, 3, 4766, 27, 22558, 32, 5, 2998, 381, 3, 679, 5, 590, 32, 99, 51, 230, 164, 79, 2, 6, 76, 2855, 4, 26523, 130, 10651, 3861, 161, 32, 5, 3970, 381, 3, 679, 257, 11, 9, 538, 13329, 4496, 5897, 2, 27, 1, 298, 7, 33, 83, 3, 302, 14217, 166, 18, 30, 5, 2081, 3, 1, 2234, 2806, 129, 8370, 25, 2087, 6, 301, 658, 4, 2563, 28, 158, 4, 1, 3717, 10, 5, 4337, 3, 1925, 25, 920, 4, 117, 8369, 17, 34, 3414, 2, 34, 14542, 5, 5773, 112, 68, 804, 3600, 1315, 4, 110, 19, 1, 4792, 2, 5552, 481, 681, 1, 466, 3, 192, 142, 4, 25, 5735, 3600, 9, 3795, 47, 2999, 1134, 8, 16, 1208, 4, 110, 10, 8, 55, 235, 2, 2630, 1, 2451, 9, 14, 105, 56, 149, 1, 12575, 3, 2252, 74, 17, 34, 4599, 3039, 8, 3394, 4, 956, 1, 1806, 3191, 44246, 1995, 71, 23, 3267, 192, 2, 15218, 17, 18571, 23664, 13, 39, 27, 66, 812, 2904, 56, 2, 50, 31, 130, 7928, 13, 96, 29, 1895, 7, 28, 4296, 21, 1, 20698, 9, 3628, 6, 92, 156, 124, 3476, 37, 13611, 740, 114, 130, 44247, 6, 847, 278, 47, 401, 30573, 1, 12339, 20699, 4723, 578, 19, 20700, 620, 13, 26, 1602, 12, 112, 2963, 85, 7, 1, 563, 9, 6041, 47, 5819, 44248, 7, 42, 1585, 180, 1, 4994, 2, 14, 247, 206, 8017, 2, 6782, 3271, 8018, 9, 684, 862, 4, 1149, 5, 4672, 97, 12, 680, 53, 2564, 3271, 1124, 62, 830, 149, 29, 6579, 13, 206, 8017, 8, 964, 1, 9800, 6, 293, 13, 26, 48, 2116, 6, 26, 313, 154, 1, 229, 17, 5, 872, 256, 6782, 44, 16, 185, 12, 4203, 158, 13, 6782, 8, 754, 58, 260, 27, 124, 15219, 219, 6, 87, 172, 44249, 93, 13, 130, 8017, 9, 276, 27, 854, 4, 8105, 44, 1, 765, 111, 25, 3271, 10350, 3, 19923, 4, 1, 4994, 244, 6782, 5, 872, 2, 15, 17, 106, 4793, 2366, 375, 15, 111, 57, 103, 5, 184, 31, 4, 12, 317, 165, 6, 87, 130, 8017, 13, 127, 72, 28, 693, 130, 2564, 3271, 1746, 66, 470, 4, 450, 13, 130, 3271, 28, 193, 8, 171, 4, 1, 24943, 149, 29, 417, 4, 13, 130, 2564, 57484, 3687, 426, 1, 24943, 562, 12, 5440, 27, 12, 2323, 2, 1840, 6889, 15, 9, 5, 7861, 2, 26524, 161, 17, 1646, 10485, 1919, 3271, 6580, 17, 12, 2, 12, 370, 7, 5, 506, 3, 3659, 21569, 1865, 8, 31, 668, 4, 1, 24943, 88, 6042, 299, 7, 631, 1525, 33, 1160, 8273, 3, 4995, 124, 8017, 135, 20, 23, 17, 14543, 86, 7, 338, 19, 4, 14, 725, 1055, 12, 370, 37750, 13892, 154, 7, 14, 57485, 6, 1795, 4, 6425, 1, 7929, 88, 57, 13, 57, 130, 57486, 6, 107, 748, 3, 38, 4995, 21, 10, 24, 145, 43, 130, 3271, 541, 2987, 186, 7, 8018, 17, 619, 5333, 2346, 1746, 172, 4, 25, 44250, 25, 281, 224, 37, 130, 3271, 5, 66, 57487, 3861, 34, 1, 212, 22, 3, 181, 4, 25, 326, 1970, 112, 333, 130, 57488, 333, 1, 24943, 94, 1840, 8018, 244, 12, 1070, 47, 23665, 137, 1315, 5, 9667, 2, 17, 47, 3477, 4317, 4, 6782, 234, 27, 3271, 343, 325, 4, 14, 2833, 59, 272, 24, 22, 5, 11900, 3, 124, 3476, 172, 280, 38, 693, 22, 145, 5, 68, 776, 8, 560, 16906, 220, 15, 41, 2570, 17, 43, 130, 3475, 31, 71, 524, 296, 5, 204, 4, 218]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFsg601WP7A2",
        "colab_type": "code",
        "outputId": "8fcbd4a7-c8e4-4fbd-9a4c-dddab2557dd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# pad documents to a max length of 10000 words\n",
        "max_length = 1000\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "print(padded_docs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[    4     5 10819 ...   204     4   218]\n",
            " [   25  2662    21 ...  5138  2096    18]\n",
            " [   64  2874   294 ...     2  4133    82]\n",
            " ...\n",
            " [   40   952    28 ...    40    64   939]\n",
            " [11138    97     1 ...   424    53     8]\n",
            " [  328    28   671 ...    77   536    51]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKHdwRxoP7A9",
        "colab_type": "code",
        "outputId": "044ba4d1-a118-444b-e1ea-13be44d392d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('~/data')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1ogZLyJ5GTI8a0o8HPac8zTtm96SzCv-k' in parents\"}).GetList()\n",
        "print(file_list[0]['title'], file_list[0]['id'] )\n",
        "fname = os.path.join(local_download_path, file_list[0]['title'])\n",
        "f_ = drive.CreateFile({'id': file_list[0]['id']})\n",
        "f_.GetContentFile(fname)\n",
        "\n",
        "\n",
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open(fname)\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove.6B.100d.txt 17BmrNJa4oJDNg3KZ6u2Ww0ETQYklOJJ7\n",
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "939BL-ZgP7BD",
        "colab_type": "code",
        "outputId": "cd6a35ab-c33d-4c94-ffaa-bd18216232d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = zeros((vocab_size, 100))\n",
        "for word, i in t.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector\n",
        "print(embedding_matrix.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128625, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiXwPtug3BuQ",
        "colab_type": "code",
        "outputId": "47997997-043f-438f-f29c-c91910983330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(padded_docs.shape)\n",
        "doc_train = np.array(padded_docs[0:8000,:])\n",
        "print(doc_train.shape)\n",
        "doc_test = np.array(padded_docs[8000:,:])\n",
        "print(doc_test.shape)\n",
        "\n",
        "onehot_train = np.array(train_onehot_encoded[0:8000,:])\n",
        "print(onehot_train.shape)\n",
        "onehot_test = np.array(train_onehot_encoded[8000:,:])\n",
        "print(onehot_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10078, 1000)\n",
            "(8000, 1000)\n",
            "(2078, 1000)\n",
            "(8000, 5)\n",
            "(2078, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yoATVFvP7BG",
        "colab_type": "code",
        "outputId": "4e175e39-7e69-478c-ffdd-a54f024ab9c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=1000, trainable=False)\n",
        "model.add(e)\n",
        "model.add(Conv1D(16, 3, border_mode='valid'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(32, 3, border_mode='valid'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(64, 3, border_mode='valid'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(3000, activation='relu', kernel_initializer='glorot_uniform'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "#model.add(Dense(30000, activation='relu'))\n",
        "#model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Dense(5, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(16, 3, padding=\"valid\")`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`NHWC` for data_format is deprecated, use `NWC` instead\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 3, padding=\"valid\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"valid\")`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhGMNDS1P7BQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model\n",
        "num_of_epochs = 500\n",
        "batchsize = 2000\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTewq1MqP7BT",
        "colab_type": "code",
        "outputId": "6ef97fe1-eac4-4dc2-c450-ab0de8bf9985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "# summarize the model\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 1000, 100)         12862500  \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 998, 16)           4816      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 499, 16)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 497, 32)           1568      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 248, 32)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 246, 64)           6208      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 123, 64)           0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3000)              195000    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 15005     \n",
            "=================================================================\n",
            "Total params: 13,085,097\n",
            "Trainable params: 222,597\n",
            "Non-trainable params: 12,862,500\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEyhvAkHP7Bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath='/content/weights.best.CNN_pos.hdf5', \n",
        "                               verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBWtZLSZP7Bv",
        "colab_type": "code",
        "outputId": "addb7b62-2821-4d04-81c5-258511d6c06b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34054
        }
      },
      "source": [
        "# fit the model\n",
        "history = model.fit(doc_train, onehot_train, epochs=num_of_epochs, verbose=1, batch_size=batchsize, callbacks=[checkpointer], validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6400 samples, validate on 1600 samples\n",
            "Epoch 1/500\n",
            "6400/6400 [==============================] - 2s 308us/step - loss: 3.1059 - categorical_accuracy: 0.5697 - val_loss: 1.2637 - val_categorical_accuracy: 0.5756\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.26374, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 2/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.8311 - categorical_accuracy: 0.6984 - val_loss: 0.4700 - val_categorical_accuracy: 0.8425\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.26374 to 0.47003, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 3/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4244 - categorical_accuracy: 0.8608 - val_loss: 0.4561 - val_categorical_accuracy: 0.8419\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.47003 to 0.45611, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 4/500\n",
            "6400/6400 [==============================] - 1s 153us/step - loss: 0.4103 - categorical_accuracy: 0.8603 - val_loss: 0.4416 - val_categorical_accuracy: 0.8425\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.45611 to 0.44155, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 5/500\n",
            "6400/6400 [==============================] - 1s 155us/step - loss: 0.4027 - categorical_accuracy: 0.8584 - val_loss: 0.5200 - val_categorical_accuracy: 0.8100\n",
            "\n",
            "Epoch 00005: val_loss did not improve\n",
            "Epoch 6/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6394 - categorical_accuracy: 0.7705 - val_loss: 0.6818 - val_categorical_accuracy: 0.7569\n",
            "\n",
            "Epoch 00006: val_loss did not improve\n",
            "Epoch 7/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.6287 - categorical_accuracy: 0.7667 - val_loss: 0.5088 - val_categorical_accuracy: 0.8044\n",
            "\n",
            "Epoch 00007: val_loss did not improve\n",
            "Epoch 8/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.5015 - categorical_accuracy: 0.8112 - val_loss: 0.4683 - val_categorical_accuracy: 0.8294\n",
            "\n",
            "Epoch 00008: val_loss did not improve\n",
            "Epoch 9/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.5867 - categorical_accuracy: 0.7758 - val_loss: 0.7918 - val_categorical_accuracy: 0.6825\n",
            "\n",
            "Epoch 00009: val_loss did not improve\n",
            "Epoch 10/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.6652 - categorical_accuracy: 0.7481 - val_loss: 0.7475 - val_categorical_accuracy: 0.7113\n",
            "\n",
            "Epoch 00010: val_loss did not improve\n",
            "Epoch 11/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.7250 - categorical_accuracy: 0.7178 - val_loss: 0.5705 - val_categorical_accuracy: 0.7887\n",
            "\n",
            "Epoch 00011: val_loss did not improve\n",
            "Epoch 12/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4827 - categorical_accuracy: 0.8291 - val_loss: 0.5133 - val_categorical_accuracy: 0.8056\n",
            "\n",
            "Epoch 00012: val_loss did not improve\n",
            "Epoch 13/500\n",
            "2000/6400 [========>.....................] - ETA: 0s - loss: 0.4830 - categorical_accuracy: 0.8170"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4838 - categorical_accuracy: 0.8219 - val_loss: 0.4884 - val_categorical_accuracy: 0.8219\n",
            "\n",
            "Epoch 00013: val_loss did not improve\n",
            "Epoch 14/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5573 - categorical_accuracy: 0.7950 - val_loss: 1.2228 - val_categorical_accuracy: 0.6081\n",
            "\n",
            "Epoch 00014: val_loss did not improve\n",
            "Epoch 15/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 1.0055 - categorical_accuracy: 0.6603 - val_loss: 0.5494 - val_categorical_accuracy: 0.7850\n",
            "\n",
            "Epoch 00015: val_loss did not improve\n",
            "Epoch 16/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4739 - categorical_accuracy: 0.8322 - val_loss: 0.6431 - val_categorical_accuracy: 0.7569\n",
            "\n",
            "Epoch 00016: val_loss did not improve\n",
            "Epoch 17/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6039 - categorical_accuracy: 0.7653 - val_loss: 0.6353 - val_categorical_accuracy: 0.7669\n",
            "\n",
            "Epoch 00017: val_loss did not improve\n",
            "Epoch 18/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5393 - categorical_accuracy: 0.8017 - val_loss: 0.5731 - val_categorical_accuracy: 0.7837\n",
            "\n",
            "Epoch 00018: val_loss did not improve\n",
            "Epoch 19/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4956 - categorical_accuracy: 0.8222 - val_loss: 0.6590 - val_categorical_accuracy: 0.7563\n",
            "\n",
            "Epoch 00019: val_loss did not improve\n",
            "Epoch 20/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6768 - categorical_accuracy: 0.7589 - val_loss: 0.8090 - val_categorical_accuracy: 0.6925\n",
            "\n",
            "Epoch 00020: val_loss did not improve\n",
            "Epoch 21/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6056 - categorical_accuracy: 0.7698 - val_loss: 0.6356 - val_categorical_accuracy: 0.7594\n",
            "\n",
            "Epoch 00021: val_loss did not improve\n",
            "Epoch 22/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5356 - categorical_accuracy: 0.8053 - val_loss: 0.5302 - val_categorical_accuracy: 0.8119\n",
            "\n",
            "Epoch 00022: val_loss did not improve\n",
            "Epoch 23/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5232 - categorical_accuracy: 0.8097 - val_loss: 0.7188 - val_categorical_accuracy: 0.7262\n",
            "\n",
            "Epoch 00023: val_loss did not improve\n",
            "Epoch 24/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5683 - categorical_accuracy: 0.7814 - val_loss: 0.6766 - val_categorical_accuracy: 0.7475\n",
            "\n",
            "Epoch 00024: val_loss did not improve\n",
            "Epoch 25/500\n",
            "6400/6400 [==============================] - 1s 155us/step - loss: 0.9134 - categorical_accuracy: 0.6812 - val_loss: 0.8364 - val_categorical_accuracy: 0.6575\n",
            "\n",
            "Epoch 00025: val_loss did not improve\n",
            "Epoch 26/500\n",
            "6000/6400 [===========================>..] - ETA: 0s - loss: 0.5894 - categorical_accuracy: 0.7788"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6400/6400 [==============================] - 1s 158us/step - loss: 0.5821 - categorical_accuracy: 0.7820 - val_loss: 0.4742 - val_categorical_accuracy: 0.8294\n",
            "\n",
            "Epoch 00026: val_loss did not improve\n",
            "Epoch 27/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4530 - categorical_accuracy: 0.8417 - val_loss: 0.5358 - val_categorical_accuracy: 0.7994\n",
            "\n",
            "Epoch 00027: val_loss did not improve\n",
            "Epoch 28/500\n",
            "6400/6400 [==============================] - 1s 155us/step - loss: 0.4896 - categorical_accuracy: 0.8188 - val_loss: 0.5099 - val_categorical_accuracy: 0.8144\n",
            "\n",
            "Epoch 00028: val_loss did not improve\n",
            "Epoch 29/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5730 - categorical_accuracy: 0.7828 - val_loss: 0.6377 - val_categorical_accuracy: 0.7600\n",
            "\n",
            "Epoch 00029: val_loss did not improve\n",
            "Epoch 30/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4846 - categorical_accuracy: 0.8272 - val_loss: 0.6838 - val_categorical_accuracy: 0.7588\n",
            "\n",
            "Epoch 00030: val_loss did not improve\n",
            "Epoch 31/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.8142 - categorical_accuracy: 0.7280 - val_loss: 0.5107 - val_categorical_accuracy: 0.8106\n",
            "\n",
            "Epoch 00031: val_loss did not improve\n",
            "Epoch 32/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4468 - categorical_accuracy: 0.8455 - val_loss: 0.4947 - val_categorical_accuracy: 0.8150\n",
            "\n",
            "Epoch 00032: val_loss did not improve\n",
            "Epoch 33/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5020 - categorical_accuracy: 0.8081 - val_loss: 0.5993 - val_categorical_accuracy: 0.7731\n",
            "\n",
            "Epoch 00033: val_loss did not improve\n",
            "Epoch 34/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.6209 - categorical_accuracy: 0.7655 - val_loss: 0.9339 - val_categorical_accuracy: 0.6837\n",
            "\n",
            "Epoch 00034: val_loss did not improve\n",
            "Epoch 35/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.6694 - categorical_accuracy: 0.7467 - val_loss: 0.6079 - val_categorical_accuracy: 0.7744\n",
            "\n",
            "Epoch 00035: val_loss did not improve\n",
            "Epoch 36/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6171 - categorical_accuracy: 0.7834 - val_loss: 0.4802 - val_categorical_accuracy: 0.8231\n",
            "\n",
            "Epoch 00036: val_loss did not improve\n",
            "Epoch 37/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.4989 - categorical_accuracy: 0.8150 - val_loss: 0.5957 - val_categorical_accuracy: 0.7475\n",
            "\n",
            "Epoch 00037: val_loss did not improve\n",
            "Epoch 38/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.5262 - categorical_accuracy: 0.7959 - val_loss: 0.8275 - val_categorical_accuracy: 0.6988\n",
            "\n",
            "Epoch 00038: val_loss did not improve\n",
            "Epoch 39/500\n",
            "2000/6400 [========>.....................] - ETA: 0s - loss: 0.7512 - categorical_accuracy: 0.7160"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.5944 - categorical_accuracy: 0.7761 - val_loss: 0.8460 - val_categorical_accuracy: 0.6913\n",
            "\n",
            "Epoch 00039: val_loss did not improve\n",
            "Epoch 40/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.6667 - categorical_accuracy: 0.7616 - val_loss: 0.5556 - val_categorical_accuracy: 0.7812\n",
            "\n",
            "Epoch 00040: val_loss did not improve\n",
            "Epoch 41/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4673 - categorical_accuracy: 0.8278 - val_loss: 0.5817 - val_categorical_accuracy: 0.7550\n",
            "\n",
            "Epoch 00041: val_loss did not improve\n",
            "Epoch 42/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4944 - categorical_accuracy: 0.8100 - val_loss: 0.4271 - val_categorical_accuracy: 0.8512\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.44155 to 0.42712, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 43/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4869 - categorical_accuracy: 0.8242 - val_loss: 1.4434 - val_categorical_accuracy: 0.6150\n",
            "\n",
            "Epoch 00043: val_loss did not improve\n",
            "Epoch 44/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 1.4280 - categorical_accuracy: 0.5928 - val_loss: 0.6938 - val_categorical_accuracy: 0.7437\n",
            "\n",
            "Epoch 00044: val_loss did not improve\n",
            "Epoch 45/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5181 - categorical_accuracy: 0.8166 - val_loss: 0.4191 - val_categorical_accuracy: 0.8587\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.42712 to 0.41911, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 46/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.3785 - categorical_accuracy: 0.8756 - val_loss: 0.4201 - val_categorical_accuracy: 0.8494\n",
            "\n",
            "Epoch 00046: val_loss did not improve\n",
            "Epoch 47/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.3800 - categorical_accuracy: 0.8675 - val_loss: 0.4789 - val_categorical_accuracy: 0.8244\n",
            "\n",
            "Epoch 00047: val_loss did not improve\n",
            "Epoch 48/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5590 - categorical_accuracy: 0.7900 - val_loss: 0.8717 - val_categorical_accuracy: 0.7206\n",
            "\n",
            "Epoch 00048: val_loss did not improve\n",
            "Epoch 49/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6536 - categorical_accuracy: 0.7689 - val_loss: 0.6299 - val_categorical_accuracy: 0.7600\n",
            "\n",
            "Epoch 00049: val_loss did not improve\n",
            "Epoch 50/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5238 - categorical_accuracy: 0.8058 - val_loss: 0.8210 - val_categorical_accuracy: 0.6981\n",
            "\n",
            "Epoch 00050: val_loss did not improve\n",
            "Epoch 51/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5816 - categorical_accuracy: 0.7897 - val_loss: 0.4214 - val_categorical_accuracy: 0.8531\n",
            "\n",
            "Epoch 00051: val_loss did not improve\n",
            "Epoch 52/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3776 - categorical_accuracy: 0.8684 - val_loss: 0.5307 - val_categorical_accuracy: 0.8006\n",
            "\n",
            "Epoch 00052: val_loss did not improve\n",
            "Epoch 53/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6825 - categorical_accuracy: 0.7478 - val_loss: 0.6700 - val_categorical_accuracy: 0.7437\n",
            "\n",
            "Epoch 00053: val_loss did not improve\n",
            "Epoch 54/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5516 - categorical_accuracy: 0.7942 - val_loss: 0.5564 - val_categorical_accuracy: 0.7919\n",
            "\n",
            "Epoch 00054: val_loss did not improve\n",
            "Epoch 55/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6175 - categorical_accuracy: 0.7766 - val_loss: 0.7745 - val_categorical_accuracy: 0.7113\n",
            "\n",
            "Epoch 00055: val_loss did not improve\n",
            "Epoch 56/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6973 - categorical_accuracy: 0.7320 - val_loss: 0.4324 - val_categorical_accuracy: 0.8544\n",
            "\n",
            "Epoch 00056: val_loss did not improve\n",
            "Epoch 57/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3854 - categorical_accuracy: 0.8730 - val_loss: 0.4097 - val_categorical_accuracy: 0.8631\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.41911 to 0.40966, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 58/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3948 - categorical_accuracy: 0.8595 - val_loss: 0.4824 - val_categorical_accuracy: 0.8188\n",
            "\n",
            "Epoch 00058: val_loss did not improve\n",
            "Epoch 59/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4899 - categorical_accuracy: 0.8169 - val_loss: 0.5082 - val_categorical_accuracy: 0.8062\n",
            "\n",
            "Epoch 00059: val_loss did not improve\n",
            "Epoch 60/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.8361 - categorical_accuracy: 0.7086 - val_loss: 1.4356 - val_categorical_accuracy: 0.4969\n",
            "\n",
            "Epoch 00060: val_loss did not improve\n",
            "Epoch 61/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 1.0668 - categorical_accuracy: 0.6395 - val_loss: 0.4352 - val_categorical_accuracy: 0.8481\n",
            "\n",
            "Epoch 00061: val_loss did not improve\n",
            "Epoch 62/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3865 - categorical_accuracy: 0.8705 - val_loss: 0.4420 - val_categorical_accuracy: 0.8431\n",
            "\n",
            "Epoch 00062: val_loss did not improve\n",
            "Epoch 63/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4035 - categorical_accuracy: 0.8545 - val_loss: 0.4534 - val_categorical_accuracy: 0.8338\n",
            "\n",
            "Epoch 00063: val_loss did not improve\n",
            "Epoch 64/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.4586 - categorical_accuracy: 0.8298 - val_loss: 0.5526 - val_categorical_accuracy: 0.7881\n",
            "\n",
            "Epoch 00064: val_loss did not improve\n",
            "Epoch 65/500\n",
            "2000/6400 [========>.....................] - ETA: 0s - loss: 0.5091 - categorical_accuracy: 0.8035"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5653 - categorical_accuracy: 0.7792 - val_loss: 0.5058 - val_categorical_accuracy: 0.8144\n",
            "\n",
            "Epoch 00065: val_loss did not improve\n",
            "Epoch 66/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.4505 - categorical_accuracy: 0.8303 - val_loss: 0.5558 - val_categorical_accuracy: 0.7781\n",
            "\n",
            "Epoch 00066: val_loss did not improve\n",
            "Epoch 67/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.5775 - categorical_accuracy: 0.7803 - val_loss: 0.7039 - val_categorical_accuracy: 0.7262\n",
            "\n",
            "Epoch 00067: val_loss did not improve\n",
            "Epoch 68/500\n",
            "6400/6400 [==============================] - 1s 160us/step - loss: 0.5889 - categorical_accuracy: 0.7700 - val_loss: 0.6085 - val_categorical_accuracy: 0.7763\n",
            "\n",
            "Epoch 00068: val_loss did not improve\n",
            "Epoch 69/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.6048 - categorical_accuracy: 0.7873 - val_loss: 1.0996 - val_categorical_accuracy: 0.6081\n",
            "\n",
            "Epoch 00069: val_loss did not improve\n",
            "Epoch 70/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.7692 - categorical_accuracy: 0.7138 - val_loss: 0.4553 - val_categorical_accuracy: 0.8388\n",
            "\n",
            "Epoch 00070: val_loss did not improve\n",
            "Epoch 71/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3967 - categorical_accuracy: 0.8627 - val_loss: 0.4479 - val_categorical_accuracy: 0.8350\n",
            "\n",
            "Epoch 00071: val_loss did not improve\n",
            "Epoch 72/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4590 - categorical_accuracy: 0.8242 - val_loss: 0.5564 - val_categorical_accuracy: 0.7944\n",
            "\n",
            "Epoch 00072: val_loss did not improve\n",
            "Epoch 73/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4504 - categorical_accuracy: 0.8359 - val_loss: 0.6365 - val_categorical_accuracy: 0.7581\n",
            "\n",
            "Epoch 00073: val_loss did not improve\n",
            "Epoch 74/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5694 - categorical_accuracy: 0.7791 - val_loss: 0.6249 - val_categorical_accuracy: 0.7569\n",
            "\n",
            "Epoch 00074: val_loss did not improve\n",
            "Epoch 75/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5853 - categorical_accuracy: 0.7761 - val_loss: 0.7680 - val_categorical_accuracy: 0.7094\n",
            "\n",
            "Epoch 00075: val_loss did not improve\n",
            "Epoch 76/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.7876 - categorical_accuracy: 0.7152 - val_loss: 0.4777 - val_categorical_accuracy: 0.8194\n",
            "\n",
            "Epoch 00076: val_loss did not improve\n",
            "Epoch 77/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3949 - categorical_accuracy: 0.8644 - val_loss: 0.5332 - val_categorical_accuracy: 0.8000\n",
            "\n",
            "Epoch 00077: val_loss did not improve\n",
            "Epoch 78/500\n",
            "6000/6400 [===========================>..] - ETA: 0s - loss: 0.5511 - categorical_accuracy: 0.7995"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6400/6400 [==============================] - 1s 156us/step - loss: 0.5523 - categorical_accuracy: 0.7983 - val_loss: 0.6013 - val_categorical_accuracy: 0.7644\n",
            "\n",
            "Epoch 00078: val_loss did not improve\n",
            "Epoch 79/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5573 - categorical_accuracy: 0.7838 - val_loss: 0.4528 - val_categorical_accuracy: 0.8475\n",
            "\n",
            "Epoch 00079: val_loss did not improve\n",
            "Epoch 80/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4431 - categorical_accuracy: 0.8420 - val_loss: 0.5298 - val_categorical_accuracy: 0.8025\n",
            "\n",
            "Epoch 00080: val_loss did not improve\n",
            "Epoch 81/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4807 - categorical_accuracy: 0.8231 - val_loss: 1.0101 - val_categorical_accuracy: 0.6594\n",
            "\n",
            "Epoch 00081: val_loss did not improve\n",
            "Epoch 82/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.8919 - categorical_accuracy: 0.6881 - val_loss: 0.4695 - val_categorical_accuracy: 0.8363\n",
            "\n",
            "Epoch 00082: val_loss did not improve\n",
            "Epoch 83/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4037 - categorical_accuracy: 0.8647 - val_loss: 0.4739 - val_categorical_accuracy: 0.8175\n",
            "\n",
            "Epoch 00083: val_loss did not improve\n",
            "Epoch 84/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6015 - categorical_accuracy: 0.7770 - val_loss: 0.6218 - val_categorical_accuracy: 0.7731\n",
            "\n",
            "Epoch 00084: val_loss did not improve\n",
            "Epoch 85/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4698 - categorical_accuracy: 0.8347 - val_loss: 0.4169 - val_categorical_accuracy: 0.8475\n",
            "\n",
            "Epoch 00085: val_loss did not improve\n",
            "Epoch 86/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4124 - categorical_accuracy: 0.8503 - val_loss: 0.6091 - val_categorical_accuracy: 0.7644\n",
            "\n",
            "Epoch 00086: val_loss did not improve\n",
            "Epoch 87/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.6441 - categorical_accuracy: 0.7528 - val_loss: 0.6744 - val_categorical_accuracy: 0.7569\n",
            "\n",
            "Epoch 00087: val_loss did not improve\n",
            "Epoch 88/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.6112 - categorical_accuracy: 0.7683 - val_loss: 0.5452 - val_categorical_accuracy: 0.7994\n",
            "\n",
            "Epoch 00088: val_loss did not improve\n",
            "Epoch 89/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4714 - categorical_accuracy: 0.8280 - val_loss: 0.4044 - val_categorical_accuracy: 0.8594\n",
            "\n",
            "Epoch 00089: val_loss improved from 0.40966 to 0.40435, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 90/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.4287 - categorical_accuracy: 0.8434 - val_loss: 0.6957 - val_categorical_accuracy: 0.7350\n",
            "\n",
            "Epoch 00090: val_loss did not improve\n",
            "Epoch 91/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.7026 - categorical_accuracy: 0.7338 - val_loss: 0.6453 - val_categorical_accuracy: 0.7312\n",
            "\n",
            "Epoch 00091: val_loss did not improve\n",
            "Epoch 92/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5815 - categorical_accuracy: 0.7780 - val_loss: 0.6337 - val_categorical_accuracy: 0.7581\n",
            "\n",
            "Epoch 00092: val_loss did not improve\n",
            "Epoch 93/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5300 - categorical_accuracy: 0.8098 - val_loss: 0.5476 - val_categorical_accuracy: 0.7937\n",
            "\n",
            "Epoch 00093: val_loss did not improve\n",
            "Epoch 94/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4582 - categorical_accuracy: 0.8378 - val_loss: 0.4892 - val_categorical_accuracy: 0.8112\n",
            "\n",
            "Epoch 00094: val_loss did not improve\n",
            "Epoch 95/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5409 - categorical_accuracy: 0.7958 - val_loss: 0.4578 - val_categorical_accuracy: 0.8306\n",
            "\n",
            "Epoch 00095: val_loss did not improve\n",
            "Epoch 96/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4885 - categorical_accuracy: 0.8219 - val_loss: 1.0041 - val_categorical_accuracy: 0.6363\n",
            "\n",
            "Epoch 00096: val_loss did not improve\n",
            "Epoch 97/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.7437 - categorical_accuracy: 0.7333 - val_loss: 0.7733 - val_categorical_accuracy: 0.7106\n",
            "\n",
            "Epoch 00097: val_loss did not improve\n",
            "Epoch 98/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5961 - categorical_accuracy: 0.7748 - val_loss: 0.4356 - val_categorical_accuracy: 0.8450\n",
            "\n",
            "Epoch 00098: val_loss did not improve\n",
            "Epoch 99/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3889 - categorical_accuracy: 0.8623 - val_loss: 0.5602 - val_categorical_accuracy: 0.7994\n",
            "\n",
            "Epoch 00099: val_loss did not improve\n",
            "Epoch 100/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6338 - categorical_accuracy: 0.7781 - val_loss: 0.6097 - val_categorical_accuracy: 0.7700\n",
            "\n",
            "Epoch 00100: val_loss did not improve\n",
            "Epoch 101/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4949 - categorical_accuracy: 0.8253 - val_loss: 0.4216 - val_categorical_accuracy: 0.8431\n",
            "\n",
            "Epoch 00101: val_loss did not improve\n",
            "Epoch 102/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.4942 - categorical_accuracy: 0.8163 - val_loss: 0.6255 - val_categorical_accuracy: 0.7406\n",
            "\n",
            "Epoch 00102: val_loss did not improve\n",
            "Epoch 103/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.6174 - categorical_accuracy: 0.7586 - val_loss: 0.6109 - val_categorical_accuracy: 0.7606\n",
            "\n",
            "Epoch 00103: val_loss did not improve\n",
            "Epoch 104/500\n",
            "6000/6400 [===========================>..] - ETA: 0s - loss: 0.5375 - categorical_accuracy: 0.7920"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6400/6400 [==============================] - 1s 159us/step - loss: 0.5308 - categorical_accuracy: 0.7950 - val_loss: 0.3939 - val_categorical_accuracy: 0.8619\n",
            "\n",
            "Epoch 00104: val_loss improved from 0.40435 to 0.39389, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 105/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3578 - categorical_accuracy: 0.8809 - val_loss: 0.4819 - val_categorical_accuracy: 0.8175\n",
            "\n",
            "Epoch 00105: val_loss did not improve\n",
            "Epoch 106/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.5078 - categorical_accuracy: 0.8044 - val_loss: 0.4544 - val_categorical_accuracy: 0.8344\n",
            "\n",
            "Epoch 00106: val_loss did not improve\n",
            "Epoch 107/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.6290 - categorical_accuracy: 0.7633 - val_loss: 0.6568 - val_categorical_accuracy: 0.7531\n",
            "\n",
            "Epoch 00107: val_loss did not improve\n",
            "Epoch 108/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6249 - categorical_accuracy: 0.7719 - val_loss: 0.6978 - val_categorical_accuracy: 0.7312\n",
            "\n",
            "Epoch 00108: val_loss did not improve\n",
            "Epoch 109/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6371 - categorical_accuracy: 0.7584 - val_loss: 0.4290 - val_categorical_accuracy: 0.8494\n",
            "\n",
            "Epoch 00109: val_loss did not improve\n",
            "Epoch 110/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3857 - categorical_accuracy: 0.8672 - val_loss: 0.3986 - val_categorical_accuracy: 0.8537\n",
            "\n",
            "Epoch 00110: val_loss did not improve\n",
            "Epoch 111/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3589 - categorical_accuracy: 0.8755 - val_loss: 0.4651 - val_categorical_accuracy: 0.8263\n",
            "\n",
            "Epoch 00111: val_loss did not improve\n",
            "Epoch 112/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5198 - categorical_accuracy: 0.8006 - val_loss: 0.6660 - val_categorical_accuracy: 0.7500\n",
            "\n",
            "Epoch 00112: val_loss did not improve\n",
            "Epoch 113/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.7055 - categorical_accuracy: 0.7338 - val_loss: 0.8823 - val_categorical_accuracy: 0.7031\n",
            "\n",
            "Epoch 00113: val_loss did not improve\n",
            "Epoch 114/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.7167 - categorical_accuracy: 0.7369 - val_loss: 0.6544 - val_categorical_accuracy: 0.7744\n",
            "\n",
            "Epoch 00114: val_loss did not improve\n",
            "Epoch 115/500\n",
            "6400/6400 [==============================] - 1s 160us/step - loss: 0.4471 - categorical_accuracy: 0.8480 - val_loss: 0.4062 - val_categorical_accuracy: 0.8512\n",
            "\n",
            "Epoch 00115: val_loss did not improve\n",
            "Epoch 116/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.3629 - categorical_accuracy: 0.8753 - val_loss: 0.5483 - val_categorical_accuracy: 0.7944\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00116: val_loss did not improve\n",
            "Epoch 117/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.5063 - categorical_accuracy: 0.8102 - val_loss: 0.6702 - val_categorical_accuracy: 0.7644\n",
            "\n",
            "Epoch 00117: val_loss did not improve\n",
            "Epoch 118/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5857 - categorical_accuracy: 0.7866 - val_loss: 0.5120 - val_categorical_accuracy: 0.8238\n",
            "\n",
            "Epoch 00118: val_loss did not improve\n",
            "Epoch 119/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4615 - categorical_accuracy: 0.8291 - val_loss: 0.5641 - val_categorical_accuracy: 0.7912\n",
            "\n",
            "Epoch 00119: val_loss did not improve\n",
            "Epoch 120/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4604 - categorical_accuracy: 0.8289 - val_loss: 0.5583 - val_categorical_accuracy: 0.7887\n",
            "\n",
            "Epoch 00120: val_loss did not improve\n",
            "Epoch 121/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4638 - categorical_accuracy: 0.8330 - val_loss: 0.5669 - val_categorical_accuracy: 0.7681\n",
            "\n",
            "Epoch 00121: val_loss did not improve\n",
            "Epoch 122/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5778 - categorical_accuracy: 0.7823 - val_loss: 0.6338 - val_categorical_accuracy: 0.7581\n",
            "\n",
            "Epoch 00122: val_loss did not improve\n",
            "Epoch 123/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6062 - categorical_accuracy: 0.7762 - val_loss: 0.6435 - val_categorical_accuracy: 0.7613\n",
            "\n",
            "Epoch 00123: val_loss did not improve\n",
            "Epoch 124/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.6923 - categorical_accuracy: 0.7455 - val_loss: 0.5358 - val_categorical_accuracy: 0.7981\n",
            "\n",
            "Epoch 00124: val_loss did not improve\n",
            "Epoch 125/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4483 - categorical_accuracy: 0.8369 - val_loss: 0.4411 - val_categorical_accuracy: 0.8331\n",
            "\n",
            "Epoch 00125: val_loss did not improve\n",
            "Epoch 126/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4278 - categorical_accuracy: 0.8395 - val_loss: 0.7224 - val_categorical_accuracy: 0.7125\n",
            "\n",
            "Epoch 00126: val_loss did not improve\n",
            "Epoch 127/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.5560 - categorical_accuracy: 0.7916 - val_loss: 0.4436 - val_categorical_accuracy: 0.8469\n",
            "\n",
            "Epoch 00127: val_loss did not improve\n",
            "Epoch 128/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.4953 - categorical_accuracy: 0.8191 - val_loss: 0.6156 - val_categorical_accuracy: 0.7806\n",
            "\n",
            "Epoch 00128: val_loss did not improve\n",
            "Epoch 129/500\n",
            "6400/6400 [==============================] - 1s 161us/step - loss: 0.8180 - categorical_accuracy: 0.7197 - val_loss: 0.5494 - val_categorical_accuracy: 0.7956\n",
            "\n",
            "Epoch 00129: val_loss did not improve\n",
            "Epoch 130/500\n",
            "2000/6400 [========>.....................] - ETA: 0s - loss: 0.5481 - categorical_accuracy: 0.8055"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 160us/step - loss: 0.4323 - categorical_accuracy: 0.8441 - val_loss: 0.4224 - val_categorical_accuracy: 0.8438\n",
            "\n",
            "Epoch 00130: val_loss did not improve\n",
            "Epoch 131/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.3715 - categorical_accuracy: 0.8680 - val_loss: 0.4081 - val_categorical_accuracy: 0.8581\n",
            "\n",
            "Epoch 00131: val_loss did not improve\n",
            "Epoch 132/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.5731 - categorical_accuracy: 0.7833 - val_loss: 0.8019 - val_categorical_accuracy: 0.7106\n",
            "\n",
            "Epoch 00132: val_loss did not improve\n",
            "Epoch 133/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.8612 - categorical_accuracy: 0.6712 - val_loss: 0.5818 - val_categorical_accuracy: 0.7837\n",
            "\n",
            "Epoch 00133: val_loss did not improve\n",
            "Epoch 134/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4361 - categorical_accuracy: 0.8450 - val_loss: 0.4025 - val_categorical_accuracy: 0.8562\n",
            "\n",
            "Epoch 00134: val_loss did not improve\n",
            "Epoch 135/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3690 - categorical_accuracy: 0.8737 - val_loss: 0.5719 - val_categorical_accuracy: 0.7788\n",
            "\n",
            "Epoch 00135: val_loss did not improve\n",
            "Epoch 136/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.5205 - categorical_accuracy: 0.8081 - val_loss: 0.4732 - val_categorical_accuracy: 0.8238\n",
            "\n",
            "Epoch 00136: val_loss did not improve\n",
            "Epoch 137/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.4010 - categorical_accuracy: 0.8534 - val_loss: 0.5450 - val_categorical_accuracy: 0.8031\n",
            "\n",
            "Epoch 00137: val_loss did not improve\n",
            "Epoch 138/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.5731 - categorical_accuracy: 0.7813 - val_loss: 0.7793 - val_categorical_accuracy: 0.7000\n",
            "\n",
            "Epoch 00138: val_loss did not improve\n",
            "Epoch 139/500\n",
            "6400/6400 [==============================] - 1s 161us/step - loss: 0.6794 - categorical_accuracy: 0.7444 - val_loss: 0.5653 - val_categorical_accuracy: 0.7812\n",
            "\n",
            "Epoch 00139: val_loss did not improve\n",
            "Epoch 140/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.4636 - categorical_accuracy: 0.8269 - val_loss: 0.3994 - val_categorical_accuracy: 0.8656\n",
            "\n",
            "Epoch 00140: val_loss did not improve\n",
            "Epoch 141/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3584 - categorical_accuracy: 0.8716 - val_loss: 0.4093 - val_categorical_accuracy: 0.8512\n",
            "\n",
            "Epoch 00141: val_loss did not improve\n",
            "Epoch 142/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4214 - categorical_accuracy: 0.8391 - val_loss: 0.8071 - val_categorical_accuracy: 0.7125\n",
            "\n",
            "Epoch 00142: val_loss did not improve\n",
            "Epoch 143/500\n",
            "6000/6400 [===========================>..] - ETA: 0s - loss: 0.7120 - categorical_accuracy: 0.7475"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6400/6400 [==============================] - 1s 158us/step - loss: 0.7032 - categorical_accuracy: 0.7494 - val_loss: 0.6721 - val_categorical_accuracy: 0.7437\n",
            "\n",
            "Epoch 00143: val_loss did not improve\n",
            "Epoch 144/500\n",
            "6400/6400 [==============================] - 1s 155us/step - loss: 0.5832 - categorical_accuracy: 0.7831 - val_loss: 0.3703 - val_categorical_accuracy: 0.8694\n",
            "\n",
            "Epoch 00144: val_loss improved from 0.39389 to 0.37028, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 145/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3184 - categorical_accuracy: 0.8969 - val_loss: 0.3782 - val_categorical_accuracy: 0.8625\n",
            "\n",
            "Epoch 00145: val_loss did not improve\n",
            "Epoch 146/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.4451 - categorical_accuracy: 0.8381 - val_loss: 0.4640 - val_categorical_accuracy: 0.8219\n",
            "\n",
            "Epoch 00146: val_loss did not improve\n",
            "Epoch 147/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4493 - categorical_accuracy: 0.8312 - val_loss: 1.0368 - val_categorical_accuracy: 0.6250\n",
            "\n",
            "Epoch 00147: val_loss did not improve\n",
            "Epoch 148/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.8179 - categorical_accuracy: 0.7058 - val_loss: 0.4977 - val_categorical_accuracy: 0.8175\n",
            "\n",
            "Epoch 00148: val_loss did not improve\n",
            "Epoch 149/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4205 - categorical_accuracy: 0.8498 - val_loss: 0.6535 - val_categorical_accuracy: 0.7731\n",
            "\n",
            "Epoch 00149: val_loss did not improve\n",
            "Epoch 150/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.5803 - categorical_accuracy: 0.7922 - val_loss: 0.4134 - val_categorical_accuracy: 0.8531\n",
            "\n",
            "Epoch 00150: val_loss did not improve\n",
            "Epoch 151/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.3588 - categorical_accuracy: 0.8741 - val_loss: 0.5396 - val_categorical_accuracy: 0.7994\n",
            "\n",
            "Epoch 00151: val_loss did not improve\n",
            "Epoch 152/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.4470 - categorical_accuracy: 0.8344 - val_loss: 0.5518 - val_categorical_accuracy: 0.7887\n",
            "\n",
            "Epoch 00152: val_loss did not improve\n",
            "Epoch 153/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.5010 - categorical_accuracy: 0.8073 - val_loss: 0.5606 - val_categorical_accuracy: 0.7719\n",
            "\n",
            "Epoch 00153: val_loss did not improve\n",
            "Epoch 154/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5151 - categorical_accuracy: 0.7927 - val_loss: 0.4859 - val_categorical_accuracy: 0.8231\n",
            "\n",
            "Epoch 00154: val_loss did not improve\n",
            "Epoch 155/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.4714 - categorical_accuracy: 0.8294 - val_loss: 0.7671 - val_categorical_accuracy: 0.7294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00155: val_loss did not improve\n",
            "Epoch 156/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6185 - categorical_accuracy: 0.7841 - val_loss: 0.4191 - val_categorical_accuracy: 0.8519\n",
            "\n",
            "Epoch 00156: val_loss did not improve\n",
            "Epoch 157/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3945 - categorical_accuracy: 0.8520 - val_loss: 0.5723 - val_categorical_accuracy: 0.7875\n",
            "\n",
            "Epoch 00157: val_loss did not improve\n",
            "Epoch 158/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.6467 - categorical_accuracy: 0.7520 - val_loss: 0.6602 - val_categorical_accuracy: 0.7600\n",
            "\n",
            "Epoch 00158: val_loss did not improve\n",
            "Epoch 159/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4589 - categorical_accuracy: 0.8387 - val_loss: 0.4265 - val_categorical_accuracy: 0.8413\n",
            "\n",
            "Epoch 00159: val_loss did not improve\n",
            "Epoch 160/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5265 - categorical_accuracy: 0.8011 - val_loss: 0.4322 - val_categorical_accuracy: 0.8550\n",
            "\n",
            "Epoch 00160: val_loss did not improve\n",
            "Epoch 161/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3945 - categorical_accuracy: 0.8578 - val_loss: 0.5444 - val_categorical_accuracy: 0.7994\n",
            "\n",
            "Epoch 00161: val_loss did not improve\n",
            "Epoch 162/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4617 - categorical_accuracy: 0.8281 - val_loss: 0.4330 - val_categorical_accuracy: 0.8369\n",
            "\n",
            "Epoch 00162: val_loss did not improve\n",
            "Epoch 163/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5553 - categorical_accuracy: 0.7986 - val_loss: 0.6318 - val_categorical_accuracy: 0.7544\n",
            "\n",
            "Epoch 00163: val_loss did not improve\n",
            "Epoch 164/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4812 - categorical_accuracy: 0.8172 - val_loss: 0.3732 - val_categorical_accuracy: 0.8625\n",
            "\n",
            "Epoch 00164: val_loss did not improve\n",
            "Epoch 165/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3861 - categorical_accuracy: 0.8536 - val_loss: 0.5426 - val_categorical_accuracy: 0.7900\n",
            "\n",
            "Epoch 00165: val_loss did not improve\n",
            "Epoch 166/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4470 - categorical_accuracy: 0.8416 - val_loss: 0.3857 - val_categorical_accuracy: 0.8606\n",
            "\n",
            "Epoch 00166: val_loss did not improve\n",
            "Epoch 167/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4761 - categorical_accuracy: 0.8381 - val_loss: 0.5021 - val_categorical_accuracy: 0.8163\n",
            "\n",
            "Epoch 00167: val_loss did not improve\n",
            "Epoch 168/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5075 - categorical_accuracy: 0.8055 - val_loss: 0.8685 - val_categorical_accuracy: 0.6806\n",
            "\n",
            "Epoch 00168: val_loss did not improve\n",
            "Epoch 169/500\n",
            "2000/6400 [========>.....................] - ETA: 0s - loss: 0.8489 - categorical_accuracy: 0.6860"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5893 - categorical_accuracy: 0.7812 - val_loss: 0.5576 - val_categorical_accuracy: 0.7856\n",
            "\n",
            "Epoch 00169: val_loss did not improve\n",
            "Epoch 170/500\n",
            "6400/6400 [==============================] - 1s 155us/step - loss: 0.4947 - categorical_accuracy: 0.8141 - val_loss: 0.5412 - val_categorical_accuracy: 0.7975\n",
            "\n",
            "Epoch 00170: val_loss did not improve\n",
            "Epoch 171/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4596 - categorical_accuracy: 0.8294 - val_loss: 0.4061 - val_categorical_accuracy: 0.8494\n",
            "\n",
            "Epoch 00171: val_loss did not improve\n",
            "Epoch 172/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4621 - categorical_accuracy: 0.8331 - val_loss: 0.5860 - val_categorical_accuracy: 0.7763\n",
            "\n",
            "Epoch 00172: val_loss did not improve\n",
            "Epoch 173/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5304 - categorical_accuracy: 0.8142 - val_loss: 0.4738 - val_categorical_accuracy: 0.8194\n",
            "\n",
            "Epoch 00173: val_loss did not improve\n",
            "Epoch 174/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3967 - categorical_accuracy: 0.8547 - val_loss: 0.6402 - val_categorical_accuracy: 0.7544\n",
            "\n",
            "Epoch 00174: val_loss did not improve\n",
            "Epoch 175/500\n",
            "6400/6400 [==============================] - 1s 155us/step - loss: 0.5397 - categorical_accuracy: 0.7944 - val_loss: 0.6716 - val_categorical_accuracy: 0.7394\n",
            "\n",
            "Epoch 00175: val_loss did not improve\n",
            "Epoch 176/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.7300 - categorical_accuracy: 0.7269 - val_loss: 0.4523 - val_categorical_accuracy: 0.8356\n",
            "\n",
            "Epoch 00176: val_loss did not improve\n",
            "Epoch 177/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3693 - categorical_accuracy: 0.8745 - val_loss: 0.3464 - val_categorical_accuracy: 0.8819\n",
            "\n",
            "Epoch 00177: val_loss improved from 0.37028 to 0.34643, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 178/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3042 - categorical_accuracy: 0.8977 - val_loss: 0.4679 - val_categorical_accuracy: 0.8269\n",
            "\n",
            "Epoch 00178: val_loss did not improve\n",
            "Epoch 179/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4725 - categorical_accuracy: 0.8186 - val_loss: 0.6569 - val_categorical_accuracy: 0.7475\n",
            "\n",
            "Epoch 00179: val_loss did not improve\n",
            "Epoch 180/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6197 - categorical_accuracy: 0.7600 - val_loss: 0.8577 - val_categorical_accuracy: 0.7262\n",
            "\n",
            "Epoch 00180: val_loss did not improve\n",
            "Epoch 181/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.6121 - categorical_accuracy: 0.7792 - val_loss: 0.4986 - val_categorical_accuracy: 0.8163\n",
            "\n",
            "Epoch 00181: val_loss did not improve\n",
            "Epoch 182/500\n",
            "2000/6400 [========>.....................] - ETA: 0s - loss: 0.4680 - categorical_accuracy: 0.8260"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4335 - categorical_accuracy: 0.8455 - val_loss: 0.6695 - val_categorical_accuracy: 0.7494\n",
            "\n",
            "Epoch 00182: val_loss did not improve\n",
            "Epoch 183/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4555 - categorical_accuracy: 0.8373 - val_loss: 0.3505 - val_categorical_accuracy: 0.8725\n",
            "\n",
            "Epoch 00183: val_loss did not improve\n",
            "Epoch 184/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3109 - categorical_accuracy: 0.8941 - val_loss: 0.5330 - val_categorical_accuracy: 0.7925\n",
            "\n",
            "Epoch 00184: val_loss did not improve\n",
            "Epoch 185/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5876 - categorical_accuracy: 0.7730 - val_loss: 0.4857 - val_categorical_accuracy: 0.8112\n",
            "\n",
            "Epoch 00185: val_loss did not improve\n",
            "Epoch 186/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.6229 - categorical_accuracy: 0.7702 - val_loss: 0.4419 - val_categorical_accuracy: 0.8413\n",
            "\n",
            "Epoch 00186: val_loss did not improve\n",
            "Epoch 187/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3995 - categorical_accuracy: 0.8467 - val_loss: 0.4543 - val_categorical_accuracy: 0.8344\n",
            "\n",
            "Epoch 00187: val_loss did not improve\n",
            "Epoch 188/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3725 - categorical_accuracy: 0.8644 - val_loss: 0.3651 - val_categorical_accuracy: 0.8681\n",
            "\n",
            "Epoch 00188: val_loss did not improve\n",
            "Epoch 189/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3276 - categorical_accuracy: 0.8866 - val_loss: 0.6468 - val_categorical_accuracy: 0.7594\n",
            "\n",
            "Epoch 00189: val_loss did not improve\n",
            "Epoch 190/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5088 - categorical_accuracy: 0.8077 - val_loss: 0.6225 - val_categorical_accuracy: 0.7437\n",
            "\n",
            "Epoch 00190: val_loss did not improve\n",
            "Epoch 191/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6051 - categorical_accuracy: 0.7645 - val_loss: 0.5893 - val_categorical_accuracy: 0.7906\n",
            "\n",
            "Epoch 00191: val_loss did not improve\n",
            "Epoch 192/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4423 - categorical_accuracy: 0.8417 - val_loss: 0.5872 - val_categorical_accuracy: 0.7744\n",
            "\n",
            "Epoch 00192: val_loss did not improve\n",
            "Epoch 193/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5990 - categorical_accuracy: 0.7780 - val_loss: 0.6577 - val_categorical_accuracy: 0.7769\n",
            "\n",
            "Epoch 00193: val_loss did not improve\n",
            "Epoch 194/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4430 - categorical_accuracy: 0.8419 - val_loss: 0.3614 - val_categorical_accuracy: 0.8656\n",
            "\n",
            "Epoch 00194: val_loss did not improve\n",
            "Epoch 195/500\n",
            "6000/6400 [===========================>..] - ETA: 0s - loss: 0.3401 - categorical_accuracy: 0.8772"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6400/6400 [==============================] - 1s 157us/step - loss: 0.3532 - categorical_accuracy: 0.8716 - val_loss: 0.5599 - val_categorical_accuracy: 0.7844\n",
            "\n",
            "Epoch 00195: val_loss did not improve\n",
            "Epoch 196/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4383 - categorical_accuracy: 0.8383 - val_loss: 0.4430 - val_categorical_accuracy: 0.8294\n",
            "\n",
            "Epoch 00196: val_loss did not improve\n",
            "Epoch 197/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5571 - categorical_accuracy: 0.7894 - val_loss: 0.6366 - val_categorical_accuracy: 0.7650\n",
            "\n",
            "Epoch 00197: val_loss did not improve\n",
            "Epoch 198/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.6033 - categorical_accuracy: 0.7802 - val_loss: 0.4859 - val_categorical_accuracy: 0.8087\n",
            "\n",
            "Epoch 00198: val_loss did not improve\n",
            "Epoch 199/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3920 - categorical_accuracy: 0.8566 - val_loss: 0.3721 - val_categorical_accuracy: 0.8687\n",
            "\n",
            "Epoch 00199: val_loss did not improve\n",
            "Epoch 200/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3373 - categorical_accuracy: 0.8775 - val_loss: 0.4169 - val_categorical_accuracy: 0.8400\n",
            "\n",
            "Epoch 00200: val_loss did not improve\n",
            "Epoch 201/500\n",
            "6400/6400 [==============================] - 1s 155us/step - loss: 0.4229 - categorical_accuracy: 0.8358 - val_loss: 0.8993 - val_categorical_accuracy: 0.7138\n",
            "\n",
            "Epoch 00201: val_loss did not improve\n",
            "Epoch 202/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.9730 - categorical_accuracy: 0.6730 - val_loss: 0.5608 - val_categorical_accuracy: 0.7806\n",
            "\n",
            "Epoch 00202: val_loss did not improve\n",
            "Epoch 203/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4044 - categorical_accuracy: 0.8550 - val_loss: 0.3732 - val_categorical_accuracy: 0.8656\n",
            "\n",
            "Epoch 00203: val_loss did not improve\n",
            "Epoch 204/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3096 - categorical_accuracy: 0.8938 - val_loss: 0.4854 - val_categorical_accuracy: 0.8081\n",
            "\n",
            "Epoch 00204: val_loss did not improve\n",
            "Epoch 205/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3865 - categorical_accuracy: 0.8545 - val_loss: 0.7135 - val_categorical_accuracy: 0.7575\n",
            "\n",
            "Epoch 00205: val_loss did not improve\n",
            "Epoch 206/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.7312 - categorical_accuracy: 0.7531 - val_loss: 0.5043 - val_categorical_accuracy: 0.8050\n",
            "\n",
            "Epoch 00206: val_loss did not improve\n",
            "Epoch 207/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4035 - categorical_accuracy: 0.8503 - val_loss: 0.4046 - val_categorical_accuracy: 0.8506\n",
            "\n",
            "Epoch 00207: val_loss did not improve\n",
            "Epoch 208/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3892 - categorical_accuracy: 0.8594 - val_loss: 0.4914 - val_categorical_accuracy: 0.8188\n",
            "\n",
            "Epoch 00208: val_loss did not improve\n",
            "Epoch 209/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4340 - categorical_accuracy: 0.8412 - val_loss: 0.5120 - val_categorical_accuracy: 0.8087\n",
            "\n",
            "Epoch 00209: val_loss did not improve\n",
            "Epoch 210/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4204 - categorical_accuracy: 0.8452 - val_loss: 0.4260 - val_categorical_accuracy: 0.8363\n",
            "\n",
            "Epoch 00210: val_loss did not improve\n",
            "Epoch 211/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5323 - categorical_accuracy: 0.7972 - val_loss: 0.6331 - val_categorical_accuracy: 0.7713\n",
            "\n",
            "Epoch 00211: val_loss did not improve\n",
            "Epoch 212/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5425 - categorical_accuracy: 0.8003 - val_loss: 0.4136 - val_categorical_accuracy: 0.8494\n",
            "\n",
            "Epoch 00212: val_loss did not improve\n",
            "Epoch 213/500\n",
            "6400/6400 [==============================] - 1s 155us/step - loss: 0.3963 - categorical_accuracy: 0.8530 - val_loss: 0.6201 - val_categorical_accuracy: 0.7756\n",
            "\n",
            "Epoch 00213: val_loss did not improve\n",
            "Epoch 214/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4949 - categorical_accuracy: 0.8156 - val_loss: 0.4988 - val_categorical_accuracy: 0.8250\n",
            "\n",
            "Epoch 00214: val_loss did not improve\n",
            "Epoch 215/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4116 - categorical_accuracy: 0.8439 - val_loss: 0.3696 - val_categorical_accuracy: 0.8644\n",
            "\n",
            "Epoch 00215: val_loss did not improve\n",
            "Epoch 216/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4552 - categorical_accuracy: 0.8417 - val_loss: 0.6275 - val_categorical_accuracy: 0.7775\n",
            "\n",
            "Epoch 00216: val_loss did not improve\n",
            "Epoch 217/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4685 - categorical_accuracy: 0.8292 - val_loss: 0.4907 - val_categorical_accuracy: 0.8138\n",
            "\n",
            "Epoch 00217: val_loss did not improve\n",
            "Epoch 218/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4677 - categorical_accuracy: 0.8208 - val_loss: 0.6848 - val_categorical_accuracy: 0.7369\n",
            "\n",
            "Epoch 00218: val_loss did not improve\n",
            "Epoch 219/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5606 - categorical_accuracy: 0.7873 - val_loss: 0.4229 - val_categorical_accuracy: 0.8394\n",
            "\n",
            "Epoch 00219: val_loss did not improve\n",
            "Epoch 220/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3123 - categorical_accuracy: 0.8894 - val_loss: 0.3481 - val_categorical_accuracy: 0.8706\n",
            "\n",
            "Epoch 00220: val_loss did not improve\n",
            "Epoch 221/500\n",
            "6000/6400 [===========================>..] - ETA: 0s - loss: 0.3148 - categorical_accuracy: 0.8895"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6400/6400 [==============================] - 1s 156us/step - loss: 0.3217 - categorical_accuracy: 0.8850 - val_loss: 0.5433 - val_categorical_accuracy: 0.8012\n",
            "\n",
            "Epoch 00221: val_loss did not improve\n",
            "Epoch 222/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4895 - categorical_accuracy: 0.8159 - val_loss: 0.9048 - val_categorical_accuracy: 0.6994\n",
            "\n",
            "Epoch 00222: val_loss did not improve\n",
            "Epoch 223/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.8864 - categorical_accuracy: 0.7117 - val_loss: 0.4131 - val_categorical_accuracy: 0.8494\n",
            "\n",
            "Epoch 00223: val_loss did not improve\n",
            "Epoch 224/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3326 - categorical_accuracy: 0.8827 - val_loss: 0.4198 - val_categorical_accuracy: 0.8413\n",
            "\n",
            "Epoch 00224: val_loss did not improve\n",
            "Epoch 225/500\n",
            "6400/6400 [==============================] - 1s 155us/step - loss: 0.4117 - categorical_accuracy: 0.8423 - val_loss: 0.3378 - val_categorical_accuracy: 0.8750\n",
            "\n",
            "Epoch 00225: val_loss improved from 0.34643 to 0.33778, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 226/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2967 - categorical_accuracy: 0.8986 - val_loss: 0.6562 - val_categorical_accuracy: 0.7412\n",
            "\n",
            "Epoch 00226: val_loss did not improve\n",
            "Epoch 227/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5496 - categorical_accuracy: 0.7895 - val_loss: 0.5216 - val_categorical_accuracy: 0.7881\n",
            "\n",
            "Epoch 00227: val_loss did not improve\n",
            "Epoch 228/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4695 - categorical_accuracy: 0.8197 - val_loss: 0.5343 - val_categorical_accuracy: 0.8125\n",
            "\n",
            "Epoch 00228: val_loss did not improve\n",
            "Epoch 229/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5207 - categorical_accuracy: 0.8213 - val_loss: 0.6611 - val_categorical_accuracy: 0.7706\n",
            "\n",
            "Epoch 00229: val_loss did not improve\n",
            "Epoch 230/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6636 - categorical_accuracy: 0.7620 - val_loss: 0.3565 - val_categorical_accuracy: 0.8731\n",
            "\n",
            "Epoch 00230: val_loss did not improve\n",
            "Epoch 231/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3346 - categorical_accuracy: 0.8850 - val_loss: 0.4978 - val_categorical_accuracy: 0.8125\n",
            "\n",
            "Epoch 00231: val_loss did not improve\n",
            "Epoch 232/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4242 - categorical_accuracy: 0.8377 - val_loss: 0.3837 - val_categorical_accuracy: 0.8531\n",
            "\n",
            "Epoch 00232: val_loss did not improve\n",
            "Epoch 233/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3772 - categorical_accuracy: 0.8622 - val_loss: 0.6156 - val_categorical_accuracy: 0.7731\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00233: val_loss did not improve\n",
            "Epoch 234/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6034 - categorical_accuracy: 0.7706 - val_loss: 0.5330 - val_categorical_accuracy: 0.7937\n",
            "\n",
            "Epoch 00234: val_loss did not improve\n",
            "Epoch 235/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4557 - categorical_accuracy: 0.8273 - val_loss: 0.4128 - val_categorical_accuracy: 0.8400\n",
            "\n",
            "Epoch 00235: val_loss did not improve\n",
            "Epoch 236/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3328 - categorical_accuracy: 0.8777 - val_loss: 0.4445 - val_categorical_accuracy: 0.8331\n",
            "\n",
            "Epoch 00236: val_loss did not improve\n",
            "Epoch 237/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3436 - categorical_accuracy: 0.8706 - val_loss: 0.8254 - val_categorical_accuracy: 0.7081\n",
            "\n",
            "Epoch 00237: val_loss did not improve\n",
            "Epoch 238/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.8044 - categorical_accuracy: 0.7327 - val_loss: 0.7601 - val_categorical_accuracy: 0.7225\n",
            "\n",
            "Epoch 00238: val_loss did not improve\n",
            "Epoch 239/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5643 - categorical_accuracy: 0.7881 - val_loss: 0.4347 - val_categorical_accuracy: 0.8419\n",
            "\n",
            "Epoch 00239: val_loss did not improve\n",
            "Epoch 240/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3438 - categorical_accuracy: 0.8750 - val_loss: 0.3260 - val_categorical_accuracy: 0.8813\n",
            "\n",
            "Epoch 00240: val_loss improved from 0.33778 to 0.32596, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 241/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2653 - categorical_accuracy: 0.9098 - val_loss: 0.3731 - val_categorical_accuracy: 0.8675\n",
            "\n",
            "Epoch 00241: val_loss did not improve\n",
            "Epoch 242/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4714 - categorical_accuracy: 0.8391 - val_loss: 0.6493 - val_categorical_accuracy: 0.7437\n",
            "\n",
            "Epoch 00242: val_loss did not improve\n",
            "Epoch 243/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5421 - categorical_accuracy: 0.7892 - val_loss: 0.5394 - val_categorical_accuracy: 0.7956\n",
            "\n",
            "Epoch 00243: val_loss did not improve\n",
            "Epoch 244/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.4704 - categorical_accuracy: 0.8156 - val_loss: 0.6763 - val_categorical_accuracy: 0.7588\n",
            "\n",
            "Epoch 00244: val_loss did not improve\n",
            "Epoch 245/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5339 - categorical_accuracy: 0.8066 - val_loss: 0.4083 - val_categorical_accuracy: 0.8562\n",
            "\n",
            "Epoch 00245: val_loss did not improve\n",
            "Epoch 246/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.3016 - categorical_accuracy: 0.8948 - val_loss: 0.3832 - val_categorical_accuracy: 0.8606\n",
            "\n",
            "Epoch 00246: val_loss did not improve\n",
            "Epoch 247/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.3684 - categorical_accuracy: 0.8675 - val_loss: 0.7013 - val_categorical_accuracy: 0.7456\n",
            "\n",
            "Epoch 00247: val_loss did not improve\n",
            "Epoch 248/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.5849 - categorical_accuracy: 0.7769 - val_loss: 0.4487 - val_categorical_accuracy: 0.8325\n",
            "\n",
            "Epoch 00248: val_loss did not improve\n",
            "Epoch 249/500\n",
            "6400/6400 [==============================] - 1s 160us/step - loss: 0.5367 - categorical_accuracy: 0.7973 - val_loss: 0.5083 - val_categorical_accuracy: 0.8156\n",
            "\n",
            "Epoch 00249: val_loss did not improve\n",
            "Epoch 250/500\n",
            "6400/6400 [==============================] - 1s 161us/step - loss: 0.3867 - categorical_accuracy: 0.8634 - val_loss: 0.3709 - val_categorical_accuracy: 0.8694\n",
            "\n",
            "Epoch 00250: val_loss did not improve\n",
            "Epoch 251/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3245 - categorical_accuracy: 0.8845 - val_loss: 0.4423 - val_categorical_accuracy: 0.8363\n",
            "\n",
            "Epoch 00251: val_loss did not improve\n",
            "Epoch 252/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.4330 - categorical_accuracy: 0.8345 - val_loss: 0.5294 - val_categorical_accuracy: 0.8019\n",
            "\n",
            "Epoch 00252: val_loss did not improve\n",
            "Epoch 253/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.6596 - categorical_accuracy: 0.7698 - val_loss: 1.0104 - val_categorical_accuracy: 0.7063\n",
            "\n",
            "Epoch 00253: val_loss did not improve\n",
            "Epoch 254/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5106 - categorical_accuracy: 0.8330 - val_loss: 0.3462 - val_categorical_accuracy: 0.8706\n",
            "\n",
            "Epoch 00254: val_loss did not improve\n",
            "Epoch 255/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2836 - categorical_accuracy: 0.9031 - val_loss: 0.3924 - val_categorical_accuracy: 0.8575\n",
            "\n",
            "Epoch 00255: val_loss did not improve\n",
            "Epoch 256/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5751 - categorical_accuracy: 0.7938 - val_loss: 0.5140 - val_categorical_accuracy: 0.8138\n",
            "\n",
            "Epoch 00256: val_loss did not improve\n",
            "Epoch 257/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4939 - categorical_accuracy: 0.8062 - val_loss: 0.3740 - val_categorical_accuracy: 0.8681\n",
            "\n",
            "Epoch 00257: val_loss did not improve\n",
            "Epoch 258/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3097 - categorical_accuracy: 0.8950 - val_loss: 0.4419 - val_categorical_accuracy: 0.8425\n",
            "\n",
            "Epoch 00258: val_loss did not improve\n",
            "Epoch 259/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4124 - categorical_accuracy: 0.8488 - val_loss: 0.4570 - val_categorical_accuracy: 0.8231\n",
            "\n",
            "Epoch 00259: val_loss did not improve\n",
            "Epoch 260/500\n",
            "6000/6400 [===========================>..] - ETA: 0s - loss: 0.4039 - categorical_accuracy: 0.8462"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6400/6400 [==============================] - 1s 157us/step - loss: 0.4094 - categorical_accuracy: 0.8431 - val_loss: 0.6295 - val_categorical_accuracy: 0.7731\n",
            "\n",
            "Epoch 00260: val_loss did not improve\n",
            "Epoch 261/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5527 - categorical_accuracy: 0.7950 - val_loss: 0.4296 - val_categorical_accuracy: 0.8331\n",
            "\n",
            "Epoch 00261: val_loss did not improve\n",
            "Epoch 262/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3090 - categorical_accuracy: 0.8898 - val_loss: 0.3505 - val_categorical_accuracy: 0.8694\n",
            "\n",
            "Epoch 00262: val_loss did not improve\n",
            "Epoch 263/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3767 - categorical_accuracy: 0.8641 - val_loss: 0.6438 - val_categorical_accuracy: 0.7638\n",
            "\n",
            "Epoch 00263: val_loss did not improve\n",
            "Epoch 264/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3920 - categorical_accuracy: 0.8598 - val_loss: 0.4633 - val_categorical_accuracy: 0.8250\n",
            "\n",
            "Epoch 00264: val_loss did not improve\n",
            "Epoch 265/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5311 - categorical_accuracy: 0.8036 - val_loss: 0.3552 - val_categorical_accuracy: 0.8650\n",
            "\n",
            "Epoch 00265: val_loss did not improve\n",
            "Epoch 266/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4591 - categorical_accuracy: 0.8334 - val_loss: 0.6487 - val_categorical_accuracy: 0.7731\n",
            "\n",
            "Epoch 00266: val_loss did not improve\n",
            "Epoch 267/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4518 - categorical_accuracy: 0.8328 - val_loss: 0.4173 - val_categorical_accuracy: 0.8475\n",
            "\n",
            "Epoch 00267: val_loss did not improve\n",
            "Epoch 268/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3390 - categorical_accuracy: 0.8738 - val_loss: 0.4782 - val_categorical_accuracy: 0.8163\n",
            "\n",
            "Epoch 00268: val_loss did not improve\n",
            "Epoch 269/500\n",
            "6400/6400 [==============================] - 1s 155us/step - loss: 0.4656 - categorical_accuracy: 0.8247 - val_loss: 0.4117 - val_categorical_accuracy: 0.8519\n",
            "\n",
            "Epoch 00269: val_loss did not improve\n",
            "Epoch 270/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3739 - categorical_accuracy: 0.8594 - val_loss: 0.5557 - val_categorical_accuracy: 0.7875\n",
            "\n",
            "Epoch 00270: val_loss did not improve\n",
            "Epoch 271/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5065 - categorical_accuracy: 0.8056 - val_loss: 0.7176 - val_categorical_accuracy: 0.7400\n",
            "\n",
            "Epoch 00271: val_loss did not improve\n",
            "Epoch 272/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.7002 - categorical_accuracy: 0.7575 - val_loss: 0.3666 - val_categorical_accuracy: 0.8656\n",
            "\n",
            "Epoch 00272: val_loss did not improve\n",
            "Epoch 273/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2860 - categorical_accuracy: 0.9014 - val_loss: 0.4526 - val_categorical_accuracy: 0.8338\n",
            "\n",
            "Epoch 00273: val_loss did not improve\n",
            "Epoch 274/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4580 - categorical_accuracy: 0.8342 - val_loss: 0.5297 - val_categorical_accuracy: 0.8069\n",
            "\n",
            "Epoch 00274: val_loss did not improve\n",
            "Epoch 275/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3747 - categorical_accuracy: 0.8636 - val_loss: 0.4081 - val_categorical_accuracy: 0.8450\n",
            "\n",
            "Epoch 00275: val_loss did not improve\n",
            "Epoch 276/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3963 - categorical_accuracy: 0.8511 - val_loss: 0.3352 - val_categorical_accuracy: 0.8819\n",
            "\n",
            "Epoch 00276: val_loss did not improve\n",
            "Epoch 277/500\n",
            "6400/6400 [==============================] - 1s 155us/step - loss: 0.3232 - categorical_accuracy: 0.8806 - val_loss: 0.8363 - val_categorical_accuracy: 0.6875\n",
            "\n",
            "Epoch 00277: val_loss did not improve\n",
            "Epoch 278/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.6568 - categorical_accuracy: 0.7544 - val_loss: 0.7598 - val_categorical_accuracy: 0.7344\n",
            "\n",
            "Epoch 00278: val_loss did not improve\n",
            "Epoch 279/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4818 - categorical_accuracy: 0.8308 - val_loss: 0.5577 - val_categorical_accuracy: 0.7987\n",
            "\n",
            "Epoch 00279: val_loss did not improve\n",
            "Epoch 280/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4186 - categorical_accuracy: 0.8502 - val_loss: 0.4139 - val_categorical_accuracy: 0.8431\n",
            "\n",
            "Epoch 00280: val_loss did not improve\n",
            "Epoch 281/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3736 - categorical_accuracy: 0.8600 - val_loss: 0.3178 - val_categorical_accuracy: 0.8800\n",
            "\n",
            "Epoch 00281: val_loss improved from 0.32596 to 0.31778, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 282/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.2613 - categorical_accuracy: 0.9109 - val_loss: 0.5569 - val_categorical_accuracy: 0.7912\n",
            "\n",
            "Epoch 00282: val_loss did not improve\n",
            "Epoch 283/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5286 - categorical_accuracy: 0.7986 - val_loss: 0.4579 - val_categorical_accuracy: 0.8200\n",
            "\n",
            "Epoch 00283: val_loss did not improve\n",
            "Epoch 284/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4990 - categorical_accuracy: 0.8025 - val_loss: 1.0213 - val_categorical_accuracy: 0.6806\n",
            "\n",
            "Epoch 00284: val_loss did not improve\n",
            "Epoch 285/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.7344 - categorical_accuracy: 0.7438 - val_loss: 0.5600 - val_categorical_accuracy: 0.7950\n",
            "\n",
            "Epoch 00285: val_loss did not improve\n",
            "Epoch 286/500\n",
            "2000/6400 [========>.....................] - ETA: 0s - loss: 0.4985 - categorical_accuracy: 0.8045"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3850 - categorical_accuracy: 0.8617 - val_loss: 0.3477 - val_categorical_accuracy: 0.8744\n",
            "\n",
            "Epoch 00286: val_loss did not improve\n",
            "Epoch 287/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2696 - categorical_accuracy: 0.9102 - val_loss: 0.3241 - val_categorical_accuracy: 0.8856\n",
            "\n",
            "Epoch 00287: val_loss did not improve\n",
            "Epoch 288/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3158 - categorical_accuracy: 0.8836 - val_loss: 0.5298 - val_categorical_accuracy: 0.8044\n",
            "\n",
            "Epoch 00288: val_loss did not improve\n",
            "Epoch 289/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.4491 - categorical_accuracy: 0.8264 - val_loss: 0.5672 - val_categorical_accuracy: 0.7962\n",
            "\n",
            "Epoch 00289: val_loss did not improve\n",
            "Epoch 290/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3428 - categorical_accuracy: 0.8811 - val_loss: 0.4892 - val_categorical_accuracy: 0.8225\n",
            "\n",
            "Epoch 00290: val_loss did not improve\n",
            "Epoch 291/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5673 - categorical_accuracy: 0.7928 - val_loss: 0.5643 - val_categorical_accuracy: 0.7950\n",
            "\n",
            "Epoch 00291: val_loss did not improve\n",
            "Epoch 292/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.4147 - categorical_accuracy: 0.8480 - val_loss: 0.4740 - val_categorical_accuracy: 0.8106\n",
            "\n",
            "Epoch 00292: val_loss did not improve\n",
            "Epoch 293/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.3819 - categorical_accuracy: 0.8589 - val_loss: 0.4241 - val_categorical_accuracy: 0.8419\n",
            "\n",
            "Epoch 00293: val_loss did not improve\n",
            "Epoch 294/500\n",
            "6400/6400 [==============================] - 1s 160us/step - loss: 0.4887 - categorical_accuracy: 0.8202 - val_loss: 0.4358 - val_categorical_accuracy: 0.8394\n",
            "\n",
            "Epoch 00294: val_loss did not improve\n",
            "Epoch 295/500\n",
            "6400/6400 [==============================] - 1s 160us/step - loss: 0.4389 - categorical_accuracy: 0.8316 - val_loss: 0.6895 - val_categorical_accuracy: 0.7544\n",
            "\n",
            "Epoch 00295: val_loss did not improve\n",
            "Epoch 296/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.4684 - categorical_accuracy: 0.8298 - val_loss: 0.4105 - val_categorical_accuracy: 0.8481\n",
            "\n",
            "Epoch 00296: val_loss did not improve\n",
            "Epoch 297/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3876 - categorical_accuracy: 0.8578 - val_loss: 0.4223 - val_categorical_accuracy: 0.8438\n",
            "\n",
            "Epoch 00297: val_loss did not improve\n",
            "Epoch 298/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3413 - categorical_accuracy: 0.8764 - val_loss: 0.5063 - val_categorical_accuracy: 0.8256\n",
            "\n",
            "Epoch 00298: val_loss did not improve\n",
            "Epoch 299/500\n",
            "6000/6400 [===========================>..] - ETA: 0s - loss: 0.7316 - categorical_accuracy: 0.7545"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6400/6400 [==============================] - 1s 156us/step - loss: 0.7171 - categorical_accuracy: 0.7578 - val_loss: 0.5545 - val_categorical_accuracy: 0.7975\n",
            "\n",
            "Epoch 00299: val_loss did not improve\n",
            "Epoch 300/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3729 - categorical_accuracy: 0.8730 - val_loss: 0.4669 - val_categorical_accuracy: 0.8244\n",
            "\n",
            "Epoch 00300: val_loss did not improve\n",
            "Epoch 301/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.3545 - categorical_accuracy: 0.8686 - val_loss: 0.5401 - val_categorical_accuracy: 0.8031\n",
            "\n",
            "Epoch 00301: val_loss did not improve\n",
            "Epoch 302/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5305 - categorical_accuracy: 0.8103 - val_loss: 0.6046 - val_categorical_accuracy: 0.7763\n",
            "\n",
            "Epoch 00302: val_loss did not improve\n",
            "Epoch 303/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4301 - categorical_accuracy: 0.8448 - val_loss: 0.3428 - val_categorical_accuracy: 0.8844\n",
            "\n",
            "Epoch 00303: val_loss did not improve\n",
            "Epoch 304/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2562 - categorical_accuracy: 0.9166 - val_loss: 0.3587 - val_categorical_accuracy: 0.8675\n",
            "\n",
            "Epoch 00304: val_loss did not improve\n",
            "Epoch 305/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4385 - categorical_accuracy: 0.8425 - val_loss: 0.5698 - val_categorical_accuracy: 0.8006\n",
            "\n",
            "Epoch 00305: val_loss did not improve\n",
            "Epoch 306/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4558 - categorical_accuracy: 0.8311 - val_loss: 0.4688 - val_categorical_accuracy: 0.8188\n",
            "\n",
            "Epoch 00306: val_loss did not improve\n",
            "Epoch 307/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4169 - categorical_accuracy: 0.8378 - val_loss: 0.3161 - val_categorical_accuracy: 0.8825\n",
            "\n",
            "Epoch 00307: val_loss improved from 0.31778 to 0.31610, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 308/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.2928 - categorical_accuracy: 0.8972 - val_loss: 0.7586 - val_categorical_accuracy: 0.7744\n",
            "\n",
            "Epoch 00308: val_loss did not improve\n",
            "Epoch 309/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.8167 - categorical_accuracy: 0.7286 - val_loss: 0.5932 - val_categorical_accuracy: 0.7706\n",
            "\n",
            "Epoch 00309: val_loss did not improve\n",
            "Epoch 310/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.4159 - categorical_accuracy: 0.8436 - val_loss: 0.3472 - val_categorical_accuracy: 0.8794\n",
            "\n",
            "Epoch 00310: val_loss did not improve\n",
            "Epoch 311/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2814 - categorical_accuracy: 0.9036 - val_loss: 0.3540 - val_categorical_accuracy: 0.8719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00311: val_loss did not improve\n",
            "Epoch 312/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3007 - categorical_accuracy: 0.8856 - val_loss: 0.5292 - val_categorical_accuracy: 0.8019\n",
            "\n",
            "Epoch 00312: val_loss did not improve\n",
            "Epoch 313/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5636 - categorical_accuracy: 0.7869 - val_loss: 0.4504 - val_categorical_accuracy: 0.8344\n",
            "\n",
            "Epoch 00313: val_loss did not improve\n",
            "Epoch 314/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3208 - categorical_accuracy: 0.8839 - val_loss: 0.3632 - val_categorical_accuracy: 0.8600\n",
            "\n",
            "Epoch 00314: val_loss did not improve\n",
            "Epoch 315/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4197 - categorical_accuracy: 0.8447 - val_loss: 0.4680 - val_categorical_accuracy: 0.8281\n",
            "\n",
            "Epoch 00315: val_loss did not improve\n",
            "Epoch 316/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3950 - categorical_accuracy: 0.8556 - val_loss: 0.7355 - val_categorical_accuracy: 0.7538\n",
            "\n",
            "Epoch 00316: val_loss did not improve\n",
            "Epoch 317/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4719 - categorical_accuracy: 0.8264 - val_loss: 0.3288 - val_categorical_accuracy: 0.8869\n",
            "\n",
            "Epoch 00317: val_loss did not improve\n",
            "Epoch 318/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.3105 - categorical_accuracy: 0.8891 - val_loss: 0.8356 - val_categorical_accuracy: 0.7231\n",
            "\n",
            "Epoch 00318: val_loss did not improve\n",
            "Epoch 319/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.6032 - categorical_accuracy: 0.7817 - val_loss: 0.5033 - val_categorical_accuracy: 0.8156\n",
            "\n",
            "Epoch 00319: val_loss did not improve\n",
            "Epoch 320/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.3531 - categorical_accuracy: 0.8708 - val_loss: 0.3395 - val_categorical_accuracy: 0.8819\n",
            "\n",
            "Epoch 00320: val_loss did not improve\n",
            "Epoch 321/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3239 - categorical_accuracy: 0.8812 - val_loss: 0.4714 - val_categorical_accuracy: 0.8313\n",
            "\n",
            "Epoch 00321: val_loss did not improve\n",
            "Epoch 322/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.4074 - categorical_accuracy: 0.8466 - val_loss: 0.5974 - val_categorical_accuracy: 0.7862\n",
            "\n",
            "Epoch 00322: val_loss did not improve\n",
            "Epoch 323/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4513 - categorical_accuracy: 0.8439 - val_loss: 0.7235 - val_categorical_accuracy: 0.7619\n",
            "\n",
            "Epoch 00323: val_loss did not improve\n",
            "Epoch 324/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4924 - categorical_accuracy: 0.8205 - val_loss: 0.4314 - val_categorical_accuracy: 0.8413\n",
            "\n",
            "Epoch 00324: val_loss did not improve\n",
            "Epoch 325/500\n",
            "2000/6400 [========>.....................] - ETA: 0s - loss: 0.3601 - categorical_accuracy: 0.8590"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3073 - categorical_accuracy: 0.8891 - val_loss: 0.4839 - val_categorical_accuracy: 0.8188\n",
            "\n",
            "Epoch 00325: val_loss did not improve\n",
            "Epoch 326/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4706 - categorical_accuracy: 0.8278 - val_loss: 0.3217 - val_categorical_accuracy: 0.8825\n",
            "\n",
            "Epoch 00326: val_loss did not improve\n",
            "Epoch 327/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2487 - categorical_accuracy: 0.9148 - val_loss: 0.3623 - val_categorical_accuracy: 0.8556\n",
            "\n",
            "Epoch 00327: val_loss did not improve\n",
            "Epoch 328/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3474 - categorical_accuracy: 0.8706 - val_loss: 0.5033 - val_categorical_accuracy: 0.8094\n",
            "\n",
            "Epoch 00328: val_loss did not improve\n",
            "Epoch 329/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4958 - categorical_accuracy: 0.8231 - val_loss: 0.8631 - val_categorical_accuracy: 0.7138\n",
            "\n",
            "Epoch 00329: val_loss did not improve\n",
            "Epoch 330/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6369 - categorical_accuracy: 0.7734 - val_loss: 0.6975 - val_categorical_accuracy: 0.7619\n",
            "\n",
            "Epoch 00330: val_loss did not improve\n",
            "Epoch 331/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4450 - categorical_accuracy: 0.8372 - val_loss: 0.3177 - val_categorical_accuracy: 0.8881\n",
            "\n",
            "Epoch 00331: val_loss did not improve\n",
            "Epoch 332/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2481 - categorical_accuracy: 0.9148 - val_loss: 0.4013 - val_categorical_accuracy: 0.8600\n",
            "\n",
            "Epoch 00332: val_loss did not improve\n",
            "Epoch 333/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3650 - categorical_accuracy: 0.8608 - val_loss: 0.3623 - val_categorical_accuracy: 0.8681\n",
            "\n",
            "Epoch 00333: val_loss did not improve\n",
            "Epoch 334/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3356 - categorical_accuracy: 0.8727 - val_loss: 0.5389 - val_categorical_accuracy: 0.8119\n",
            "\n",
            "Epoch 00334: val_loss did not improve\n",
            "Epoch 335/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4129 - categorical_accuracy: 0.8416 - val_loss: 0.9089 - val_categorical_accuracy: 0.6981\n",
            "\n",
            "Epoch 00335: val_loss did not improve\n",
            "Epoch 336/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.8537 - categorical_accuracy: 0.7169 - val_loss: 0.3832 - val_categorical_accuracy: 0.8625\n",
            "\n",
            "Epoch 00336: val_loss did not improve\n",
            "Epoch 337/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2783 - categorical_accuracy: 0.9036 - val_loss: 0.3211 - val_categorical_accuracy: 0.8825\n",
            "\n",
            "Epoch 00337: val_loss did not improve\n",
            "Epoch 338/500\n",
            "6000/6400 [===========================>..] - ETA: 0s - loss: 0.2640 - categorical_accuracy: 0.9053"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6400/6400 [==============================] - 1s 156us/step - loss: 0.2670 - categorical_accuracy: 0.9045 - val_loss: 0.5114 - val_categorical_accuracy: 0.8094\n",
            "\n",
            "Epoch 00338: val_loss did not improve\n",
            "Epoch 339/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4480 - categorical_accuracy: 0.8328 - val_loss: 0.3243 - val_categorical_accuracy: 0.8806\n",
            "\n",
            "Epoch 00339: val_loss did not improve\n",
            "Epoch 340/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3373 - categorical_accuracy: 0.8770 - val_loss: 0.3945 - val_categorical_accuracy: 0.8575\n",
            "\n",
            "Epoch 00340: val_loss did not improve\n",
            "Epoch 341/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3340 - categorical_accuracy: 0.8747 - val_loss: 0.3711 - val_categorical_accuracy: 0.8625\n",
            "\n",
            "Epoch 00341: val_loss did not improve\n",
            "Epoch 342/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3099 - categorical_accuracy: 0.8845 - val_loss: 0.7555 - val_categorical_accuracy: 0.7075\n",
            "\n",
            "Epoch 00342: val_loss did not improve\n",
            "Epoch 343/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5298 - categorical_accuracy: 0.7989 - val_loss: 0.4540 - val_categorical_accuracy: 0.8288\n",
            "\n",
            "Epoch 00343: val_loss did not improve\n",
            "Epoch 344/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4061 - categorical_accuracy: 0.8492 - val_loss: 0.3339 - val_categorical_accuracy: 0.8788\n",
            "\n",
            "Epoch 00344: val_loss did not improve\n",
            "Epoch 345/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2691 - categorical_accuracy: 0.9062 - val_loss: 0.4089 - val_categorical_accuracy: 0.8531\n",
            "\n",
            "Epoch 00345: val_loss did not improve\n",
            "Epoch 346/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3366 - categorical_accuracy: 0.8753 - val_loss: 0.3790 - val_categorical_accuracy: 0.8531\n",
            "\n",
            "Epoch 00346: val_loss did not improve\n",
            "Epoch 347/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5396 - categorical_accuracy: 0.8117 - val_loss: 0.6569 - val_categorical_accuracy: 0.7563\n",
            "\n",
            "Epoch 00347: val_loss did not improve\n",
            "Epoch 348/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5578 - categorical_accuracy: 0.7892 - val_loss: 0.3919 - val_categorical_accuracy: 0.8544\n",
            "\n",
            "Epoch 00348: val_loss did not improve\n",
            "Epoch 349/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2749 - categorical_accuracy: 0.9027 - val_loss: 0.3430 - val_categorical_accuracy: 0.8769\n",
            "\n",
            "Epoch 00349: val_loss did not improve\n",
            "Epoch 350/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3067 - categorical_accuracy: 0.8827 - val_loss: 0.4503 - val_categorical_accuracy: 0.8331\n",
            "\n",
            "Epoch 00350: val_loss did not improve\n",
            "Epoch 351/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3606 - categorical_accuracy: 0.8614 - val_loss: 0.5833 - val_categorical_accuracy: 0.7919\n",
            "\n",
            "Epoch 00351: val_loss did not improve\n",
            "Epoch 352/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4954 - categorical_accuracy: 0.8131 - val_loss: 0.5174 - val_categorical_accuracy: 0.8062\n",
            "\n",
            "Epoch 00352: val_loss did not improve\n",
            "Epoch 353/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4092 - categorical_accuracy: 0.8477 - val_loss: 0.4471 - val_categorical_accuracy: 0.8294\n",
            "\n",
            "Epoch 00353: val_loss did not improve\n",
            "Epoch 354/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3231 - categorical_accuracy: 0.8822 - val_loss: 0.4290 - val_categorical_accuracy: 0.8431\n",
            "\n",
            "Epoch 00354: val_loss did not improve\n",
            "Epoch 355/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4568 - categorical_accuracy: 0.8344 - val_loss: 0.8230 - val_categorical_accuracy: 0.7088\n",
            "\n",
            "Epoch 00355: val_loss did not improve\n",
            "Epoch 356/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4842 - categorical_accuracy: 0.8252 - val_loss: 0.4110 - val_categorical_accuracy: 0.8569\n",
            "\n",
            "Epoch 00356: val_loss did not improve\n",
            "Epoch 357/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3377 - categorical_accuracy: 0.8756 - val_loss: 0.3475 - val_categorical_accuracy: 0.8719\n",
            "\n",
            "Epoch 00357: val_loss did not improve\n",
            "Epoch 358/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3127 - categorical_accuracy: 0.8873 - val_loss: 0.8342 - val_categorical_accuracy: 0.7175\n",
            "\n",
            "Epoch 00358: val_loss did not improve\n",
            "Epoch 359/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.5642 - categorical_accuracy: 0.7900 - val_loss: 0.3693 - val_categorical_accuracy: 0.8569\n",
            "\n",
            "Epoch 00359: val_loss did not improve\n",
            "Epoch 360/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.3168 - categorical_accuracy: 0.8820 - val_loss: 0.3465 - val_categorical_accuracy: 0.8675\n",
            "\n",
            "Epoch 00360: val_loss did not improve\n",
            "Epoch 361/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.2637 - categorical_accuracy: 0.9077 - val_loss: 0.4084 - val_categorical_accuracy: 0.8469\n",
            "\n",
            "Epoch 00361: val_loss did not improve\n",
            "Epoch 362/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.3229 - categorical_accuracy: 0.8820 - val_loss: 0.4795 - val_categorical_accuracy: 0.8281\n",
            "\n",
            "Epoch 00362: val_loss did not improve\n",
            "Epoch 363/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.6178 - categorical_accuracy: 0.7997 - val_loss: 1.3317 - val_categorical_accuracy: 0.6800\n",
            "\n",
            "Epoch 00363: val_loss did not improve\n",
            "Epoch 364/500\n",
            "6000/6400 [===========================>..] - ETA: 0s - loss: 0.7028 - categorical_accuracy: 0.7850"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6400/6400 [==============================] - 1s 158us/step - loss: 0.6767 - categorical_accuracy: 0.7923 - val_loss: 0.3206 - val_categorical_accuracy: 0.8781\n",
            "\n",
            "Epoch 00364: val_loss did not improve\n",
            "Epoch 365/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.2414 - categorical_accuracy: 0.9211 - val_loss: 0.3795 - val_categorical_accuracy: 0.8619\n",
            "\n",
            "Epoch 00365: val_loss did not improve\n",
            "Epoch 366/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3811 - categorical_accuracy: 0.8550 - val_loss: 0.6047 - val_categorical_accuracy: 0.7806\n",
            "\n",
            "Epoch 00366: val_loss did not improve\n",
            "Epoch 367/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4552 - categorical_accuracy: 0.8313 - val_loss: 0.3485 - val_categorical_accuracy: 0.8725\n",
            "\n",
            "Epoch 00367: val_loss did not improve\n",
            "Epoch 368/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2781 - categorical_accuracy: 0.8991 - val_loss: 0.3565 - val_categorical_accuracy: 0.8675\n",
            "\n",
            "Epoch 00368: val_loss did not improve\n",
            "Epoch 369/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2762 - categorical_accuracy: 0.8970 - val_loss: 0.3904 - val_categorical_accuracy: 0.8594\n",
            "\n",
            "Epoch 00369: val_loss did not improve\n",
            "Epoch 370/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4185 - categorical_accuracy: 0.8473 - val_loss: 0.6021 - val_categorical_accuracy: 0.7862\n",
            "\n",
            "Epoch 00370: val_loss did not improve\n",
            "Epoch 371/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4545 - categorical_accuracy: 0.8358 - val_loss: 0.4378 - val_categorical_accuracy: 0.8456\n",
            "\n",
            "Epoch 00371: val_loss did not improve\n",
            "Epoch 372/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3531 - categorical_accuracy: 0.8661 - val_loss: 0.6489 - val_categorical_accuracy: 0.7569\n",
            "\n",
            "Epoch 00372: val_loss did not improve\n",
            "Epoch 373/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6041 - categorical_accuracy: 0.7769 - val_loss: 0.3189 - val_categorical_accuracy: 0.8794\n",
            "\n",
            "Epoch 00373: val_loss did not improve\n",
            "Epoch 374/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2626 - categorical_accuracy: 0.9094 - val_loss: 0.4818 - val_categorical_accuracy: 0.8156\n",
            "\n",
            "Epoch 00374: val_loss did not improve\n",
            "Epoch 375/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4348 - categorical_accuracy: 0.8319 - val_loss: 0.3539 - val_categorical_accuracy: 0.8719\n",
            "\n",
            "Epoch 00375: val_loss did not improve\n",
            "Epoch 376/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2739 - categorical_accuracy: 0.9020 - val_loss: 0.3299 - val_categorical_accuracy: 0.8806\n",
            "\n",
            "Epoch 00376: val_loss did not improve\n",
            "Epoch 377/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2599 - categorical_accuracy: 0.9039 - val_loss: 0.7018 - val_categorical_accuracy: 0.7337\n",
            "\n",
            "Epoch 00377: val_loss did not improve\n",
            "Epoch 378/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.7345 - categorical_accuracy: 0.7452 - val_loss: 0.8072 - val_categorical_accuracy: 0.7331\n",
            "\n",
            "Epoch 00378: val_loss did not improve\n",
            "Epoch 379/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5645 - categorical_accuracy: 0.7928 - val_loss: 0.3800 - val_categorical_accuracy: 0.8581\n",
            "\n",
            "Epoch 00379: val_loss did not improve\n",
            "Epoch 380/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2675 - categorical_accuracy: 0.9092 - val_loss: 0.3168 - val_categorical_accuracy: 0.8875\n",
            "\n",
            "Epoch 00380: val_loss did not improve\n",
            "Epoch 381/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2606 - categorical_accuracy: 0.9100 - val_loss: 0.5489 - val_categorical_accuracy: 0.8087\n",
            "\n",
            "Epoch 00381: val_loss did not improve\n",
            "Epoch 382/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4215 - categorical_accuracy: 0.8506 - val_loss: 0.4504 - val_categorical_accuracy: 0.8306\n",
            "\n",
            "Epoch 00382: val_loss did not improve\n",
            "Epoch 383/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3676 - categorical_accuracy: 0.8605 - val_loss: 0.4601 - val_categorical_accuracy: 0.8313\n",
            "\n",
            "Epoch 00383: val_loss did not improve\n",
            "Epoch 384/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3166 - categorical_accuracy: 0.8831 - val_loss: 0.3643 - val_categorical_accuracy: 0.8669\n",
            "\n",
            "Epoch 00384: val_loss did not improve\n",
            "Epoch 385/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.4432 - categorical_accuracy: 0.8338 - val_loss: 0.8333 - val_categorical_accuracy: 0.7331\n",
            "\n",
            "Epoch 00385: val_loss did not improve\n",
            "Epoch 386/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5183 - categorical_accuracy: 0.8244 - val_loss: 0.3043 - val_categorical_accuracy: 0.8900\n",
            "\n",
            "Epoch 00386: val_loss improved from 0.31610 to 0.30434, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 387/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2252 - categorical_accuracy: 0.9261 - val_loss: 0.3062 - val_categorical_accuracy: 0.8875\n",
            "\n",
            "Epoch 00387: val_loss did not improve\n",
            "Epoch 388/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2407 - categorical_accuracy: 0.9128 - val_loss: 0.3477 - val_categorical_accuracy: 0.8675\n",
            "\n",
            "Epoch 00388: val_loss did not improve\n",
            "Epoch 389/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3456 - categorical_accuracy: 0.8706 - val_loss: 0.4505 - val_categorical_accuracy: 0.8394\n",
            "\n",
            "Epoch 00389: val_loss did not improve\n",
            "Epoch 390/500\n",
            "2000/6400 [========>.....................] - ETA: 0s - loss: 0.3782 - categorical_accuracy: 0.8590"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3983 - categorical_accuracy: 0.8453 - val_loss: 0.5296 - val_categorical_accuracy: 0.8112\n",
            "\n",
            "Epoch 00390: val_loss did not improve\n",
            "Epoch 391/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5378 - categorical_accuracy: 0.7911 - val_loss: 0.7519 - val_categorical_accuracy: 0.7375\n",
            "\n",
            "Epoch 00391: val_loss did not improve\n",
            "Epoch 392/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5286 - categorical_accuracy: 0.8091 - val_loss: 0.4207 - val_categorical_accuracy: 0.8519\n",
            "\n",
            "Epoch 00392: val_loss did not improve\n",
            "Epoch 393/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2612 - categorical_accuracy: 0.9120 - val_loss: 0.2857 - val_categorical_accuracy: 0.9006\n",
            "\n",
            "Epoch 00393: val_loss improved from 0.30434 to 0.28574, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 394/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2246 - categorical_accuracy: 0.9250 - val_loss: 0.3973 - val_categorical_accuracy: 0.8556\n",
            "\n",
            "Epoch 00394: val_loss did not improve\n",
            "Epoch 395/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4102 - categorical_accuracy: 0.8445 - val_loss: 0.4121 - val_categorical_accuracy: 0.8413\n",
            "\n",
            "Epoch 00395: val_loss did not improve\n",
            "Epoch 396/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.4360 - categorical_accuracy: 0.8372 - val_loss: 0.6444 - val_categorical_accuracy: 0.7944\n",
            "\n",
            "Epoch 00396: val_loss did not improve\n",
            "Epoch 397/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.4081 - categorical_accuracy: 0.8548 - val_loss: 0.3095 - val_categorical_accuracy: 0.8838\n",
            "\n",
            "Epoch 00397: val_loss did not improve\n",
            "Epoch 398/500\n",
            "6400/6400 [==============================] - 1s 160us/step - loss: 0.3120 - categorical_accuracy: 0.8927 - val_loss: 0.9273 - val_categorical_accuracy: 0.7006\n",
            "\n",
            "Epoch 00398: val_loss did not improve\n",
            "Epoch 399/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.5439 - categorical_accuracy: 0.8072 - val_loss: 0.3500 - val_categorical_accuracy: 0.8712\n",
            "\n",
            "Epoch 00399: val_loss did not improve\n",
            "Epoch 400/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2803 - categorical_accuracy: 0.9028 - val_loss: 0.4693 - val_categorical_accuracy: 0.8069\n",
            "\n",
            "Epoch 00400: val_loss did not improve\n",
            "Epoch 401/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4314 - categorical_accuracy: 0.8380 - val_loss: 0.6754 - val_categorical_accuracy: 0.7375\n",
            "\n",
            "Epoch 00401: val_loss did not improve\n",
            "Epoch 402/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4092 - categorical_accuracy: 0.8400 - val_loss: 0.4364 - val_categorical_accuracy: 0.8350\n",
            "\n",
            "Epoch 00402: val_loss did not improve\n",
            "Epoch 403/500\n",
            "2000/6400 [========>.....................] - ETA: 0s - loss: 0.3429 - categorical_accuracy: 0.8720"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2778 - categorical_accuracy: 0.9025 - val_loss: 0.3095 - val_categorical_accuracy: 0.8894\n",
            "\n",
            "Epoch 00403: val_loss did not improve\n",
            "Epoch 404/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2746 - categorical_accuracy: 0.8981 - val_loss: 0.5593 - val_categorical_accuracy: 0.7925\n",
            "\n",
            "Epoch 00404: val_loss did not improve\n",
            "Epoch 405/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4320 - categorical_accuracy: 0.8316 - val_loss: 0.4429 - val_categorical_accuracy: 0.8344\n",
            "\n",
            "Epoch 00405: val_loss did not improve\n",
            "Epoch 406/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4717 - categorical_accuracy: 0.8277 - val_loss: 1.1568 - val_categorical_accuracy: 0.6594\n",
            "\n",
            "Epoch 00406: val_loss did not improve\n",
            "Epoch 407/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6996 - categorical_accuracy: 0.7595 - val_loss: 0.3163 - val_categorical_accuracy: 0.8825\n",
            "\n",
            "Epoch 00407: val_loss did not improve\n",
            "Epoch 408/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2282 - categorical_accuracy: 0.9255 - val_loss: 0.2981 - val_categorical_accuracy: 0.8869\n",
            "\n",
            "Epoch 00408: val_loss did not improve\n",
            "Epoch 409/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2468 - categorical_accuracy: 0.9091 - val_loss: 0.4247 - val_categorical_accuracy: 0.8431\n",
            "\n",
            "Epoch 00409: val_loss did not improve\n",
            "Epoch 410/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3367 - categorical_accuracy: 0.8747 - val_loss: 0.5715 - val_categorical_accuracy: 0.8144\n",
            "\n",
            "Epoch 00410: val_loss did not improve\n",
            "Epoch 411/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5526 - categorical_accuracy: 0.8086 - val_loss: 0.2969 - val_categorical_accuracy: 0.8931\n",
            "\n",
            "Epoch 00411: val_loss did not improve\n",
            "Epoch 412/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3029 - categorical_accuracy: 0.8887 - val_loss: 0.3712 - val_categorical_accuracy: 0.8594\n",
            "\n",
            "Epoch 00412: val_loss did not improve\n",
            "Epoch 413/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3193 - categorical_accuracy: 0.8797 - val_loss: 0.6564 - val_categorical_accuracy: 0.7575\n",
            "\n",
            "Epoch 00413: val_loss did not improve\n",
            "Epoch 414/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3789 - categorical_accuracy: 0.8598 - val_loss: 0.3559 - val_categorical_accuracy: 0.8706\n",
            "\n",
            "Epoch 00414: val_loss did not improve\n",
            "Epoch 415/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3164 - categorical_accuracy: 0.8864 - val_loss: 0.4326 - val_categorical_accuracy: 0.8419\n",
            "\n",
            "Epoch 00415: val_loss did not improve\n",
            "Epoch 416/500\n",
            "6000/6400 [===========================>..] - ETA: 0s - loss: 0.5867 - categorical_accuracy: 0.7868"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6400/6400 [==============================] - 1s 156us/step - loss: 0.5964 - categorical_accuracy: 0.7866 - val_loss: 0.5740 - val_categorical_accuracy: 0.7906\n",
            "\n",
            "Epoch 00416: val_loss did not improve\n",
            "Epoch 417/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4790 - categorical_accuracy: 0.8205 - val_loss: 0.3121 - val_categorical_accuracy: 0.8844\n",
            "\n",
            "Epoch 00417: val_loss did not improve\n",
            "Epoch 418/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2185 - categorical_accuracy: 0.9312 - val_loss: 0.3024 - val_categorical_accuracy: 0.8856\n",
            "\n",
            "Epoch 00418: val_loss did not improve\n",
            "Epoch 419/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2616 - categorical_accuracy: 0.9067 - val_loss: 0.3948 - val_categorical_accuracy: 0.8644\n",
            "\n",
            "Epoch 00419: val_loss did not improve\n",
            "Epoch 420/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3014 - categorical_accuracy: 0.8848 - val_loss: 0.3340 - val_categorical_accuracy: 0.8788\n",
            "\n",
            "Epoch 00420: val_loss did not improve\n",
            "Epoch 421/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.3468 - categorical_accuracy: 0.8764 - val_loss: 0.7159 - val_categorical_accuracy: 0.7569\n",
            "\n",
            "Epoch 00421: val_loss did not improve\n",
            "Epoch 422/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.7266 - categorical_accuracy: 0.7492 - val_loss: 0.4176 - val_categorical_accuracy: 0.8512\n",
            "\n",
            "Epoch 00422: val_loss did not improve\n",
            "Epoch 423/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2585 - categorical_accuracy: 0.9108 - val_loss: 0.3904 - val_categorical_accuracy: 0.8556\n",
            "\n",
            "Epoch 00423: val_loss did not improve\n",
            "Epoch 424/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4723 - categorical_accuracy: 0.8283 - val_loss: 0.3994 - val_categorical_accuracy: 0.8519\n",
            "\n",
            "Epoch 00424: val_loss did not improve\n",
            "Epoch 425/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2739 - categorical_accuracy: 0.8967 - val_loss: 0.3455 - val_categorical_accuracy: 0.8719\n",
            "\n",
            "Epoch 00425: val_loss did not improve\n",
            "Epoch 426/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.2488 - categorical_accuracy: 0.9089 - val_loss: 0.2804 - val_categorical_accuracy: 0.8963\n",
            "\n",
            "Epoch 00426: val_loss improved from 0.28574 to 0.28036, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 427/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.2436 - categorical_accuracy: 0.9136 - val_loss: 0.9595 - val_categorical_accuracy: 0.7125\n",
            "\n",
            "Epoch 00427: val_loss did not improve\n",
            "Epoch 428/500\n",
            "6400/6400 [==============================] - 1s 160us/step - loss: 0.8043 - categorical_accuracy: 0.7547 - val_loss: 0.3665 - val_categorical_accuracy: 0.8625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00428: val_loss did not improve\n",
            "Epoch 429/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.3402 - categorical_accuracy: 0.8761 - val_loss: 0.3933 - val_categorical_accuracy: 0.8450\n",
            "\n",
            "Epoch 00429: val_loss did not improve\n",
            "Epoch 430/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.2805 - categorical_accuracy: 0.8983 - val_loss: 0.3590 - val_categorical_accuracy: 0.8775\n",
            "\n",
            "Epoch 00430: val_loss did not improve\n",
            "Epoch 431/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.2776 - categorical_accuracy: 0.9005 - val_loss: 0.3238 - val_categorical_accuracy: 0.8819\n",
            "\n",
            "Epoch 00431: val_loss did not improve\n",
            "Epoch 432/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2529 - categorical_accuracy: 0.9113 - val_loss: 0.6869 - val_categorical_accuracy: 0.7675\n",
            "\n",
            "Epoch 00432: val_loss did not improve\n",
            "Epoch 433/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4565 - categorical_accuracy: 0.8388 - val_loss: 0.5941 - val_categorical_accuracy: 0.8000\n",
            "\n",
            "Epoch 00433: val_loss did not improve\n",
            "Epoch 434/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5019 - categorical_accuracy: 0.8219 - val_loss: 0.4010 - val_categorical_accuracy: 0.8512\n",
            "\n",
            "Epoch 00434: val_loss did not improve\n",
            "Epoch 435/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3196 - categorical_accuracy: 0.8819 - val_loss: 0.3528 - val_categorical_accuracy: 0.8687\n",
            "\n",
            "Epoch 00435: val_loss did not improve\n",
            "Epoch 436/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3387 - categorical_accuracy: 0.8742 - val_loss: 0.3964 - val_categorical_accuracy: 0.8525\n",
            "\n",
            "Epoch 00436: val_loss did not improve\n",
            "Epoch 437/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2932 - categorical_accuracy: 0.8903 - val_loss: 0.3128 - val_categorical_accuracy: 0.8756\n",
            "\n",
            "Epoch 00437: val_loss did not improve\n",
            "Epoch 438/500\n",
            "6400/6400 [==============================] - 1s 155us/step - loss: 0.2221 - categorical_accuracy: 0.9175 - val_loss: 0.5548 - val_categorical_accuracy: 0.7969\n",
            "\n",
            "Epoch 00438: val_loss did not improve\n",
            "Epoch 439/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.6449 - categorical_accuracy: 0.7727 - val_loss: 0.9798 - val_categorical_accuracy: 0.6687\n",
            "\n",
            "Epoch 00439: val_loss did not improve\n",
            "Epoch 440/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.6496 - categorical_accuracy: 0.7989 - val_loss: 0.3156 - val_categorical_accuracy: 0.8869\n",
            "\n",
            "Epoch 00440: val_loss did not improve\n",
            "Epoch 441/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2234 - categorical_accuracy: 0.9270 - val_loss: 0.2758 - val_categorical_accuracy: 0.8963\n",
            "\n",
            "Epoch 00441: val_loss improved from 0.28036 to 0.27584, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 442/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.1931 - categorical_accuracy: 0.9364 - val_loss: 0.3074 - val_categorical_accuracy: 0.8856\n",
            "\n",
            "Epoch 00442: val_loss did not improve\n",
            "Epoch 443/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2950 - categorical_accuracy: 0.8903 - val_loss: 0.5845 - val_categorical_accuracy: 0.8050\n",
            "\n",
            "Epoch 00443: val_loss did not improve\n",
            "Epoch 444/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4254 - categorical_accuracy: 0.8422 - val_loss: 0.3667 - val_categorical_accuracy: 0.8644\n",
            "\n",
            "Epoch 00444: val_loss did not improve\n",
            "Epoch 445/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2818 - categorical_accuracy: 0.8981 - val_loss: 0.3413 - val_categorical_accuracy: 0.8756\n",
            "\n",
            "Epoch 00445: val_loss did not improve\n",
            "Epoch 446/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5552 - categorical_accuracy: 0.8156 - val_loss: 0.9957 - val_categorical_accuracy: 0.7262\n",
            "\n",
            "Epoch 00446: val_loss did not improve\n",
            "Epoch 447/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.6597 - categorical_accuracy: 0.7759 - val_loss: 0.2922 - val_categorical_accuracy: 0.8919\n",
            "\n",
            "Epoch 00447: val_loss did not improve\n",
            "Epoch 448/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2116 - categorical_accuracy: 0.9314 - val_loss: 0.2727 - val_categorical_accuracy: 0.9000\n",
            "\n",
            "Epoch 00448: val_loss improved from 0.27584 to 0.27269, saving model to /content/weights.best.CNN_pos.hdf5\n",
            "Epoch 449/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.1866 - categorical_accuracy: 0.9398 - val_loss: 0.2939 - val_categorical_accuracy: 0.8975\n",
            "\n",
            "Epoch 00449: val_loss did not improve\n",
            "Epoch 450/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2881 - categorical_accuracy: 0.8903 - val_loss: 0.3437 - val_categorical_accuracy: 0.8700\n",
            "\n",
            "Epoch 00450: val_loss did not improve\n",
            "Epoch 451/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3023 - categorical_accuracy: 0.8925 - val_loss: 0.5725 - val_categorical_accuracy: 0.7912\n",
            "\n",
            "Epoch 00451: val_loss did not improve\n",
            "Epoch 452/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3598 - categorical_accuracy: 0.8652 - val_loss: 0.5598 - val_categorical_accuracy: 0.7856\n",
            "\n",
            "Epoch 00452: val_loss did not improve\n",
            "Epoch 453/500\n",
            "6400/6400 [==============================] - 1s 155us/step - loss: 0.4570 - categorical_accuracy: 0.8258 - val_loss: 0.6411 - val_categorical_accuracy: 0.7644\n",
            "\n",
            "Epoch 00453: val_loss did not improve\n",
            "Epoch 454/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4008 - categorical_accuracy: 0.8497 - val_loss: 0.3693 - val_categorical_accuracy: 0.8662\n",
            "\n",
            "Epoch 00454: val_loss did not improve\n",
            "Epoch 455/500\n",
            "2000/6400 [========>.....................] - ETA: 0s - loss: 0.2582 - categorical_accuracy: 0.9120"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3132 - categorical_accuracy: 0.8891 - val_loss: 0.3681 - val_categorical_accuracy: 0.8612\n",
            "\n",
            "Epoch 00455: val_loss did not improve\n",
            "Epoch 456/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2796 - categorical_accuracy: 0.8962 - val_loss: 0.4389 - val_categorical_accuracy: 0.8300\n",
            "\n",
            "Epoch 00456: val_loss did not improve\n",
            "Epoch 457/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2926 - categorical_accuracy: 0.8892 - val_loss: 0.4159 - val_categorical_accuracy: 0.8431\n",
            "\n",
            "Epoch 00457: val_loss did not improve\n",
            "Epoch 458/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4390 - categorical_accuracy: 0.8375 - val_loss: 0.7331 - val_categorical_accuracy: 0.7100\n",
            "\n",
            "Epoch 00458: val_loss did not improve\n",
            "Epoch 459/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4404 - categorical_accuracy: 0.8348 - val_loss: 0.4477 - val_categorical_accuracy: 0.8325\n",
            "\n",
            "Epoch 00459: val_loss did not improve\n",
            "Epoch 460/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3093 - categorical_accuracy: 0.8825 - val_loss: 0.3153 - val_categorical_accuracy: 0.8806\n",
            "\n",
            "Epoch 00460: val_loss did not improve\n",
            "Epoch 461/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.2849 - categorical_accuracy: 0.8928 - val_loss: 0.6501 - val_categorical_accuracy: 0.7769\n",
            "\n",
            "Epoch 00461: val_loss did not improve\n",
            "Epoch 462/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4867 - categorical_accuracy: 0.8247 - val_loss: 0.5270 - val_categorical_accuracy: 0.8144\n",
            "\n",
            "Epoch 00462: val_loss did not improve\n",
            "Epoch 463/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3137 - categorical_accuracy: 0.8828 - val_loss: 0.2902 - val_categorical_accuracy: 0.8931\n",
            "\n",
            "Epoch 00463: val_loss did not improve\n",
            "Epoch 464/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2116 - categorical_accuracy: 0.9281 - val_loss: 0.4340 - val_categorical_accuracy: 0.8325\n",
            "\n",
            "Epoch 00464: val_loss did not improve\n",
            "Epoch 465/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4204 - categorical_accuracy: 0.8367 - val_loss: 0.3199 - val_categorical_accuracy: 0.8875\n",
            "\n",
            "Epoch 00465: val_loss did not improve\n",
            "Epoch 466/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3201 - categorical_accuracy: 0.8755 - val_loss: 0.8555 - val_categorical_accuracy: 0.7169\n",
            "\n",
            "Epoch 00466: val_loss did not improve\n",
            "Epoch 467/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.5335 - categorical_accuracy: 0.8064 - val_loss: 0.4526 - val_categorical_accuracy: 0.8356\n",
            "\n",
            "Epoch 00467: val_loss did not improve\n",
            "Epoch 468/500\n",
            "6000/6400 [===========================>..] - ETA: 0s - loss: 0.2728 - categorical_accuracy: 0.9052"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6400/6400 [==============================] - 1s 160us/step - loss: 0.2675 - categorical_accuracy: 0.9069 - val_loss: 0.2979 - val_categorical_accuracy: 0.8900\n",
            "\n",
            "Epoch 00468: val_loss did not improve\n",
            "Epoch 469/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.2458 - categorical_accuracy: 0.9106 - val_loss: 0.6042 - val_categorical_accuracy: 0.7869\n",
            "\n",
            "Epoch 00469: val_loss did not improve\n",
            "Epoch 470/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.4804 - categorical_accuracy: 0.8305 - val_loss: 0.5910 - val_categorical_accuracy: 0.7919\n",
            "\n",
            "Epoch 00470: val_loss did not improve\n",
            "Epoch 471/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.4003 - categorical_accuracy: 0.8498 - val_loss: 0.4415 - val_categorical_accuracy: 0.8319\n",
            "\n",
            "Epoch 00471: val_loss did not improve\n",
            "Epoch 472/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3355 - categorical_accuracy: 0.8745 - val_loss: 0.2818 - val_categorical_accuracy: 0.8969\n",
            "\n",
            "Epoch 00472: val_loss did not improve\n",
            "Epoch 473/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2035 - categorical_accuracy: 0.9288 - val_loss: 0.5158 - val_categorical_accuracy: 0.8037\n",
            "\n",
            "Epoch 00473: val_loss did not improve\n",
            "Epoch 474/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.5313 - categorical_accuracy: 0.8123 - val_loss: 0.5746 - val_categorical_accuracy: 0.7887\n",
            "\n",
            "Epoch 00474: val_loss did not improve\n",
            "Epoch 475/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3231 - categorical_accuracy: 0.8870 - val_loss: 0.4871 - val_categorical_accuracy: 0.8150\n",
            "\n",
            "Epoch 00475: val_loss did not improve\n",
            "Epoch 476/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3625 - categorical_accuracy: 0.8620 - val_loss: 0.3112 - val_categorical_accuracy: 0.8825\n",
            "\n",
            "Epoch 00476: val_loss did not improve\n",
            "Epoch 477/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.2461 - categorical_accuracy: 0.9142 - val_loss: 0.5275 - val_categorical_accuracy: 0.7962\n",
            "\n",
            "Epoch 00477: val_loss did not improve\n",
            "Epoch 478/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3825 - categorical_accuracy: 0.8564 - val_loss: 0.4217 - val_categorical_accuracy: 0.8456\n",
            "\n",
            "Epoch 00478: val_loss did not improve\n",
            "Epoch 479/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3342 - categorical_accuracy: 0.8695 - val_loss: 0.4421 - val_categorical_accuracy: 0.8238\n",
            "\n",
            "Epoch 00479: val_loss did not improve\n",
            "Epoch 480/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3529 - categorical_accuracy: 0.8695 - val_loss: 0.3615 - val_categorical_accuracy: 0.8706\n",
            "\n",
            "Epoch 00480: val_loss did not improve\n",
            "Epoch 481/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3543 - categorical_accuracy: 0.8728 - val_loss: 0.4838 - val_categorical_accuracy: 0.8206\n",
            "\n",
            "Epoch 00481: val_loss did not improve\n",
            "Epoch 482/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.4778 - categorical_accuracy: 0.8184 - val_loss: 1.0549 - val_categorical_accuracy: 0.7081\n",
            "\n",
            "Epoch 00482: val_loss did not improve\n",
            "Epoch 483/500\n",
            "6400/6400 [==============================] - 1s 160us/step - loss: 0.7967 - categorical_accuracy: 0.7530 - val_loss: 0.3040 - val_categorical_accuracy: 0.8875\n",
            "\n",
            "Epoch 00483: val_loss did not improve\n",
            "Epoch 484/500\n",
            "6400/6400 [==============================] - 1s 159us/step - loss: 0.2109 - categorical_accuracy: 0.9344 - val_loss: 0.2976 - val_categorical_accuracy: 0.8888\n",
            "\n",
            "Epoch 00484: val_loss did not improve\n",
            "Epoch 485/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.2167 - categorical_accuracy: 0.9228 - val_loss: 0.3495 - val_categorical_accuracy: 0.8669\n",
            "\n",
            "Epoch 00485: val_loss did not improve\n",
            "Epoch 486/500\n",
            "6400/6400 [==============================] - 1s 158us/step - loss: 0.2743 - categorical_accuracy: 0.8995 - val_loss: 0.3950 - val_categorical_accuracy: 0.8500\n",
            "\n",
            "Epoch 00486: val_loss did not improve\n",
            "Epoch 487/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2728 - categorical_accuracy: 0.9002 - val_loss: 0.4141 - val_categorical_accuracy: 0.8494\n",
            "\n",
            "Epoch 00487: val_loss did not improve\n",
            "Epoch 488/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4149 - categorical_accuracy: 0.8466 - val_loss: 0.4478 - val_categorical_accuracy: 0.8350\n",
            "\n",
            "Epoch 00488: val_loss did not improve\n",
            "Epoch 489/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3481 - categorical_accuracy: 0.8717 - val_loss: 0.4103 - val_categorical_accuracy: 0.8462\n",
            "\n",
            "Epoch 00489: val_loss did not improve\n",
            "Epoch 490/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.4512 - categorical_accuracy: 0.8394 - val_loss: 0.3340 - val_categorical_accuracy: 0.8838\n",
            "\n",
            "Epoch 00490: val_loss did not improve\n",
            "Epoch 491/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2254 - categorical_accuracy: 0.9219 - val_loss: 0.3102 - val_categorical_accuracy: 0.8894\n",
            "\n",
            "Epoch 00491: val_loss did not improve\n",
            "Epoch 492/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.2732 - categorical_accuracy: 0.9003 - val_loss: 0.4789 - val_categorical_accuracy: 0.8319\n",
            "\n",
            "Epoch 00492: val_loss did not improve\n",
            "Epoch 493/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.3256 - categorical_accuracy: 0.8763 - val_loss: 0.5014 - val_categorical_accuracy: 0.8175\n",
            "\n",
            "Epoch 00493: val_loss did not improve\n",
            "Epoch 494/500\n",
            "6000/6400 [===========================>..] - ETA: 0s - loss: 0.3981 - categorical_accuracy: 0.8502"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6400/6400 [==============================] - 1s 156us/step - loss: 0.3946 - categorical_accuracy: 0.8522 - val_loss: 0.4604 - val_categorical_accuracy: 0.8294\n",
            "\n",
            "Epoch 00494: val_loss did not improve\n",
            "Epoch 495/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.4625 - categorical_accuracy: 0.8194 - val_loss: 0.3472 - val_categorical_accuracy: 0.8669\n",
            "\n",
            "Epoch 00495: val_loss did not improve\n",
            "Epoch 496/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.2605 - categorical_accuracy: 0.9052 - val_loss: 0.5123 - val_categorical_accuracy: 0.8144\n",
            "\n",
            "Epoch 00496: val_loss did not improve\n",
            "Epoch 497/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.3112 - categorical_accuracy: 0.8833 - val_loss: 0.2821 - val_categorical_accuracy: 0.8956\n",
            "\n",
            "Epoch 00497: val_loss did not improve\n",
            "Epoch 498/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.1962 - categorical_accuracy: 0.9300 - val_loss: 0.4975 - val_categorical_accuracy: 0.8294\n",
            "\n",
            "Epoch 00498: val_loss did not improve\n",
            "Epoch 499/500\n",
            "6400/6400 [==============================] - 1s 157us/step - loss: 0.5070 - categorical_accuracy: 0.8314 - val_loss: 1.1692 - val_categorical_accuracy: 0.6944\n",
            "\n",
            "Epoch 00499: val_loss did not improve\n",
            "Epoch 500/500\n",
            "6400/6400 [==============================] - 1s 156us/step - loss: 0.7756 - categorical_accuracy: 0.7472 - val_loss: 0.3962 - val_categorical_accuracy: 0.8587\n",
            "\n",
            "Epoch 00500: val_loss did not improve\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6CfrypgP7B1",
        "colab_type": "code",
        "outputId": "7b1a6dd4-11e7-4c78-c463-25e6f4337b70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# evaluate the model\n",
        "loss_train, acc_train = model.evaluate(doc_train, onehot_train, verbose=1)\n",
        "print('Training Accuracy: ' +str(acc_train*100)+\"%\")\n",
        "print(\"Training Loss: \" +str(loss_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 1s 134us/step\n",
            "Training Accuracy: 89.3%\n",
            "Training Loss: 0.29497428238391876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX3gVPkHP7CB",
        "colab_type": "code",
        "outputId": "35a4223e-2d30-484a-96ba-231cc4b470fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# evaluate the model\n",
        "loss_test, acc_test = model.evaluate(doc_test, onehot_test, verbose=1)\n",
        "print('Test Accuracy: ' +str(acc_test*100)+\"%\")\n",
        "print(\"Test Loss: \" +str(loss_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2078/2078 [==============================] - 0s 135us/step\n",
            "Test Accuracy: 86.3811357131477%\n",
            "Test Loss: 0.3762062402214421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXvRKjlqP7CM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#predict = model.predict(doc_test)\n",
        "#print(predict[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXZURsw_P7CT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from keras.utils import plot_model\n",
        "#plot_model(model, to_file='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqV10wE3P7CW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from IPython.display import SVG\n",
        "#from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "#SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6pkTB6jP7CZ",
        "colab_type": "code",
        "outputId": "5bf9e6f9-36f0-4f12-9c88-78f04ea9e8b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['categorical_accuracy'] )\n",
        "plt.plot(history.history['val_categorical_accuracy'])\n",
        "# plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy  ')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZv5LxuUbQwq8RYZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc484914828>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mnTmZrBP7Cj",
        "colab_type": "code",
        "outputId": "703271db-b405-464d-9560-40689aa02003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'] )\n",
        "\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model   loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzsvXmYHVWd//8+Vbf3dEI3dCdA+DII\niCCgjt/g8GCCRll1BhydCePg4PIVfl8yXwTy6MggEAVUFhmQRTCASkAIBASEkMgSICvZCNk3SNKd\nTu97991q+/1Rt6rOqap7u+7te7u7qM/reXhI31vLubWc9/ks53OYYRgGCIIgCIIIDdJ4N4AgCIIg\niPwg8SYIgiCIkEHiTRAEQRAhg8SbIAiCIEIGiTdBEARBhAwSb4IgCIIIGSTeBBFBbrzxRtx///05\nt3nhhRfw3e9+N6/j/vSnP8VDDz00ipYRBBEEEm+CIAiCCBkk3gQxwTl06BC++MUvYsGCBbjgggtw\nwQUXYPPmzbjyyisxc+ZM3HDDDfa2r732Gr7+9a/jwgsvxH/8x3+gqakJANDb24vvf//7mD17Nq68\n8koMDg7a++zbtw+XX345LrjgAvzjP/4jtm7dWpR279q1C5dddhkuvPBCXHLJJVixYgUAYHh4GHPn\nzsVFF12Er3zlK/jZz34GRVGyfk4QhBcSb4IIAb29vWhoaMCyZctwyimn4LrrrsOvf/1rvPzyy3jl\nlVfQ1NSEw4cP46abbsKDDz6IpUuX4ktf+hJuvvlmAMCCBQtQV1eHt956CzfffDNWrlwJANB1HXPn\nzsUll1yCZcuWYf78+bj66quhquqo2qvrOq6//npcfvnlWLp0KW677TbMmzcPQ0NDePHFFzF58mS8\n9tprWLZsGWRZxr59+7J+ThCEFxJvgggBqqriwgsvBAB88pOfxBlnnIH6+nrU1dWhoaEBHR0dWLVq\nFb7whS/g+OOPBwD8y7/8C9577z2oqooNGzbgoosuAgBMnz4dZ511FgDgo48+Qnd3N771rW8BAD7/\n+c+jvr4e77///qjae+jQIXR1deFrX/saAOCMM87AMcccg61bt9rHX7lyJXRdx89//nOceuqpWT8n\nCMJLbLwbQBDEyMiyjMrKSgCAJEmorq4WvtM0Db29vZg8ebL9eW1tLQzDQG9vL/r7+1FbW2t/Z203\nMDCAZDJpCzsADA0Noa+vb1Tt7enpQW1tLRhjwjl7enrwta99Df39/bjvvvvw0Ucf4Z/+6Z9www03\n4KKLLvL9vLy8fFRtIYiPI2R5E8THhCOPPFIQ3f7+fkiShLq6OkyePFmIc/f09AAAGhsbUVNTg6VL\nl9r/rVy5Euedd96o29Lf3w9+3aO+vj4ceeSRAIDLLrsMzz33HJYsWYLt27fjxRdfzPk5QRAiJN4E\n8THhnHPOwYYNG9Dc3AwAeOaZZ3DOOecgFovhs5/9LN544w0AQFNTEzZu3AgAOPbYYzFt2jQsXboU\ngCnq119/PeLx+KjaMn36dEybNg1LliwBAGzatAldXV0488wz8eCDD2Lx4sUAgKlTp2L69OlgjGX9\nnCAIL+Q2J4iPCdOmTcNtt92Gq6++GoqiYPr06bj11lsBAFdddRWuu+46zJ49GyeeeCLOP/98AABj\nDPfccw/mz5+Pe++9F5Ik4Xvf+57gli8E67i33HILHnjgAVRVVeG+++5DdXU1LrnkEtxwww1YsGAB\nGGP4zGc+g0suuQQdHR2+nxME4YXRet4EQRAEES7IbU4QBEEQIYPEmyAIgiBCBok3QRAEQYQMEm+C\nIAiCCBkk3gRBEAQRMkIzVayzc3DkjfKgrq4avb2jm8tK0HUsBnQNRw9dw+JA13H0FPsaNjTU+n4e\nWcs7FpPHuwkfC+g6jh66hqOHrmFxoOs4esbqGkZWvAmCIAgirJB4EwRBEETIIPEmCIIgiJBB4k0Q\nBEEQIYPEmyAIgiBCBok3QRAEQYQMEm+CIAiCCBkk3gRBEAQRkLfffjPQdvfd9xscPtxSsnaQeBME\nQRBEAFpbD+ONN5YF2vZHP5qHY445tmRtCU15VIIgCIIYT+655w7s3LkdM2fOwPnnX4TW1sO4996H\n8Ktf/QKdnR1IJBK47rof4fTT/zf+8z+vxPXX/wTLl7+J4eEhNDUdREvLIVxzzTycffY5o25LJMU7\nldbw1oZmnHJMLcrLqBwgQRBE2Hj2rX1Yv6ujqMec8alG/Ovsk7J+/2//9h288MKzOOGEE9HUdAAP\nPfQoent7cNZZ/4CLLvo6WloO4Re/uBGPPPInYb+OjnbcffdvsXbtarz00vMk3oXy/t5O/P6vO/B/\nLz0dMz7VON7NIQiCIELGqad+GgBQWzsZO3dux8svvwDGJPT19Xm2PfPMzwIAGhsbMTQ0VJTzR1K8\nFVUHAKQVbZxbQhAEQRTCv84+KaeVXGrKysoAAK+/vhQDAwN48MFHMTAwgKuuusKzrSw7Hl7DMIpy\n/mgmrDHzf0W6hgRBEEQEkCQJmiYafX19fTj66GMgSRLeeectpNPpsWnLmJxlgsEy6m2A1JsgCIII\nxvHHn4Ddu3dheNhxfX/pS7OxevUK/OhH/xdVVVWYNm0a/vCHBSVvCzOKZcOXmM7OwaIda9XWVjz2\n6k5876JPYeZnjinacaNIQ0NtUe9NFKFrOHroGhYHuo6jp9jXsKGh1vfzSFreFqEYtRAEQRCEi0iK\nN2Pj3QKCIAiCKJySZZsnEgn89Kc/RXd3N1KpFK6++mp8+ctftr9fvXo17rnnHsiyjFmzZmHu3Lml\naooHO+YdjogBQRAEQQiUTLyXL1+O008/HT/84Q/R0tKC73//+4J433bbbXjssccwdepUXH755bjg\nggtw0kljlPZvZZuPzdkIgiAIoqiUTLwvvvhi+9+tra2YOnWq/XdzczOmTJmCo48+GgBw7rnnYs2a\nNWMm3rbXnNSbIAiCCCElL9Jy2WWXoa2tDQ8//LD9WWdnJ+rr6+2/6+vr0dzcnPM4dXXViMWKU8p0\n8uR+AMCkSRVZM/mI4NA1HD10DUcPXcPiQNdx9IzFNSy5eD/zzDPYuXMnfvzjH+Pll18GKzBbrLc3\nXrQ2DQ4m7f/TtIjRQVNLRg9dw9FD17A40HUcPQ0NtTj33C/hiScWobq6uijH86Nk2ebbtm1Da2sr\nAODUU0+Fpmno6ekBYNZ37erqsrdtb29HY+PY1RhnFPMmCIIgQkzJxHvDhg14/PHHAQBdXV2Ix+Oo\nq6sDAEyfPh1DQ0M4dOgQVFXF8uXLcc45o19lJV8o2ZwgCIIIyve//+9oa2sDALS1teJ73/s2fvKT\na/H//t9V+OEPr8COHdvGrC0lc5tfdtlluPHGG/Htb38byWQSN998M1588UXU1tbivPPOw/z58zFv\n3jwAZnLbCSecUKqmeCjUdU8QBEFMDF7Y9wre79ha1GN+rvEM/PNJX8/6/axZX8aqVe/im9/8V6xY\n8Q5mzfoyTjzxZMya9SVs3LgeTz31J5x77tlFbVM2SibelZWV+M1vfpP1+xkzZmDRokWlOn1OLOmm\ned4EQRBEUGbN+jIeeOBefPOb/4qVK9/Bf/7ndXjmmYV4+umFUBQFlZWVY9aWSC4JakHSTRAEEU7+\n+aSv57SSS8EnPnEiurs70d7ehsHBQaxY8TaOOqoRN910K3bt2oEHHrh3zNoS7fKopN4EQRBEHpx9\n9hfx+98/hJkzz0V/fx+OPXY6AOCdd5ZDVdUxa0ckxRv2kqAEQRAEEZxzz/0y3nhjGb70pa/gwgu/\nhkWLnsJ1183Fpz99Orq7u/H888+PSTsi6TZ3LG+Sb4IgCCI4p576abzzznv23089tdj+9xe/eC4a\nGmoxa9b5JW9HJC1v8poTBEEQYSaS4m0vTELqTRAEQYSQSIo3A83zJgiCIMJLJMXbWRKUTG+CIAgi\nfERSvGlJUIIgCCLMRFO8aWESgiAIIsREUrzted6UsUYQBEGEkEiKN61LQhAEQYSZaIp35v9keBME\nQRBhJJLiDYp5EwRBECEmkuLNqEoLQRAEEWIiKd5keRMEQRBhJpLiTfO8CYIgiDATbfEmCIIgiBAS\nSfG2IMObIAiCCCPRFG9GRVoIgiCI8BJJ8Sa3OUEQBBFmoineNFOMIAiCCDGRFG8L0m6CIAgijERS\nvJld3JzkmyAIgggfkRRvC3KbEwRBEGEkkuJNq4oRBEEQYSaa4m2v5z3ODSEIgiCIAoikeDu1zUm9\nCYIgiPARSfGm2uYEQRBEmImkeNOqYgRBEESYiaR4M1JvgiAIIsREU7wp5k0QBEGEmEiKtwVlmxME\nQRBhJJLiTfO8CYIgiDATTfGmed4EQRBEiImkeFtQzJsgCIIII5EUb1qXhCAIgggzsVIe/M4778TG\njRuhqiquuuoqnH/++fZ3s2fPxrRp0yDLMgDg7rvvxtSpU0vZHA+k3QRBEEQYKZl4r127Fnv37sWi\nRYvQ29uLb3zjG4J4A8CCBQtQU1NTqiZkhTGa500QBEGEl5KJ94wZM3DmmWcCACZPnoxEIgFN02xL\nezxxvOak3gRBEET4KJl4y7KM6upqAMDixYsxa9Ysj3DfcsstaGlpwec//3nMmzfPsYhLDRneBEEQ\nRIgpacwbAN544w0sXrwYjz/+uPD5Nddcg5kzZ2LKlCmYO3culi1bhgsvvDDrcerqqhGLFcdqj2um\nbFdWlqGhobYox4wydA1HD13D0UPXsDjQdRw9Y3ENSyreK1aswMMPP4xHH30UtbXij7n00kvtf8+a\nNQt79uzJKd69vfGitcs6ViKhoLNzsGjHjSINDbV0DUcJXcPRQ9ewONB1HD3FvobZBgIlmyo2ODiI\nO++8E4888giOOOIIz3c/+MEPkE6nAQDr16/HySefXKqmeHCWBCXHOUEQBBE+SmZ5L1myBL29vbj2\n2mvtz77whS/glFNOwXnnnYdZs2Zhzpw5qKiowGmnnZbT6i42lGxOEARBhJmSifecOXMwZ86crN9f\nccUVuOKKK0p1+kCQ4U0QBEGEkYhWWKMSawRBEER4iaZ4Z/5PljdBEAQRRiIp3jTPmyAIgggzkRRv\nJ9t8PFtBEARBEIURSfG20s2pPCpBEAQRRiIp3mR5EwRBEGEm0uJN2k0QBEGEkUiKt52wRupNEARB\nhJBIijcj25sgCIIIMdEUb5oqRhAEQYSYSIq3Dak3QRAEEUIiKd7MnipGEARBEOEjkuJtYVDGGkEQ\nBBFCIine9rokBEEQBBFCoinemf+T4U0QBEGEkUiKNyjmTRAEQYSYSIq3Ux6V5JsgCIIIH5EUb1oS\nlCAIgggzkRRvWpiEIAiCCDPRFG+KeRMEQRAhJpLibUHzvAmCIIgwEknxpnneBEEQRJiJpnhn/k+G\nN0EQBBFGIineXMoaQRAEQYSOSIq3vSQomd4EQRBECImkeFuQdBMEQRBhJJLiTQlrBEEQRJiJpHgT\nBEEQRJiJpHizTMIahbwJgiCIMBJJ8XZqm5N6EwRBEOEjkuJNtc0JgiCIMBNN8aZVxQiCIIgQE0nx\ndvzmJN8EQRBE+IikeJPlTRAEQYSZSIq3BRneBEEQRBiJpHhTkRaCIAgizERTvO153mR6EwRBEOEj\nkuJNi4oRBEEQYSZWyoPfeeed2LhxI1RVxVVXXYXzzz/f/m716tW45557IMsyZs2ahblz55ayKQK0\nnjdBEAQRZkom3mvXrsXevXuxaNEi9Pb24hvf+IYg3rfddhsee+wxTJ06FZdffjkuuOACnHTSSaVq\njgDLBL1JuwmCIIgwUjLxnjFjBs4880wAwOTJk5FIJKBpGmRZRnNzM6ZMmYKjjz4aAHDuuedizZo1\nYybeNmR6EwRBECGkZOItyzKqq6sBAIsXL8asWbMgyzIAoLOzE/X19fa29fX1aG5uznm8urpqxGJy\n0drHGBArk9HQUFu0Y0YVuoajh67h6KFrWBzoOo6esbiGJY15A8Abb7yBxYsX4/HHHx/VcXp740Vq\nkQkDkFY0dHYOFvW4UaOhoZau4Sihazh66BoWB7qOo6fY1zDbQKCk4r1ixQo8/PDDePTRR1Fb6zSg\nsbERXV1d9t/t7e1obGwsZVO8MEZBb4IgCCKUlGyq2ODgIO6880488sgjOOKII4Tvpk+fjqGhIRw6\ndAiqqmL58uU455xzStUUXxhoSVCCIAginJTM8l6yZAl6e3tx7bXX2p994QtfwCmnnILzzjsP8+fP\nx7x58wAAF198MU444YRSNcUXZqo3QRAEQYSOkon3nDlzMGfOnKzfz5gxA4sWLSrV6QPASLsJgiCI\nUBLNCmvIhLxJvQmCIIgQEl3xBkB+c4IgCCKMRFa8wRhZ3gRBEEQoiax400wxgiAIIqxEV7wBUm+C\nIAgilERXvBnN8yYIgiDCSWTFGyC/OUEQBBFOIiveFPMmCIIgwkp0xRs0z5sgCIIIJ5EVb6qPShAE\nQYSVyIo3STdBEAQRVqIr3qTeBEEQREiJrHjTwiQEQRBEWImseJsLk5B8EwRBEOEj0uJNEARBEGEk\nuuINWpiEIAiCCCeRFW8qsEYQBEGElciKt7kwCck3QRAEET6iK95keRMEQRAhJbLiTX5zgiAIIqzk\nLd7pdBqtra2laMuYQkuCEgRBEGElFmSjRx55BNXV1fjWt76Fb37zm6ipqcE555yDa6+9ttTtKxm0\nMAlBEAQRVgJZ3suXL8fll1+OpUuX4stf/jKee+45bNq0qdRtKy000ZsgCIIIKYHEOxaLgTGGd999\nF1/96lcBALqul7RhpcassDberSAIgiCI/AnkNq+trcWVV16JtrY2fO5zn8Py5cvBQm65mq0n9SYI\ngiDCRyDx/s1vfoPVq1fj7//+7wEAFRUVuOOOO0rasJLDaGESgiAIIpwEcpv39PSgrq4O9fX1ePbZ\nZ/HKK68gkUiUum0lhRLWCIIgiLASSLxvuOEGlJWVYceOHXjuuedwwQUX4Lbbbit120pKyL3+BEEQ\nRIQJJN6MMZx55pl4/fXX8e///u8499xzQ7+cprkwSbh/A0EQBBFNAol3PB7Hli1bsGzZMsyaNQvp\ndBoDAwOlbltpoQJrBEEQREgJJN7f//73cdNNN2HOnDmor6/H/fffj69//eulbltJMRcmGe9WEARB\nEET+BMo2v/jii3HxxRejr68P/f39uP7668M/VYwsb4IgCCKkBBLvjRs34r/+678wPDwMXddRV1eH\nu+66C2eccUap21dCqEoLQRAEEU4Cifc999yDhx56CJ/85CcBADt27MDtt9+Op556qqSNKyVkeRME\nQRBhJVDMW5IkW7gB4LTTToMsyyVr1FhA5VEJgiCIsBJYvJctW4ahoSEMDQ1hyZIloRdvq0AqQRAE\nQYSNQG7zn//857j11ltx0003gTGGz3zmM/jFL35R6rYRBEEQBOFDTvH+9re/bWeVG4aBk046CQAw\nNDSEn/70pyPGvPfs2YOrr74a3/3ud3H55ZcL382ePRvTpk2zLfi7774bU6dOLfiH5IvpNie/OUEQ\nBBE+cor3tddeW/CB4/E4br31Vpx99tlZt1mwYAFqamoKPsdoIKc5QRAEEVZyivdZZ51V8IHLy8ux\nYMECLFiwoOBjlBLGGCWsEQRBEKEkUMy7oAPHYojFch/+lltuQUtLCz7/+c9j3rx5Y174hbSbIAiC\nCCMlE++RuOaaazBz5kxMmTIFc+fOxbJly3DhhRdm3b6urhqxWPEy3Bkz/2toqC3aMaMKXcPRQ9dw\n9NA1LA50HUfPWFzDcRPvSy+91P73rFmzsGfPnpzi3dsbL+r5GRh03UBn52BRjxs1Ghpq6RqOErqG\no4euYXGg6zh6in0Nsw0EAs3zLjaDg4P4wQ9+gHQ6DQBYv349Tj755LFtBFVYIwiCIEJKySzvbdu2\n4Y477kBLSwtisRiWLVuG2bNnY/r06TjvvPMwa9YszJkzBxUVFTjttNNyWt2lgDGQehMEQRChpGTi\nffrpp2PhwoVZv7/iiitwxRVXlOr0I2Jq9/iqt6Kr+Mu+VzHz2H/A0TVjN8edIAiCCDfj4jafEEyA\nlUnWtm7AO4dW4e4ND+ZVMGZf3378ZMV8NA+2lLB1BEEQxEQlsuI9EbzmKS0FAEhqSazc2hp4v+f2\nvIRhJY5X979eqqYRBEEQE5joivcEW1Vs64fdgbcdb3c/QRAEMb5EV7wnhO1NEARBEPkTWfHGBLC8\nGVdhnYYRBEEQRFAiK94TYWGSidAGgiAIInxEV7wnwsIko6zlzkj+CYIgIklkxRsY/8QvEl+CIAii\nECIr3lRhjSAIgggrERZvRtpNEMSEojvRg2GluIswER9Pxm1VMYLc5gRBiNy85tcAgAdn3znOLSEm\nOhG2vM3/51OWtPiNGNfdCYIgiJASXfHOSN94us4LtbzHdcBBEERJ0A19vJtAhIjoirelm6SDBEFM\nAGhQTuRDZMXbYjynixXq9majnB9OEMTEQydLgsiDyIq3E/Me11YUtBeN0Ani44dBbnMiDyIp3s2D\nLdg/+SWwqoFxbceoDWiywAniY4NOg3IiDyIp3ocGD0ORByHVDEwcy5veW4KINAbI8iaCE0nxlhj/\ns0k1CYIYf8jyJvIhkuJtJ3wxY0TLW9M1pDWlNO0oyVEJgggjlMtC5EMkxVuCM09spNflptW/wnXv\n3FiSdtCrShCEhU5ucyIPIinezHKbM2NEBe1Ply6pjUbaBEFYUH9A5EMkxVvixHs853nTSJsgCAuq\nsEbkQ0TF24k2j+dgd7QjbYqZE8THB0pYI/IhkuJt1RRnbHxflkKt/vH0FhAEURrovQ43cSUxpueL\npHg7U8VGzja3KEU8imJcBEFYkNs8vKxt3YAfr7gF69o2jdk5IyneQsJawNFuKUbFNNImCMJiIpVH\nNQwDN6y8FU/tXDzeTQkFqw6vAwCsad0wZueMpHjbMW8WfLpWKUbFNNImCMJiIg3mVV3FQHoQq1vX\njXdTQsVY5iFFU7yRv9u8FELLu80Le20pZY0gPi5MpIS1idMSIhuRFG++wlpQSiLeBSesEQTxcWMi\nWd7kFcyXsb93kRRvMWEt2EUvxaiYEtYIgrCYSIJJi6QUBhtDb2hExZurbR5wn5LEvEuRBGcY+OtH\ny7C398OiH5sgiNIxkcR7IrnwCX8iKd7M+tkMgb0dpaiGVors0s5EF5YeeBP3vv9I0Y9NEETpILd5\neBmPsU4kxdupsDa+lncpKqwpujqqYxIEMT5MJGuXxDtfKOY9Jlgxb8aMwEOmieg2P9w1PKFeeIIg\nCmciCeZEakuYYIxi3iWF5bEkqMVETFg73D2M3Qd7i3pMgiDGh4n07kbVKDAMA6ta3kNfqj+//UrU\nnlxEUrydVcVyG978yzSRporxjVY0sV3RfOUIIvxMpAzvidSWsWRL1w78effz+J9ND493U0YkouId\nbJ43L9ilSC4Tj1+Y7MZk9y2Mtnxv6tiCBVsXktuPCB0TydqN6vtjWdxdie5xbsnIlFS89+zZg69+\n9at48sknPd+tXr0a3/rWtzBnzhw8+OCDpWyGBxZwnjcfk9YmkuXN4RbvieR6Gw8e2/YkNnduxaHB\nw+PdFCJPDMPAju7dSKjJ8W7KuFBqT18+TKSBxFgSppUeSybe8Xgct956K84++2zf72+77Tbcf//9\nePrpp7Fq1Srs27evVE3xYJdHHcHy5q3tkixMwr+seiHHNyBLYoJE0EGGbujY17cf6sc0O30iTbv5\nOKBoCnb17C2pqGzr3okHP3gMj25dWLJzTGT46ajjPQgf78HDuDHKy/6xKNJSXl6OBQsWoLGx0fNd\nc3MzpkyZgqOPPhqSJOHcc8/FmjVrStUUD4yfKpbjZvEP8NvvNxe9HbzAFPTM+MTsNUMLtOuKlrX4\nn02/w4sfLgm0vW7o+OP2Z7C9e3e+rSQ+Bjy75yXcv3mBvXpSKWgdbgcA7OrdW7JzTGTEtQ5IvMeD\n8b7u+RAr2YFjMcRi/ofv7OxEfX29/Xd9fT2am3OLY11dNWIxuShtY8NK5h9AfX0NGuqrfbcbTjvn\ne2tzC67959qinN+iosm5PnJMQkNDsOPLsuP2nzylStivw6i0/53reIf2mtd7V9+eQOfd3fUh1rdv\nwvr2TXh2zu+E74K2eyypq6tBQ/3Ea1c2JuI15Nm5xhy0daTbStbWSV3Bnt1sTPRrOBK16Qr730ce\nNQnlctm4tKOhoRaDcpXw93iw8uB6/Hbt47j3oltwzORpY3LOSb3OPcjnd8diZp9cXi7nvW+hlEy8\ni01vb7xox+pLZY7FDHR3D4Fp/tbqkDLM/WWgs3OwaG0AgHg8Zf87lUoHPr5qZZgzoLtnGJ215fZ3\n3b3OMXIdL5Uy3eWapgc6b19/wve4DQ21Rb8uxaC3dxid2sRrlx8T9Rry6JlnLplUS9bW4WHnfcj3\nHGG4hiPR2+/0cZ2dAyiXy3NsXRqs69gzMMS1pbTX1TAMrG5dh0/VfRJHVtXZn/9u3RMAgFe3v4NL\nT7q4pG2wGBxy8i3y+d2KYmpIOvP/Yl6zbAOBcck2b2xsRFdXl/13e3u7r3u9VDB+SdAc2/FuLJbH\nCmRB4c9eWIKI4dkvqLvLOnfQGI3MIjkxYUx4cPEHeOHdiV2L3nrKSlmEYiwLXExEJlbC2tidf3fv\nPvx51/O4a+P9wufhcWA7fCxi3rmYPn06hoaGcOjQIaiqiuXLl+Occ84Zs/NbU8XYCAuTCA9wKcR7\ntC8rM2C4Et00PVjMmztIoK0kVpyQBeFl6ZoDeGX1wfFuRk6cwR5RKvQSJ8jmQ7GyzVcfXo8POrfn\n3KY/NQAAGEwP5dxuTCj4d4/9/SqZ23zbtm2444470NLSglgshmXLlmH27NmYPn06zjvvPMyfPx/z\n5s0DAFx88cU44YQTStUUDxJvReaaKiYIavFvjo7Rj7Q1vVDLOz9KMc+9lJRial+kcUzvkp1iLK2W\niYiQwPoxyTZ/atdzAIAHZ9+ZdZvxHqjwjLYlY/kEl0y8Tz/9dCxcmH3Kx4wZM7Bo0aJSnT4ndicx\nYpEW7vsCLW9N19CT7END9ZGe7wTLO4/Hxt6Ped3mQbPNrUFL0IctbGI43m7HjxtWByuVsHuKtnSL\nz2wplgvOh7GssDbeAxWeiTRJJwsvAAAgAElEQVSQGIlIBjKDructPMAFivcfdzyN+WvvQNPAIc93\nujA1JPjL4jzsBnTXbqUS2bCJoR50EEMEwnlTSiixFPP2/Xcp6Yh34qUPX/PUexjLwXrWXngCifpI\nUG3zMULiKqzluupBY94dfQm0Z8mG39SxBQBwcNA7FY4XbLf7Oxd2u5g3NpX3SxewwwybGIbNUzDh\nsZw9pdTuiNveYhhtbOTg3k0P428Hl+O9to1iW8ZQOCeU5T3qtnzME9bGG7s8aj4Jazm2/OnDa3DD\nI2vzboc40g4uNrpgebti3gET1vJ9RMMmhmHxFJj3cnQdRutwO1YfXl+cBmXBEpaoCywAvLr/dTyw\n+dGiH1es6Dg2z29/2pzSFFcSwudjmeMyUogg6rMQshGaed7FhI/b5axtXoSYdy6EqWJ5vKxWu5hv\nzDu/ly6taDAMY8QXJCxiaBGW9i7csQiVf78FyU1fKfgYt733GwDASUecgMbqo4rVNBck3hZL9r8O\nwHzGpCJOoSzGQkXFohjvT9DfkG278bgCxVjpcayIqOWd/6piJZnnXWCMS0hscU8VC+zeNvfr6kti\n60c9eZ0zn+lomq5hQ/vmMV9sIiyegnXtm8BiKiCNPizxynulWx/AfjzJbW5TbIEVyyWPs3gX4fz5\n1pyYEBSq3Zn/j6WTIJLiLQmrimXfTrSGSzxVLHOuzR1b7XmPWffjs82LMFWsuWPkakC8GKZ1JdA5\nAGBP74f4w/Y/e2JqpSb/+e4OhmF43IglpwiDw1Vb2ovQEH8sN24pBXZCdeIBCD5QDgbvRRvvVb2K\n4QUIo3iPvi0U8x4D2MjZ5qV2m7ss7/39TViwbSHu2vBA7v24QUXBU8XyhH8R01pw8R7OlJhNjEIM\nN+/twuGu4ZE35BiN2+/PuxbjxytuQUe8K+d2mq4hraULPo8Am9iegrHoXkv17I6G/f1NeOWjv/kK\nWLG9O+ORbW6fz3WHi7GiYlDrfbxDBDyFl2ght/mYwcBMV3jQIi1ZxJt/8DT3vK0sWPu4RXggbVrc\nvam+nPsLCWuG+7v8O5QgCSF8trmiBxcsy0rPx1rnSaZV/Pb5LfjZo+/ltd9oxHt1q5n8tb8/d9Wz\nBdueGHGgFRQmTWzxtusClNAvOBHzFO7e+ABeO/AGmga9Uz3f3ez9bDQIS4KO4TxrP0QvQGFtCWx5\nZ9lutII4mB7Cjatux8b2DwLvM/qBxNiJeITF2/zpubPNR74Rmm4ATAMkDaqWfXvroXjn0Gpc/87P\n0JXocS0BGDz5xcjhNg/sLuaCmEG6Y61AyzuVsUyVPPbhSasFVp4bAyFoj3eiM9FdnIMxffSu0hJ4\nhyzyrYU/EqqueuYWj4d4B13PPq56PUeL3i7u0qUTNWGt0OeyVNUeg7KhfTP6Uv14fPtTgffJJ3HY\nd/8xvG8RFm+YnV3ged7+nauq6aia8Tqq/vfrzmpfPlid1bN7XkRaV9A0eMhTHjWoePMPWK6Yd+AO\nIEB/zIuhkocVbbmVC7W8tRwDolwUY176SCP/lJounqvXZyBWyDGCYBhGXgMwgEvIKZJ4z3v3Zty8\n+tfCZ2OdZPjCvlfwo7f/G73J3J4uIIvIj3KwpOka5q+5A3/9aBmAwisuutENHQ9sfhRrWzeM6hgW\nBbvNixTzLvSZK2S/0Q4gx3IAGlnxNn+6d6oVj1hhzSuUAARrW+WsRFXThZdR1TXs69vPnZ25LG8D\nEnc7Fu54Nru1mrM8arCXLt/XkRfDfOK8tnjnIRaarmPN9jbEk0rOAVEu2nvzi5H7MdI1Sutp6IZe\nnBdW0vMq1OMHY3qgAdua1vW47p0bsac3j5XMimxRqLqK/rSYmFmKjq+9N46uPv98izeb3gUAfMi9\nl9lQfTxahc5A2dm9B79Yexeah1rQmejG0gNvAihezPvwUBt29uzBwp3PFnwMwUAo2G0e7PfoAcON\neVOA5o/2GRxLj0lkxZtlEtZydZjued7Wtu+1bsTWrh0AIIiLwv37yrvexq+e3OR8Z6iC603RVY/b\nnBfbtW0bsL59s3+77O183OacyOZ6EO1zGcFGqELCWkBXo7mtKdr5WOtvv38YC/66A4++shPKCG7z\njngXdvbs8Xy+dH0RVunKNbAzDDskMJrMdhumF8XyDtJ3vNm8AgDw+oF3Ax/aeuZG61Z0ww8ESyHe\nNzyyFj95eE3ObYJYucW0vB/a8jja451495DYLjHmHezYh4fasNc1CCuoVZ7cGV54CxVv573IlQ+k\nGsH7k3woxPIerSeNLO8xQGIZ8c7hlnVXWLM61yd2LsLDW/4IAEgqTudjHct68Pe19DvfuTKTVV0V\nOg3DMDwPTvaXxrK8c5dHLeaDJLjN87C8U7bbPPg+h7tNq3nvoT785eALKD85+zSzn6+9Ew9sfhRJ\n1zzyYszLz3UE1dDs66sWwXXOimB5A7kHoxZ1FVMAANsPHUYilV/HWezOqTfFvSPjlG0exFry9TYV\neYaAuERwsGfh9nX34N73H3EfqQhtGf0iKfxv+O3z2ZPGShUuKcTZzj/fKSX482jdu2IPbnMRWfG2\nEtbcbtk/bP8zHtz8GABvkRZNNzydV1xJ2f+2LG/Vx1pUdVVwHZuWt/iCuC04SfJfQ9sowPIeiKfx\n/DsfYiih2Ps6v833NAKi5Z1/zDuvhDVrbMIYdvRvhVzXOeIunoSioiRvZT+GeyA2aoqRsCYFs96P\nyIg3ypIYiAcbVNmdU5Hdgny8ebyyzYOIU1Iz3/Og6x0EOq/rWopx5sKvRTGmLQV1eeduh/Mbth3I\nntg5kueq0CyLQmZG8Pfg5ZUjh1Pc+5HbfAzI5jbf0L4ZO3p2I60p4kuQSShyW3jD3PxlRTUfQr84\nrWqogutY1cXjG4buseBizBTvpJrC1q4dzgNiq5vPVDHd3/JeuGw3Xl1zEIvfNl1szmg3mHNJFyzv\nPMTbdpsHFzg7OSpLw57auRhvNL0jfJZUU0Vffz2XmKQ0Z9BWFIuxSG7zIJZ3dazK3Lw8hbSSn0gU\no+Y1f10ngngH6XCt914rgng7AyGXpw35CaZoqY8yVut6X4oT8w72PmZ7f0YrhIW5zZ02t+RRW8K6\nXn3DqTET8OiKN2MAjKwJUYeHWz0Pn6YbQplPdyWutC3ePoltLstb1TXXkqBey1vOWN5P7nwWD2/5\nI95r22Sf18LdWfMvwq7mXrNdWhr7yt6EVNuDgWHT0so3SYTfvhDLO69iJr5rjRuZrwysbl2Hv+x7\nVfg2riY8VpG7c1u0+0UhaXAk/JKULETLuwjiHdBqzk3uBEwL/hlJKcEGVVbnXgwXJ38MvqbBeJW0\nDWLlWpa3xg9CR5tt7vq9+VZYS3HPYLGvXdGzzXOEGEYa/Bbqti8o25zr52Qp+P7W/ersi+ddUKpQ\nIiveEpNyWirNgy0+CWu6IN6qriLBuc1Tqilqvpa3rglxX0VXPNnm2R7ibd27AACtQ212WwDTle8e\n5fEvzKOvbAMAvNe2Cenqw6g4dR1k2XwgRfe672kF+M4hHzexPc87D8G3m8Ob3pna39muUcJHvPl7\nu7f3I7zbshr/s+l3gduRq81Cx1kEtzkLaDXnPkiwY/AenoFUfh1N8S1vJ+Zd7Kzj1w++jfJT38NI\nXpggQplUzfdc9I6J+71+8O28BoduizZfwRxSnHvHD/yzJYc1D7Zk9Zq5zybO8x59tnkuHc3mNrfc\n3gVbsqPINjeMTF5UnvuVstaCm8iKt1VhLZvl3TTQ4hED3WV5J7UUkipveWdcxPYxnRup6qLbXNFV\nYcRvGIbHgrMeaqsdEpO8Yp3D8o7FzIePd/Vbo0nntxmBKsPxLr7hVCrHliKFTBWzZ8LxH2YqkGU7\nTlxJuFyaujgToIB55rksal68i5GwVqjlzT8PLKDrne8sh9P5la0tiuXNnT/BvT/Fdpu/+OESyLW9\nQCy31yeXOFi1F5Jaxm3OtZ1x1mRfqh8vfrgkr8HhaN3mQ8qQ/W/+vfcb4O7r249fr78Pf9j+54Bt\nyz95znuMoJa3+Z3bUrauQaFhqdG5zRlYXpa305+WxcZGViMr3tZLyVsq/MPWl+53WRmmVWO9xIAZ\n94yrnOWdERYnYU0Ub8FtbqjiCwLd85BaosCLdy7r0v0bYhkrm7eUY3Lmd3MjxSDWGn/cjXuCL4Bh\neRvyE0+vejNJzXkcP7c5H74oxPXnN4Wlsy+BVFoTYt6FJqyJtfPNbPP+4TT2HerPvpML7/MwsgCK\nbvP8BjXFSFgTMnp1f9fvQDz4AHEkmKQJ1zqtKXh8m1N1K1eGcEwyV0223OZqFrd5IdMFvW7z/Kzd\noTRneY8wRbRpoBkA8EHXdt9juT0qQm3zIoh3rtkfVtuzJZiNdP6mgUNY17bJ83kh77w9oDKAPLTb\nuV6MxLvkWG5z3jrjLa0D7b3o7I87OzBvzDuhJtGTchavUNwxb65etWpoXsvbNc/bLd6WO9Z6CCUm\nuR5IvyItXsvb6nAMwxF0e7sRpss5x+UGNvHg1po1YAki3gcGmvBe60bbjS+8yyNZ3i7xdruhC+mA\n3KIcT6r4r4fXYP4f1wsx70ItA08FP93Ajb9fi18+uRH9Q8HES3GJSb6Wd1LNt9Ja/taxbujCteSv\nlzjP2/n8xZXBljcN5K2QNeFZWN+2CRs7nKlL1rPRNtyB5/f+VbimsmV5+7nNBUEaXXIU4LK8AwjP\nYNqxvFXN//pajBQ3zjmQCHjPDcPALxdutJNig67KaD2P2Szlkc5/x4bf4k87nvHk1RTiyeH3kfJQ\nb/76lcf8ZwkVm8iKt5Wwxr/UfAczlErgjY3N3A5et/lfP1qG9wecQguWsNgDAsYPDFyWt6a6Spl6\n3bTuF0p2u80Z4H4+NcHyzrTLEk5dhiyZt5yP0eSb5KQjuFg5MW8VHSNUPbtrwwN4Yuci6LbFy7VL\n1jLHca4hf/0SakLstJgBjRuYFWR5u8S7f9jswNt74qLbvMCENf5eMUlHe6IDyjHvA5KKwUQwURV/\nc7C54rwApfIU70Lc5o9ve0pYwEVcoc6/SMtQcuR2abqO/3Pncjz4l605t2OyKgzSU66aA9Y1XNu6\nAW81r8DBAee9t4QlZSesic/YaFy7brd5vtOz+Jh3SuXE2+d5HEnIPPF310yYIPx51/NomvQGlqw9\nmDmmmDOUjZEs76DeHvf7Wsizyv/ufGLe/HoT5WVkeZcUO2GNL2/Ku0llTXTb+lje2zOJZBbpzAtk\ndxSSy22u83FS1TXS1j2JT+6/FdVwjaANaAZvUbyPHd27nZ/gsrxhSHbM237Bme5reauajieW7cb+\nVrOEZT4uvfZ4p/0w851zc2fudcrt42cGB/xKW5brk7+G/GBoX2uXZwlXvsMuxPJ2T2/jhVFMWCtU\nvEXhfb7pGcQaWhCbdiDwMVSXmASzvJ3f5SfeSTWJJftfx0Dau857IQlrLcOtaB3uQHOHaSkKbnvN\nfzDGAhRASabN42zcPUIdAFnNGh4DnPdjWDE9bYoQ3jLPYeWNCH0EV9GukFr67hBHvstwDnIx73jK\nabOfaOUt3vxAKhFspsjq1nWQpzjzuYPOibfFO5vlHfCZU1zvoV7Ae+ncR5aX5W17B5hhhyZLDYm3\n4DZ3Xkwmq6ip4t0f/vO8eWwXceaYTLC8NaFTUHTVNaI0PC+d++9XVh/EUJJ7kVyd9R93PC1sH4s5\n5wIA6JL9QDqjXW/M2zAM/PfK27F68BXc+idzcQPBS8CyvxTLm1fiF2vvwnttG6HpmtBRJ1V/V/BA\nPI0Ff3VicTrXNhvJdH2K19D594HOHtf1En9XIZaReyTPl2oVE9YKi3kLnZKkY1jNWFKyOuI0dd3Q\nM1X5RDEJZHlznVpa9bZ96YG38Or+1/HEjkU+581/EJRQk1B1Fbc8vg6A+FyL8+VHjpFquobVh9dh\nWIkHT/BzrfjnHshZ9zmumuJt3U++bn3S1/J2PB2FeF/cz6S74uJIJBQuhJfOXXdgJAH0Vnd0zv+n\npbvcmwfCT7zjStweJNnn1q3+cnTirbpCc4VY3vw+hWSbM2aUdNlcngiLt2WVGuhPDeL3W59Ay1Ar\nt4GGygpOvJlpeSW07OJtjfxWdr2FshM3u2LeqjA/2jNVjOkeEVA0Ffc/v4Vrg4FhVyJPrs7UmhZm\ndZCGLtnb58o2Vw0Nw9og5HonMU1c8CT7S2EtsrCn90NPSdRs8dU/vbYLa7Zz57Lc8i7xVjVduIat\nvQN2QhFkRbR+mC502PkUibFwi3eaK5dYjHnebsubf+VHEuH5a+7EXRseEM7NCgiB8JZvQk2gN9mH\nvkzJ0o54l2ffQizMhJrM5C9kXMy6/3UULG/J/3e827IGT+1ajD/ueDrw1Domq2IIxSPeZnusmg3W\ns8K303oWsl3vfAaHllXtfr54yzvlM6hyw58zkfb3YDifjTRdTs8MiHTPMQ735Dtv2XsM613+8Yr5\n+MmK+cLWlndDGqXlXYwlZu3pikZ+MW9HvPM+ZcFEVrxlzvJ+df/f8EHnNjy6daH9PZM1lxhkss1z\nWN6KZiahbR1cj9iRbULMeyCehKIpqJQrAQBDiZSrgpvucb/2xRPYOvSesI3bWjdydGBWzNt29RuS\n7SK3xVhyrLUN7Zsx962f4EB/k3MQybFC7GZI2V8KKw43tbpBsE4BIKmm8beDy7GrR1wHubtfvKa2\nNelym2u6uJTlb19433lpYgpSqni/xKliAYuR8CvBuTrk1Z3vInb0RwBEi/GlD5egdTh4Br6FO37K\nx2lGWk2tO9mDg4PNruxnb8w7W80BizQ3oPrvlbfhZ6t/6cyvhXugl7/lLazbLXk79XzFuyNuusgP\n9jcHX3FOVqHybnO4B6sZt7kqus35+2/dK3dehT4Ky9ubYOW0cdn6JvfmHvh7n+CK7eSKeWdzTQ8r\ncfxkxXz8/O17he1N8vS2ZO6zO4zFIxaaylJhzX7+gp3f/Y6PLmGN5ZVtrnMx77EisuJtThUzpxNZ\nHbG7s1YEyzGTsKZ4xVsfmpLZXhUqRjHZeZj6E0mk1DQqYxWAwXCgox8qb/FKuqcD6Ex2oOw4TuiY\njjRfN51BiHl7yDxIjngzu8NzXhhHvP+8azEAYEWLk4QnVZtxzyBzNnmXtgFvZviA0oeXPnwN929e\nIHwedy2OYbnDhbinpEHTDMFVnuBLokoahpOOoDJZhaJ5LScA2NK5HS99+Jrvb+B/p9A5qgls6F+F\nsuPMFcz4jrcz0Y07N9zvezwgUxXu8DohO9h9LiG+n6P+gHU8C7eYpFUF27p2QtM1/GnbYly98A9Y\n9JY4WOJd7fxvtLwa1vGdZCxuEKTlJ1JCqCRzP/k2q4bmqWdg/RY/+E+DrvXutry9MW/R8rbEXLC8\nDS1Ti8E/TKH5hE529exFW45BnbtSIX9f9x4aeY1xISSVzl1tjZ9u6kdP0qzGuLPTfFaEAY5rStwH\nndtzV0z0uc/uAQCfO2QZSdnE9kBbf6AwgidHZTRuc2YU5jYvQlnmoERbvEeIEabBiUFZGqqmCxme\nmW+g9U4FYFrezYOHna9izsvJmI6kmka5VAZmSADThIpSTNI8bh/eujO30ZHW+G2ckb/fw61lOlq7\nEAa3chWfbW51gpalXCaXOees8iYZIYvl3ZFw3KyqrnhecL6oBM+wOgT+5bZeQjHmrWcsb+eYjL++\nki7kA8h1nXi2yfGk8KL/yNY/4W8Hl3tib4A4gOM7g92uZRfdXgX3bx1MD2H14XXQDR2rD6/DU7sW\n49FtC4VtcrnNlRzizT8n7oS1NV3v4ndb/oC/HVyOdR3rUPa/dmPZumZhf02wfFUMpAeF+LY9tdDH\n8u7o83ehGoaBjngXdEPHqpb3sLJlLQAIdRGsTt3dSVvhlSAxb6euPwRrOieyKgi9Z3qlK+Zt3Xd3\nGEs33NM5s1vehmHg/s0LcOt7v8narLQrWY8XzKpy73SjXT178cK+V+x3nT8n7zb3c+Fbzz8v3oet\nio3wGi7ZrN23D63C77f+Cc/tedn/RwGO5S0sfiQej0+GtNqraBo6er3vZGvPMLoHsns8LXpTfXhg\n86P2bIHRWd7BY9eGYQjP5VgRG7tTTSwkiYEx84HJVt9ZNRzxlOs68GLbkxjSxRFxDGVI65kVynQN\nh4Yc8WZ8ZSemI62ncYRcC0OXMi5wJnzv7gASnpWyxKph/MIkfm5h1dCxu2cf2jOuRiZpUBXXqNhn\nNas2LsYlH9UCTdc8VpHl6m5oqLU/5gcbO5q68Kl6cfAxrHvF+73WjcCn30Cs5USu3SqAMhic65Rl\nYt6KK6nQ+UNHPCkKaGvykP1vv+szkEigpqwahmFA0VWUy2VCJjYvku41w93i7ebFfUuwtm0DupO9\ntsXdNtwBAFjXtgn1lXWoKat2dpB0iG5zJy7alxrAUVX1vud2DwAOJ8zf/EHntqxt458zRVPw9K4X\nsIUr3uHuyMXYr3+H+H7nVjy27Ulc+HdfsfMevnjsPwgWluVdcFtEKS2NqliVJ4EvFwxMsKZzbitr\nQrvdGfOKblr/1nX1i2+b7dZcgyWds7xdBZYChGn4nBBNFwvJTKrxds2Wx+qLx3wBjdUNrmTQ3DFv\na6BgWZPt8U7cvu4e7vvsc6R54W0aNJ+vPX3iYJaH+Q3SfMR7Wk2j2fZMoSAdBnYe7EVjXbWwLXNZ\nwX/e9Tx6kr34z8/+H2G71w8uR9NgC5oHW3DHzFsKnL7nGDW5QpK++2T2GysiK96yXWFNz7osogbx\n8460KcxGugKs3BQmCTHAsMRbRWecc5vz4i3pUHUDMRYzxVvSoRuS63vxYbOzj7ltFC6RhTGnSEXC\nJxav6Tp+u/n3zgfctDC+SEtaSwnuzUO93UDm/ZFr+7CpfavHbf7j360GYGDu/3cETqo6GVMqJmM4\n5bThw9ZeHJpuJj4ZagwspiKuiVOPdEPHEztNi0+q7bE/NwtOlInueVnzWN6QObejpGM4x9xgv850\nOGUe6087nsH69vdx58z5wj3g9+lO9HB7Glndhr2DKcgys7OT325eiZPrzIHJ5PJa6IaOP+14BgDw\n32dd5+zIxA7AqtL38JY/YmfPHtzyDz9BY/VRaB5sERZlcbtx5cxKdH2p7NPy+AGKomueAjqWWFsi\nl6t6198OLsf+/iZMygxE1hxeJ3wvPJfMsuTF59y6lmLdgyydIJ+TENBt7rG8Xa5N1VCFJWUVzXKb\ni8+M6po9wce8xdriWqAcC/73aoY4QJ5Ulb1rtlrP33veAPETLWugYFne7ZmBpIW7/+AHOJLEf26e\nPaeBaec2ZI9585a39c5lre/v+nzV4fe828AZFFre0cIsb6stpvETaB9k/52lJLLiba2VrWreetCG\nJoPJGjTmLwZ6vBZyRrxlowwwnPnUCZVz+8R4cdHMzXQZhi6BSRp0Qxa+t146QykDK1OQ0FwuJKYj\n7eqwrEzxpNtKh0/MR3Isd7ueMAN2TXkG8951NksjDgmAnqiBVDWM1qFOT0ERAJBqe/H4pmUAgF//\nw2043MMJBtMRz0xfMdQysJiKhCFa3v28wHC9wUDNLrCqE6HpzuPJJA2apgtCI5W5LO90dvH2q/CW\nSJsd1vr29wGYyVBTKibb3/OdoxC7lTRfy1s3DMx7cBVqKmM492IzDyKppewFZSaX1wqdulgn25tZ\nDzgW/8/X3onZx83E6sPr7IGB2a6kcAyZmSGPQVeI4sBAE1qH2nH2MTNciVgqKuQKYVvrd+s+bnP3\n/GMrd+Dso2eYx3M9c0KCJ9N9t7Ey3nlRV7ItE2kdCixwwpq7SIt7IKfqKuJcCMVyl7s9EGbynSuJ\n1XJhu+L4+c5uMN3mvJt55H2EWQMjFGmx8lGkTKTUPYBxT+PkhVcKEFz185ro7hADt43oNudyKlS/\ne+qItzvRjXdty654vuYaDAZxg/P7BF0op9hLEQclsjFv60armuYZoRlqOQBAZ/7WlZGqhqGZwish\nBmTc5oquCet7szIuPpt5bnRNAnQ5464WBdHqVFK7zjK3dU/JYoZgeQPOg+M3hU2F2ZZjqo+GHp9k\nir+RQl+qP+eo1Gq3kTKtqe64s73l8q84bQ0qTnWsrD++uxqDKW4AIWlIqpnfn7meKcPxJOiGji7O\nmmXlzr6pynZUnrFarOSWmavLxwljZZz4SQbiORZM8etMh9Pi9hKTRMubi3kK+QeS5qnSBQCHMkVI\nhpPiIjRdSfN3TiqvESz2fn7aH+82lzTfmPeunr2CcANey1bOMh6/a8MDeHLXc9hysEXo3BVdRaVb\nvA2rnK7XJZxtmqB13dxWutA+y21uW/bmx9Y1EVau07KJH9d5c9eobbAD7x5a7b+LJGabeyvnJTHM\nW96Ze+cWwZSqCIlpLIvl7V6EKAiaoQvWbpL147X9b9pzzfdwORc7DnZnzsOLt3/Cml0syRXzdr//\nSVf/wfc9sk+1T3fWujucYJ5DtEj5bQZSjnjzIu8bbuDqcQwLgywxjMFc4s3/xn19+7GpYwtGQkxY\nLUC8yfIuPdYcPvdSnQAApQyoSECXsiyfl66AoZaDyQkww3Gba7qGFGd58wlVFrommdtLZpENw8gI\nOx/z1vxr4zJJ91gb1ujQ6iQZJOiqDBZToMimWB5bPR3N6oeQpCEcPPIvuHHVCLGgjLvfSFYBMFdM\nipVlzqvLgKxCqhYtuwFlAJPTjggwSbdH89ZgKAVHvNNa2hY1AHYYgkfoPK0iLS7Lm78aQznE208M\n4i7xdi/LqnD7iLFbDSnVK/y7m5yQid9goa1nWBgEPPf2HqDROig3kJM1X5ewX4JdwpUQlk28Le57\ncT3qPidaiRWxcmEbd8KaliNe7BzHm6Gt6KqnfQDX2WllQEzxdZtnm3plOKa3IMgv7FiKtw+swafq\nT0ZjdYO42prLbe7O8t7f3of4yZwoZElYi6cVr+VtJawZfChC8RQMGQnN0ITr3F29Ba/s34LG6iOh\n6podXgKAJ1/fiS+f+uS9/wIAACAASURBVCnRba7ygyZ+sGWAgTmDxozmjlQpT6zx7bMBA/7y7kdg\nDLh05ifEQY3PlEDTS+Fs45ewBmSZIsld596Us2iPoilCAp63Spxz3Ac2L4BqaKj+7A/xqfqTfX6Q\n9xhBLW/3AlZjBVnemu6aEgYwzezMjGzirVTYAisZMRhWzNtQ7ekmgGNNGrpzmZW0ZLrNZQ0pxE0x\nBMxsasttrmfpgJnumapjue0scYm1fxpaqxlj1TLiXS3V2t6BXNXR7NNYL7hSCUNnGEgPOpa3JkOq\n8Fr5iq6IYijptmvZUExXrsqc/XYd6hTiyH7ZxbzlzSQdmq6LGbqu+xP3mcaXypTQ9LOE4ooowKou\njuR7BuPoTw3gt+//XpgCCNk74JOZjD3NzjZ+FsTBjn7B3X64h8sBcE2L8+vE4mocMSYO7JIuy1ti\n3oGftRgNYA6S+Fiubqi2K9U+ZmaAkUyrSKU1jxj4Yf1eoRCRpgjuWOZymxuq+ZxbXgwhBjzC3F+3\n27xtqFNouxD3lbWslRTNg+kYTPuIt6sN8XTKE/M2dO8AR/WJeX/Uf9B35SsLTRfF22JYSeDgoDhb\nwBLHbJXyNJ/raN0Xa58gRVssshUr+evqA3h51YHMecTn130Ms+9y2siHddyDtjeb3sXqw+uFc1ni\n3c+Lt64IgyZ33F64J5n7ZiVTZkPMQwgm3sVYJrcQoivemZi3ZuhQDLEjLmOVmY2yjJ4NZouhbhiA\n7ljxvHXEKs1/s1SN/VliWLJj5OYBzHaYRUg007LQs9wWySveuh3zNh/c4SHg08cfaX4XM8/f1q5n\nP2YODF2GoVRgSB00H9AcbVMNBQleDJnmuPK0Cs/2j7z6AbozljdLTPE9piZzbviyFDb1rBfXf3bl\nJCQVr+X9u5fMrGs/MU0o4n1XNNEtCknHi3uXYneva4UrSUdKTcPQnfsYk2T0ZxIfYzJzxGz/p6H1\nH5nZT4yVT5nMiSo3eGNZxNtcA971G1zi7dcpl8V48U6ac5atZ9bQoLgsTKuWgarpeHXtQVd1PQNP\n/W0P3v3g8IiFNtJ6WhxcSOZCHvZgQDMHdZYXQxAd19xfq7qdndwEcZ53x7DpSramawrhK0lcVcwt\nrEzSMZga9nzv/k3JtDvm7Z9truqKcA7DMPDyh6/hiR2LspYI1gzNt2YDY/AMrvzmUaezxLyta2ov\nmmR7FbIP4s17xMe8DTQNHsKWzu3C4E2eegDy1IPm/HdPzXfDE/bjp7lmW5VP0TS8sO8VPLXrOeF4\nmmZgMD2Ep3e/4GzLFwACPAW0+OepOmZ6EQcyMz82tm/Gc3te8iRGFhbzdo5RyAJIhRJZt7m1upaq\n6VCNtJAwVSVXYxDwVHlSmk9G2XF7oQ0cCbnBnDKh6IrtNk/pCejQYegMTDLAMithxdTJUGFaWf0D\ngDTNsdAMPVMUkGXmcBuSfTwPTEfSNa1Nh4HOvgReXL0HqAegx3DGiUdh915ALzPFe/ueBCqOLstj\nLTDr4BKgVCBRPgjdqAPAsrZNNRQkVNUZDkq6bZ2Ws0pPpJSdsgLr2gwYBkMtjsIgvGtYGxXO6Fyu\n7cO7Xa+LG8gu8TW8g60tH3bh4ECz7zrGbrFP6wrKdGeOu6cojvWxrJqdlVoBWImLTLaTbVTNsC0d\nresYaJ3TUXXWMrDyJLZ37bSPUz3JgN3dMB0aMu2XNG5NeBF3JnFfnJuRwAxPhjQAlJUx68hg5UlT\nELUyQDJLyiquYjq8q/tQxxA0o9L+Wzd0vPm++eyffXqD/blfAl9aU8TpjplpibblrZndTzydguYK\nX6m6hp5kL25a/SscxY5He3cCN8z6AedB4SxvpqM3Yb5TzUMteG7PS2isOso5bybc9MG+LmzY3YH0\nsa62Ml1YGzvbPO9EOg2NiSJlddy8iCi6JrjN06qKIWUYBgx0JZyFO3g+au3zHQAxMG+ilZ/lnWVJ\nUHvwY+cVWHOqs7v1+9MD9pQwwHSb37H+twCAzzWeaX9efrxZ8zyZ1oS2W4MlXtQY04UBhlBZD7yn\nIJvbXMea1k126V7AuubOOfh8EDNXgMsJyJzPSux9fPufAQAX/N1sTC6vFfaz2xLQojZcBW0KXf88\nXyJseTtTxVSID/KU2JG++6itn0Bi3YWAUokyyezkE+kUKsvMf6cNUyyNdJWwX4XOZTAnY+KgwBJD\nKeNW0l2WOQdjOpJpl3jrGu5b82cMxMyXrUKqQCzjVUBZpmJUshy1lZXIG10y4/tMN0esOQYWSSUl\nJM2YBWXM61opVXm2t66B1n4cquVJvsdkFSPUVHZ5RvzEWzqiM2v1s6QqduKJdNoVZ9cxnPa64q0p\ngIbqCH1MkgXBtcuOGhIABkNnkKqGsfTgW/Y2GhdGQIy7r7IGJeA0qA17uboCTPe1qMr48YgdyjGF\nU4e3OJD9NzPQ0ZcQOkG+c+M7y84h7+BL0RUxwS5Tb97uFDNu8+F0Ajev+bVQgU7TNTvBqMs4CLm+\nA3/b+x5XfY8hrWooP3kTyo7bbVs8nZl67HzBICtf4r7FW7BqaxuGki7rl+kYSjuDDNVleVvJqUlV\ncV1fI4vlrQqW95J1++1wmlVzwc1jr+7w9ZowMG9VtMygQSzWo2J79y5PTQbr39Z1sxLgciXU/Wrd\nvXbFNUB0m1vL+vIJa0MJ13XJeCSEWHCm+p9FSiiLy187PxPDgKp7vUpmboF/sltSTXqm4gFAQksJ\n4sonzpltGWEg4YN3dTgS75JiW9665pnPXV9ZB8nwc0o4D2xVeSbJR9Ixtc4UHyVmTn0yUo5QGgZQ\nIx3h/K2WQd7/D9whddNVLmXirQYDwGBkBNzQGZTDn8icy/AUlEmWd6G3YjfkyaYLulqa7BQ0sCod\nKRUol4M5WXhBgiEBqvlbupM9MAwxfs+T0hTR+pI0O5egSvaKNwB8qfGrUJpORU2sxvd7K+yQDXdC\noOoj3uUnZ48z9qu9+NmqX9p/P7X7WbybKQ1rpCvAGLB3aId3x7JMIp7GVaKDJExzSesqJMiwnxnd\nG4tWwCXBxfiBj7/b3A+DH8C4koIshGSiioxIZQRJh+4pY8vT0Rt3reXudEzDnOD1J7wFeEzLWyzS\nommGvVSjlcg4pCQEiwoAFEO165g7v0P0EvSrvZDrOhCbdtD+zM9tySQdCpfQ5VkFTtLFLGY75p3Z\nLnOtUmnFU4/er8Ka223+3q7DtgfCb7EXwLwP2cTCK946NE2s9jZcuxsPffA4/rLvVd/wg7iQjprz\nnrurSPIJa02d5n3i78NQQvEMejXNtUoiMwTvgNVXaLom3DN3/hFg5sNomjNYsRYjcrvNeYaVRJZi\nNWkhWa4/LdZD0AoQb/cMjELmlxdCScX7l7/8JebMmYPLLrsMW7aIafqzZ8/Gt7/9bXznO9/Bd77z\nHbS357+ww2iwEtYUl8scAKZUVaHCcKzl1N7PIrFptrBNTXlGoCUNx9Sbbhej2nTdCZa3Wi5W0lLL\nML3q76B2HQPA7Kihy5mpYppj2WZikoZSgWvO+RdUydUA0+0ELAuN8xoYmoxJsclC0pLMZECXUR4r\nQxCMNDfw0GXUlddxX2a3vHWodjxPgjmdzHpBK6Rq331Orf48AIba8iyWd5l/fNBKgGNl7iUAvR1S\nrqmd+9XNQiKaDg2bO7cCANT2/2VbXM4JzE7DFlpuoNOb6sPQ9Hdsb4CiKRnxthrtvW4qX35Xdk2L\ny+I2dyNWmTM8bnXAFCuWedUt8bZc1ma4JktHzsza/6K3x+louwY4wfaZWZHW02JMXlaw9ODr9gIg\n1kAx7uPd0KDgo/6DwmdpPe1M4zI09CpeK9YvIx8AhtQhyFMPANA9HT5jhuDet85hWZOWlyKpiqLM\nssS8uwbjgpV53LRKO4zSkciy9jgzfDt91dA899ScdSLeayNmXsMtXTsEIbWWjuUTCYdSqbymsgkD\nIsmxYC2GE4or5m0ORDyWt494u9vhnglg7avpjrfg1PpP2vtmW443rsZ93wUAQkigPzWAnd177Hcg\nm5cpF7nWQi8lJRPvdevW4eDBg1i0aBFuv/123H777Z5tFixYgIULF2LhwoWYOnVqqZriizWa5TtQ\niyNqKlENx1qeItfZc5Utzvu7meb+hz6JY44UxcdIOeJtKOV29SnAtDaObZhkuwzNtZtNsdMMzba4\n7c5ei6FMlhBjMVMQXfO8NcnpdIx0JSZVlgtL61WwKgAMla7pQNngxRsGw9G1jcLfWRPfZCcZqypW\nDcZlm1dnsbyHk+ZvOaKy1vd7FvN/MfVkjeABsJKvNPhv/5mjPu3f5hwYWgyGIl4zPfO3PQ9eFQdE\nRnWPXSlO0VUwTrz9PBaalGVqm6RB0b2rzPniKsHr12FphmJbB6w8I5R2oqQj3ukDp4k7Mh2AgYEk\nl4TJjMznOrqGHfH2WwXMzDZ3hDnW0II3W5ZjfZtZFMd6p/wEVzNUu5ysRVKPc1nTqq94t/V73fcA\nsC+1BeXH74J0RJfXWpN0JNQEGBhiTHbmrLumbqZUVZzvn2We95aPOoVkyCRX3yCb25y56j5YKLri\njU8zHYrm/3ykNDEjfjCR8szh3vpRp3d6bA7441mDRf6+DsRTrpi3OagRC8EYwu9I2+It3gt38rC1\nr8bVeKiJmf2pmtPyjmeNWTcNOOL9ZtMKPPDBo3giU/VQ8wk5jMTHTrzXrFmDr371qwCAE088Ef39\n/Rga8l+YYjxwxNs76q+rqUYNc8S7vtYrPqc1fgLzPvUzzJj2WXz6+KPEL7lpT4ZahsmVNcLfnz35\nKNvyYZJhCqKVbWxIOH/Gcc72SjliMQmyZFrn7oQ1ISMbQHVlTHCzlcEU48qAlrescb9Vl3Hc5GnO\n3wbLHo+XNHtUXiVXZQTIfNmqY/6W92AmO7u+2j/bPBtGulKcC5+5lhr8rYkjyxt9P899EsnOhrY/\nUsysedvy1ryhCKnGdMMpugLGC7aP5Z1NvBkDhrVe3LT6l77fC9uW8Z2dY41pA3XQeswBscqFhWxP\nBGd5K5oKQ5eEQae1rTy1CT1xThCZjqoZf0P5qevQM5Q7JyGtu9zmGavfclVabnPf0r4s5XGBJ41h\nu7NWdBV9mtcFHVf9Le+EZvY9rDzhDa8wHQktgeqyKsSkMh/LOyPeiiKIN6uMY9Ghx7G//6AQ802k\n00jy4q071ymb2zzbIkmKpng9I5kwgJUcy5N0iffTb+5Bb1Ic0MTT6ZxuczdCsaqMh4W/N/2JhMtF\nblatFLK1mYG0kAWv+brvfefHZ66NNeCoLjOfU0VXoWQZ4KZ1JauINnPrT7TFTY/v+xmPW74Ja49u\nexJ3bXhA+CzfZXMLpWTi3dXVhbo6x+VaX1+Pzk5x1HnLLbfg3/7t33D33XePWZDfwooLW4VMeCuq\nblIVjpSPdf6e7E32qiiT8YljJuPKf/o0aiocC80wzAxj27UbUzClkrPM1TKcctwRgjAYumxmaBoa\noEs44ejJttVpqOWC5R3XxRiNLjkdn9YzDTVVZYJ4y0ZFpr1eoXFbjgBQyZyBhgwZx9dNtTsIw2DC\nwERA0sAkDcyQUSGXmx2MrsAwGCaVO+Kt9TZC7Z6G5Laz0TNgdoRHVU32P6Z9fcQOykhVAdxceDv5\nivmPwg/sz3n4LCdl3utj/Z3F8gYAqdq8P6qu2vP/zcZ5XzVDym79fFT2DvrTg1m/txDc7VbMW5eQ\n3vUF6Bkxlv6Xd5ESOyQg6aY1q0u+bSw/ficODzurT1mdt1zbJ2a6+5DWxIQ1a6BhWdrW9fPU8Aeg\nSV5BTxrDwpSnQb3Hs01K95YJNvfNTNssT/rO805qSdTEqlEmxez5yPZ2lni78jrkKd3oVjrwh+1P\nC1n+CSUtJEOm4AwoPIsNWUj+lndaV7zV/HgPnCuXQtVV4Tg9gwmhsAlgZr/n4zbXuedUCNNkGEy4\nrmlmHQf3sqKKKp5zw55WTzv88lYsD4dluVthSEVTslreipZdvPtT/t4ZIFiRlo54F+avuQPbunbi\n/Y4tnqqHY2V5j9lUMbc4X3PNNZg5cyamTJmCuXPnYtmyZbjwwguz7l9XV41YzL/yWCFIBzLztDNz\nodnANKDeLIZw0vENaG5heD+TcHnUEdVA5gUsi5mJSdOPOcLOwpQTTgeaXH8BAAal+RSUf2Ib9OEp\nOOX4aViS6T+v+NrpOHraFDGeqkuArJhjWYOhsWESYPWXajkaG2pRcbAMkHTEq5oAALXsKAwaXdAz\nsa70R6dD6zoGjafW4IgpTicsZab5sAqvUBipKk/SV7U82fZFxOQYTvlEA4y91WBVwwCYbV17kFWg\nLA0JMVRXVILFM1OfNBlH1U8CMmMOI10B5aDpxu4dNtt04nFTwQ5IMLKsE870MoDrQIx0FWSUQ4eY\nfGVkEe/2w2XACf7NzsbkymokDZc4Z7wOtttci0HSy4RiMSyz/rkGDcxwJf+5sbLWM1MLeRKyV5hG\nhBmApINZz1bmnO5qeADMGvsGMy1v3RR8wyepDgB6FLMtdjXADMkRXK8V1ZLHZSu2QYKhyUjIXvE2\nZK9XIo0EVG7xmwS8i6+kDf/zWQWCWHkKGtwxZANJPY5jqxrQ35PEoNIJpTwJuSJTT9sKl8gQp4pl\nkGWGWIVzf1VDhcTdek0eeTlLwIDfUttlFRJYWnwvmKyisiZzr3QZcIWLYmXOgaZMLodWZp7fWrNB\nKmdgseDGksFNyfQLZSnQMGkyF2KSdEyZUoWqNJfQyQxUVoty8+SbO/Cra84SDyb79S8GqmvKgZR5\nHaZmjMLKGhnVZf4eRbmSQYr5ewmHfAaLAHDkUTXiMqYyE1ZNtPjDyqfQmejG8x/6L4uqw/Ddr9iU\nTLwbGxvR1eW4iDo6OtDQ4MwLvfTSS+1/z5o1C3v27Mkp3r0+67yOBmvupCqZNzI2dDTUjHgP9qUA\n3YDSdArkIw+jtmYSAPO3/GbuOUikVHR3Ox3ikJBwk4m/dk1HKlUFPV6LWs7qPfeMaejsHBQs73K5\nDIqUMN0thoR0ghMqtQyDAwkww6zKlq5sgx6fhNpJ9aZ4ZywUrWcaAAmGpmNo0NlfSZjn7s1M/bBW\n+AIyFmyN2AHKuvMSxiBD0jTo8VpIVcOQKhKYUjUJ/S6NlRADas3EL0mvBsuInC6lAV2GzhWWMThX\nc1NbxkpNqZCNSqjMuccxvQpqJp4vaeXQ+diuFoOMMntcbx3TYCoYzARDqXIYZcftBQB0dTJU5Sne\nJzQehUNKN3jb18pH4N3mpw5dhi36a5CPMJ8PqSIJxNJQNRVMczoPv5i3bTVrzuDE6mBHQlYnQYuJ\nosysKlZ20mMOx5phWtpM0pFIa6aXIMv2HRnXopGuBOOq6w0k4jl7kMc3mSU9jcx5vG0wvRtx2Tu4\nsEIKn6o7Gbv+//bOM7yu6sz3/11PLzpH0lG35CJLttzk3rGNDZgaJ5jegoFASJsY8CTckDsEAiGF\nDJkZZibxc3kIM0lu4Mkwk5B6Q8IkhAEMxtgYFwzutmTZKken7LLuh7XL2qfIMsZF8fp9kk7ba6+z\nz377++47DBLoRZakYRITJZrIOftWOmYKZ8iPoGRLumYJCFT4kM8TQAU+/8uvYEnDAvqk5d7vH8wi\nI5WIzxsE6UF3X9K5HI72uwIiZ7nNiSFCkMpYZQLxZMTb9KbT6M94j6k07MATr/+Te94F7xlkSuFU\nGdjTbX1/uSCEYD96+9PoF4Z/Py0348Gm+9gAjhx1vxRBMLFx6yH0+dgaf4KeXq/QTMRkHD7itYKz\nWg4o7OkkAEd7M0hbipmRpddpT+8AsnLp38rLm/YgGyi97mPZ0hP3Dh4u8FDkdXqvZjBMA+8coveV\nciNpTWIWve9kKKcInDK3+fz58/GrX9GJU5s3b0Z1dTXCYeo+7u/vx6233op8nm7uq6++inHjyveb\nPRXYoxNNH/0ifYYbd5VECXMmprCqfTnuaLsT7VZMu7UhhnBAQVXcGxtUJaudqqWhf+POuVhzSTvM\n/iRgqKiKBfCJcZfhhvbVzntYy7siHKA3bNEE0RX4VCbRSVOhyCIUqzwCogkzHYVieSFMOUs/y3Id\nCwI8s2+1LH3dxc0XAHk/8jumOc+ZueJYtE90QwSSpCDgk2H2ujF9n694/YrgKiKaOOjsByQNxJQQ\nUJk7PKO0HDhCbyDhgOLE5p3jCO7apIJfs5kJQRUYTd8W3qJlFRDRU8YFCIi8dym0A8OX4BMaalAZ\n9v5ozH6q8TvWhykhEfEXWdViqBcGdK/AHkKQsu53kildNseSEOoxuL2d+QDr+xAIbSlrH6tcsx9Y\nioiVKKmbGrXgSGnLO0MGaOiiIIEvZ5RJuCs8llYmWZKIgCGXHnZiWXt14RqIOxbC7EuCiFqRYmNa\nZZkkO/S+5S0vjeDLFg/8sVAEnyde/MZ7Bzzr1wyasCYU7ZM38zuva55sc120wgSZIawxgVr/hZSM\neQM4nLWqc0q0UmZbj/p9ouM2J1n6m8obJZLghoBIQwvvrJ73JkqKBp78j83YuZ8VhqQoDBGLSsVu\n81J5K1apWN7MQxREZ5CObupls83TuWyR+9oOvzmtnjWv1V4Y0ih1nfRrA061xBGmFt7zvpHuNu/s\n7MTEiRNx9dVXQxAEPPDAA3juuecQiUSwfPlyLFq0CFdddRV8Ph8mTJgwpNV9KphSOwG/3PGi08VL\nFUJY1b4a247uREgOQlAEXDi7yXn9/TfOQF1l6cQrVVJwWeIW/Pg31KVdGQugN+1e8KIoYEnjAs97\npo+txdvM++1rlmRD8LPCTlchSyJkpk6b5AM0hp0HFZBZJrudwFMqdsz6/YxNNsLcsgwmMzbT6KqH\nIOdB8n4o9XRqkU90BeVg2kp+YoS3nTRCNB8EywqRRRk55rdr15QLkgGSleH3McqILqMy5kd3L9Wi\noyGqnKgIgP3pKIK7DgU+5yed2zILZDAGn+Rzx5zYmdN2PK5E/Hb5tBZsye3H1uyuIvdvKSY11eCg\nFscuqyFWdvNckLwPaHY7pBFDRjzsA+nxHksds9F6fuiENQfGG2FmwhDD5WdxA0BXT97j4haI7OQj\nmDCdY01qqcJWfZu7BF1xwyREhEBEENGkbmRTwey2Wmwsc0yi+bwxfAA5MswEVF0FSvTDJ0TweGI8\nz8k5CABU0VKMM2EgVtydzDyaAmLdMHpqnGRBz+dY1i6xXOWCr0zMGYCe9/btPzLQDynhJipqho6s\nkYNEVOiC93OMgm5nrMC13eZmOgYxXDreKogGMmbxfu7t7oNZIuTlnl+xwvVBn9sL3TBNp4bezAUg\n2es7kVIxMT/k/O6i2LMV/jrYkwbsdB+BOLkEpqZA9FEvSdEs+VIxb6sZTp5oUEUVm3ZQoUmbtJRW\nDA3oxcNXdNXpiAhY9zCm3LSw6qFQCA9mNew/Wj5e7n3fRxfiLccpjXmvXbvW839bW5vz90033YSb\nbrrpVB5+SKbXTYKSroUWOgCiqfBJKubUzsCc2hklXz+6buikqtZUPWAcwPwOmp2dzQ3t+rx4zhi8\nbfXeVyVXAzSzIfiUAstbEqGIzGO5AFSZ/d9VKpIxP1LBkOf9AG1KQ2uHmRKrbBjarkkQQsdc4c2U\ndeU1+pNdc8E0/PFwD2aPa8bPd/3G/VyriQqbZFIrjXG6z9lr9RdY3ks666Eb1E04r6OWHlco8GYI\nftjhJ6fXPABzIAEACKkB9Fhb7GTuWz9MovmKYvl1lSH05PzYuhdUWEpG+eQ7ABXBMOqTccCSFyQd\nK+roRnQV8YhaJJhty9w0RIT8Mi2JKziWRFQYQnHiG8mUrnkH3JgzMSXccuEE/Puev1ibIgEmcSxv\nYqpIVQQwdUwAW99l3p9n9oWxvIlAqxymjK7Gxr3Fx6Xv9ReNgez174AA4bj9nEsl9lGEooz+ycpS\nvKX9P8fC/s//3gM9OxrSYGmr1RyMQNvdDkHNQGncVvwCQ/a00S01AMcmky5QsBS7va8rvHN6DiIJ\nA4yq2d2bRUJlQlWm5swoBwDTqggxy5wDQJUKAgKiKR6BsrurF1U1QwjaMnkK7lp09OV6IZqKk3Cp\nmfoJWd5lZzwwx/BkZjshEm/Cmtv0RgGQRd5ws97tsEepck/BqvPOkzxUScHvXjsA3wSaGFjOyjWh\nF1vems8zvZAUlP/+oWCkrN2kZf/AQfzjxvXof3ciBtIm/BOBgBwom3xoEjKksvNRcc52WAOA2LFp\nIIYEMxuEKp/cVrTURvG1NbNx80qqoLQ2xjF1bCX+ZvWUkq/3MTOUfUwZF7W8WUtVhSwLUBgBT/J+\niEzsTNs9HtcsG4c1l7RjxvgqVAaS6CAroR+pgdmfwBesNdilKNP1a5DZsBQzxls5CMwNQM8Vu3rn\nddRi3dLrsaRxgfsD1Nz15036g9APN2B+9GLPWs1cEAH2fAwZyagfl85rxqpFY1CToIpHXdQt5/JL\nfo/lzSo3NlE/I+wLrLdmJrfCpirud2tKiVjUmKcQWZQRkgtKBA0ZnlI5XUEkqDr7RHTZI4wMQ0BF\nxFI8CoQGGyZgXfzmUMLbrsEnIkbXupUc1PqiyWemVbGgyBKtUCj1flDlSwQtP4RggpgSgipTNZH3\nQcgxa9F8TldClgZzGo5XKFJ4k3QwBShwn9P2jkWLb4LHLW1blmYZl7NtFZfr/Fd2Ql8J+vu9JyKo\nWcCQEfLRfcubeejEgFhg7REAR/oZq03ylorB8gjZYZdS2N0ESWEoSzQ83dGKOI7w1g0DA/kBiIYb\n3tF0vWQv+tJdJVGyAQ+LZuqebHt7epxHqROIU9ZlK3N5I+96AAy7XW+5ed60zlsRFee73ty9DS+U\nmRJ2WNiOg2lv4y82fENMsei+8ZLdXdFatp1k/fx7L+Bo7hjyqTchWKG5pL/4u7Q9bSO+znskoCKM\n3Oa50HZOgaKc/FbUVYacG5wii/jsJyajY3TpPukB2b2Rsg1USDbotbx1BZIoOo0JAGrNTqluh5SP\nIvfOLJBMFOMaf/U03gAAIABJREFUY5jXUesk4sXMOmg7p0KFH5MK1lAXS+LvP70Mt19mNS9hbnw9\nfbpbalbC1Xvn5FtgpqOe+LH9IyW5AII+BSpreWcDCPhYy1tG0Fd8k7hm8gXIbZmFzGvL8Xezv+xp\nqRookVEaY70LjOuQmAJWL2hntH9KPOxz51SbImyznpSpWwfcXAYXATIzpEOGD43VjIAjIqoPL2fW\nIiIeVvHIHXNQk6DvMwdi8G9bST0LNjoTEmGEd5FL1FaYTMlzzZi6BBARoj8DU9BhmgJURXTaSDqf\nxwhvsy8JCYrb5MUUEfS5CpOZCaPi2EzPe0sJb1+uumS9u5dy0l1AiCkjhClCUSRvTNkSTp5cAOY7\nc86pnBA77tpceo6ZMNOukiD6siC6jIBixbythk6iWXg9FnS2kzVktRJJcXk/9O7akscWfFR4mwW1\n9vZoXWJIMI5VFr2vsEKgIzDX879m6khrgyC6G/bQTB3pXHG+gp5hru1MFbBnsnM+Q6GRvLe3ufPb\n8wpvR/G3hTfTgMY+D0Mo7zbXTCq87e/6UPZA2TWx44edT2GVSFMqGXKgb6avs70JvXb/c9FwFLGE\nr4QiZpescuF96mmoCoNkwzSG/BGWoQ2HqBrBypbl+PSUWxHxuTcwhQQhigIq/dYP1bqQpqdcC94v\nhDGnbjri+1bA7Kdu5NqEN2HnaD/9cSZK1KgrsohwQIEsFQvpo315BOUARIh44OZZRe8dnxiL3OZ5\njpAZXeHmBRCDJriNijJNZvIB+BlhTUwJAX/xDTXsC2Dtpctww/IJCPl9SIXcG1UkUDxStIIR3p6a\nb82HeMQHFMwtlyURtSHatMTsS6JdmYtxaieyry9D5tXlKEVRT2kAquXeJwTwSz5EgyqmtVrKEREQ\nUyvcWLcpwqdKqK4IQrbKVoghIxEMw8cMa2Etb7a1bm7LHKfRCn2OfpeqpMAvedvYsrFcYopQ2STH\ngvcD1MMjw+fG/k3RqyQRETGmuZCZC5Tsj//2uxnH+i0Hm2RW2Ds/5meUUiJBkURaveAc2C6JkmH0\npGD0pDC9stN9jy3syuQUlIupl2IwLSK/dRaMo67nhhiy0yPB7sYoFAlvb0MP0T+IY8QrWCTQNsXa\nrkl0TGyBFS46lndBoxzRgEY0mOko8rs6ihfNnJ9AZGzY7M1y1kDd8WZegc/yYJXrbc5a/WZeQcBq\nazxUqAGANYuc6bBmN3Jh3icIptO5zrG8mXa3TtJpOcvbpJ0AJchDV1EMgSdxsoTlXfg6E7Tz3t5+\n2tRFULNOtUVALPYE2dcaF96ngSsWuNajNsxBEB8lF7csx4TkeFzUcj709ychu2k+/Cq9sO/p/Cwy\nbyxxbkqtFWOc90WDVvMN68abjPo8GeoAcKQv6zxXiFIQIiD5AOZULEZuy2xcv6IVQTkARZIxqmaI\n7FhTxtpJ9+Jr59/rPmZZ1XbvYYB6Eli3eTnLGwDaRlVgyTTaHGd+nWv1BdXicwj7XEEUlBgrPO9H\nNKhi3aUXQzYDyO+c5HjIlzQuQG77VGgftGOM0ok2ZR4V/GWyrO1OTiyOR8CQEfTR78o2SIlJY9yO\n61wg8FteFMdoJQLiYZ/Hs0A8sVDGqsxEcOfUm7CobgGM3qRz05vQVImA7IfglIRJUPpcJcpxmxcK\nb80HZCLQ9o0BIEAFm+goehv5mCJiAWZfC/IsnMfzfkcpkEz3ewqlx0A/OAoAoHc1uB/LnisRUB1l\nuusZElRF9LhvWcsyv2Ma8jumYUwF/VxtT6uruBGhtPueuUGXet7TAEiX0ZCs8KyR6IozhEiL0EQw\nQ5eKPDYmMWjioCFBDPU5ZY42itWmGESE0dVIkx8ZnN4BhW5zicnQLqGgeCxvUyzK7M9bJWFGXkHI\nup6PKbs8jVect2eZZko69YIMB53oHuEthnsh17wH02NFu5a3razqyDmzBZzwSKleDQKBrtOmTyKk\nosRJsa/Wo3CVXyjrNpc8IZVPjLvMfc56HSEEf97/Ku1kZ+WbSFb7Y8UoEd6yhfcwB5qcLOe08I6F\nfbj/xhmoTQbR2TqML/9UrcMXQSDdApKJODf7kM/niSuLgojMG+ch++ZixEL04tp9mGanjm8qduFU\nV9AfamtjvOi5kN+1HG6+qA3TxlXiuqkr8f27P45Z7SksrJ+DRfXzjrvuiBJyx4/CutH5JNoByfqB\nkTxNWLu66SZoe1pBcsGywpulJhlG9s3FyG3rxIzKmSC6jPxOd5ZwVYBau8axSlSqTAtXzQe/KmFM\ndRVmmNfCOFLvuO1lUYZvsAEwZaiK5Fid9n4W0hIdhY+NvRh/O/PzzmNBewKaQByPglPDbAlmW8gK\nsuYk6zlNWBzh7d4oK4Pe78/YMwHa7vEAgCljK7F6/KXIvzvT+dxR1TEIggDZLqEzZFT2zXHKpkCo\n5V0ovAGC5MEV0PfRskzPqFZTgk+VEBeopS/4057OeCQfgFqiSx8gIBmk1xjbFjJltEHb3Y7Mqytg\n9iXcwwwwwpoIaEowIR0iQpFEal05m0GvLzaUtKBhJqoPXgz9wGjPOhwXOxuGYIV3oUsa8HptDIWG\nQViLzJCdkb82uay3TbDoy2JQPAICs2xyHhtuoWspUblCih93egqYUmmL0xMykoq8IBojvMMqPf9B\nlVqShW5j4hHeAnzy8LwWRmQ//uO9F+jfvfT7VJq2IRN0B8vINbtxIEeVH1txIalt+P2e/7bOb+gu\niRphlBhGYfFLfug7O8vnVTAQ1lVuSp69a4kxHkTb8iYmXtz7J4hEhr6HGiRCgN5zi8IbcD0KYonw\n0qngnBbeAM0if+i2OVg0pe6MrsMWMHaymlCilklFECQfwMLJNG4WDtCL5ZJ5zUWvvfGC8bj5ojZc\nPNd97is3z8DyGY2YNs51SS+aUofPfHyypzZ8adMiXDF2Zdm12klmIev4n5t2O/TDjTB7K53zaOi6\nDNm3FtAbsiyiIzXWudkGS7jNC/EpEkg+APNYNZLBOMjbF8A4Uodl0xvw/fuWoC0xDuK285DfNh3J\nMCtk/M7eZXL0B8/G3O+7dhoWTK7Fgsm1WDKtHoun1mHddZ2eY1f4qDASBAHnNy1GQ6QOD902G59Z\nNQlRZwIacTwKjnuQiEhE/W6tvKQ5HhHHlUYExCMqbA80MUWkKrwejqsnL4d+sAVzJqacdXz245Ox\ndAr1FNnZ/G4WPqEKmX0DE0woJWLeAJNABzpAxsEU4VNENKjWTUrNeXMxcuVDSzURS3gzllbIbzcE\ncCfREVOEmXaFNyECGipc4U1MCYosQmL6BtiW5fgmVwmVRAnVwRK5JKbriXBghXfWO2MAKMiX0BXU\nJIIei4wYiieRDwDyOREle/wLZtEAI4fCx0sIb9kMFQlop6GSVlzVQJ8QndAy0cUi4W17AIjm83g5\niKZCznkVe6J5QzHDFd6IugNkjO7y99GDeUt4D0aKvCBkqC6JAvHGxpk9SvjjyGnGEBUNDKyr3BQ9\nit1Tz7uKhu1BMqUMerJHkRQbnIRJMUALVEt1BtYPNmNl00Woj9QUP3kKOG3tUTlDU5sI4lDPIBqq\ny2cb371qEgazOma105v6fddOQ9+g5ghTlqBfKVJImmuiaK4ZuuRtODxwy0z0D+YdodhaMRba+zT5\nzX5sfF0K2993k0aiIffHpZxgfoEkCgj7ZeTyBgazmqNoZPsCoIKLSbRibtCD1tQyVlloSkXwyZVu\ng5ObLnTLFwFgZf2lmN88GYXUJkOoTYbw+uuuS9w+V8dlSAQosoiKYBiHzW4IMiO8neQdanmrhpUw\nlwkjHvWD7dg5tiGGxz+zwFN1MHVcJQb2xYEuV3irgg+DBICsISTKHou/sHpCP9QIo7seyXp3r4Jy\n0O2sSUTIkojWwGS8uWcXjCO18E+X3ecNuSgJiJgCREFw5rGzLV5p8puVgW33xs/7CqbWiYj6GMXF\npIoe2/THFsQ+RcJ5U+sQDtLnGqpCeHUrvBAJAG0MZIvWQsvbbkUb84XRZxz1WtmW8C60vAOqAs/w\nQVGHaPhASnRb81j9muq6w62GIOGAgoGMhqgcR2GhkaiFyiZQmv2JkgoDMUUIpgJiNUQqVBLsMjWi\nqairiOMtu02xpkKRJW+jWFYAmqLH21EKT98A+23ZEDIbliDQ+fvy7zOUom59RY2WWATizPk2De9Y\n4pgSL1572QNTgS0gZykB7vl9sDePgHW7VOGHBoD4aU13gCSKvDb9A8StYbcwByNY0rCgpOF1KuDC\n+yzhjssn4mh/znF3A8Bjd86DJLkXQkeL19qorwqjHqcfnyLBFys95tMWONNbq/Fff2a02Q/hSrr9\nsgl4c3s3KmMBXLV0HP7xZ29j8VT3jO3St6gSRtRIoudgAAYTXy1leZfjhvbVSGuDWNa0cMjXyRLj\nsrNc4k6mseWubq8cg8OH34eZjsFfQ19vJ48RQ0I4oGBV/YV4/YW90D5oR+OSOmzZNQE9+6ggS0T8\nJb0TTZEGBGQ/6sNUs/eJVOgLsoagKoMcs27cch6KLHlqebUPJuJra2bjta2ulRRWQo5wlowgBEFA\nQFWhvd/h7Ft13wTs76Z97Y/k6WAh/VAjYr4YjuyugE8R3VACu09Mo6BPLB6L3+VeQjoT9t4EiYCo\nygpvCYos0Sx/O2xoj+PUDNx5hZuw1ZgqzsdwstRLTJwDqCAneT8ga1AUhSpMtqvdFAEiUcubfY8u\n08FD7CRQ0YBqRjwDRwBA6RkLQ6aNAcx0FLktcxCc8VsQwYSep8epSwaxbW8vkv4EikrqcyGUq2E0\n+hOlnyMCZCMMTTpqnYP3d2bafdV1FU2VFe6MAV2B6pc9MxU9yX2mBJXpzyCYcpFgLTUbAUQEdB/M\nnN/T8Ma7KLGoZ4AjSIXi/hiCQBy3uamLAAQIuTCIbwAxqcpa+4la3lJBwpq7HlVSqfAO9EEAoORj\nIHmvItPbZxQJb5iSmwR8Gjjn3eZnCz6F3jhY93Uy5kc8PHQm79lCZcwagGKtvykVxqhUBAsmuaUx\nd13RgTsuG/5s7TkTavCpyzsgigJmtFXjB/ct8cTwr19BXbxzO+qwNHQtFTrMzetjC6mb/uOLR+N4\nzKmdgWVNi477urCftbzpD1qystKJQd2+l49faiXGTXByGG5svwpmbxW0va0IBxUkAxXIb5sOkgsi\nGQ2gweiEOUBj3+XCCk3RBjy28H9jnJW8aGesC7LmcZsLSh6KLKLSzgvoS0CWBNRVhpxQBwAmBAAo\nGt1XNimtMuZHZ/g8aLupp8LurmcORlCVmwSSDUGVRUTYz7GsZtb1vXJuMy6puh75XZO8liERnAlR\nAHWJqrIIH+uut1zYec17Ux/FCO+JLVZM3Wf1EM+xn8nc4nQF2u52aO9PdJRJR2DpCsIBhe5Pgas9\nyEwNNHqT0PaPRVgqyCXpr4RwcIKTWU90hYaMCF3LoDFIlaEK+n8iUJyLomuuC5yuzfLapCOe/BcP\nRIRCLM+HldyWe2cm9ENWDNcaXEQ0Fc3Vbu4BdNW5bt2TY647IsLPXAuCXnx842iq6DGn5wHjActt\nnWElSdqfLUDKe8cAO/MJSkwtA+BY3jkrBWBC/nJk31yERkLbPbP9AspheynsdRbG/PPvT4C2Zxx8\nttISsDSdXBQwZY9XpedYiSZcpgT5JPuFnAhceHM+Eh6+fQ6e/OJi539BEPDALTPxyYtdF/WMtmrM\nnlDiBz9MCt1RSzsbsH7dUqQqgsiXGOrQNqoC69ctxbiG4hvlh2V6DbX+9P1jHIv+E+Mupzd1Syj4\nFAXm0RpqSVr9A+rCNfjq4k/j5vOnYkxd8fzyWNgSvMfxuLF7MCFIuwHmP2hHyC87STuCZEASBVQF\nk+jIrUL+3elOkmKIUQwSITeE4tep4qAy/Q6q4gGkGE9QZxUtV2R73SuyhNGR0dC765B7dzr+dvpa\n3DfzswhYpWy2MprwVViCmzlBInrL8Sy3eUxlQjuWRZYqCA3Fw+7N+rMfn4x7r5/hJLpp+xlBYcgQ\nTBVmJgS9uwHmsWoYPbWuR4uItE2rrkCSBPhVb/2vmY55Khvy26YDuoqY6v0O9byC3oG82zzJkCFL\nAipAPUFmNoC6ZJCWMcJKGs0HYWZCyH9AQzf5I5We/dEPjYKZDSK/k+77/TeW6P5IBGcOgKBabVj7\nk25DGOvjglIYsSAT09YVZyoiABg91d6Qhmh6qg/YeHh+52RkN82HcdRtrFS0LKZfgTkY9b6WiKjs\nmwW9i/Eb2oqDNbXQTHvDe5o1lCQzSJXm5lQcJB/EwSM0LBANlPYEehclIqBYvfBNdx6Es4TDTUhk\nO9A5jlrzgqxBFRUYVv07uz/pNIF0rMnzflmUPMbXqYYLb85HgiyJUIdZWnIq0PTTU57REh+FzIal\n0PeNdUIEVcEkzQbPhaAXlBz2D7puxVQi6MlDuGFFK1RZxPT2lBNfPJHwQpW/Cpn/uRDmUTrHXe+q\nB9EV5HdMdvZjamMzQCQstI4bszw5ggBMHuWuxW6Ly1reiagfyZh7w7phwmpkNiwByQed7lOqIsKv\nKtDemwyztwqpaAWaIg1YNqMB4xvjuPdaahmx4Z+oLZwLY7hWwtrEuOudiQT8uG55K65e5h1cJAgC\nPnX5RKy5pB2KLGLhtHpcWHkVctumgQx6b/xjj61CbtMCj9Xv1KwTAaH+VuhdjegdyNPvocDyjoe9\ncXoAqI0VVHhYGcr+LPU0Gb2VCPpktIrzkd81Afq+saitDKHCUjqCfhm1XRcjt2khjEPNyLyxBFpv\nBRh5Cn1vK3JvLQTJhiGJAlpqmRI2zc1vCAiW5S3rTo6F5zrKhhAPekMbRFedShEzHUF+RydoKZv1\nAtGAnxHeRo5pCpQN0iErJRrjOLXObEIeEUAGo5As65iYIsJq2MmTAWiNOuDWlOd3ToF2oBlijp7z\noEBLygZ6VdQkgo7yZg83igVKz53wYIpOuVy5Ji13XDYRFWFXEagNpZDJmlBlEaOTTCIaEdFiLEB2\ns9sU53S6zAEuvDl/ZYQDw4h9nSyWBWkYxYXDtvD+m6umoK4y5CQXlmJJZwOeXHseElG/E79nhdzx\nYBP/YmEVX/z4HGQ3LIPRU4ec5WaeMzGFr94yE1cspJnq45viuO2SCfjuZxci5g9BMGUYR6sc5YFV\nwBRZdJIhWxtitE2t5T61lgtVoY1VCgn5Fdx3XacT5mAtkgfm3IPMhiUoiuESeszmuJu3EAv6sGx6\nQ8nkqVntKac3PgA0hBpgHivYb9Gw+iJ4j3XjhNUw+hLQdrdhYeVSGIdGYVZ7NURRKJpIFw95y7we\nvHUWRsW9ndLGRWlp39HtLdDfnQWjqwHJWAA+WYHR1QQQCXXJkLOfyagf01sZa9RyiytK4TVF1x30\nyx6vS27zXOjdddC76xGQXCu3ORWBIMBT3qYPxBANFrR01VRXwLNNWKy8AUE0PDMJjJzrNrcbCbEh\niaRYj+zb89CUoF4ZtuyMKmkCgvlaWsNvyoA1/thGLBjkQTQV+p42CDr9nIzYY51L2BLedD0HjtBQ\nSUVoGMIbQEi1O/IVVwx89ZaZaKmNeq7V2lANBnM6An4ZYyKtzKsFNFSFPfkVhf0zTjU8YY3zV8Gy\n6Q14/2C/I6ROJX5VQjZveKzqZNSHI305R3noaEnia2tKt8YtRdSqNW+sKl9tUEgk6LrC25oqIEui\nM7HNjhELgoAmJj4sCgLmdrgWREvPldj8Xg/0GmK93nuMkF/Bd+6e7+mSB9Be8dv2ALXJ4HHGklBY\nj4Rf9uHrn1zsWCoXpC7Hz7f8D0g+AEUWEQmqyGxYCggmYg3Hj2U6n8tk5398zGV4dufzMI9VIzLa\nFWRLOusxaXQSNaFKiO/NBckbaG2M46HbZtPxrgCgq8ht63Rcv/GQH41SO3bupJtTkwzCJE3Iv9cB\ncyCOaWOrsWJKG7a8vQGqLCPfm3D2iL2h11UG0TaqAvddOw1j6mM4NpDD//39Ts85JJU6VEnzsHGD\nV5jZvRFW1F2An7+yCyQfhPYerYqol5uwvX8j9APNiFQpmD0hhZzfgJ2Mbw7EEEkWKLWGgrDsAzSv\nOzhA4sjgCIiuoCIQB+ypl2yugqaiY3QCfZlBdFkP5TMKyGAUY9pi2H1owJOYGPIrMA0J0r4pGJ/q\nxAYzg0vnt8AwCeyU1sJ+8e5YW6uyRDpKh+BkqPBOWp0j7emEjdEabEoDelc95Kp99BSPVSKRb0dv\n9Uv2QWite5a6zTvH1GGLdbh4WHV+JwITyqkN1eDVrI5IUMHEilb87vAvnOdG18aADVx4czgnRSSo\n4vNXlh4C81Fz9bJx+D8vbPXE7//2+unY9N4RN3nqBLlwVhN03cTSzuHXD4xtiOGLV03F2PqYIwjD\nAQXdvdnjDguxifipFyGdoYqIHRNnY92xEkmT157fikTEjwtnN8GvSrhiQUvZPv4AoOneBbEx7Jk1\nU/Gz/6Tp3IpMS9ZsYdE4ROlkIazwXtI0Hz/89xwAAZGAKximjq10ev1/9ZaZ2PReD8Y3xT1W7co5\no/Cb10Qn9KDIEmaGl2PbYTq1TBJFiKIAo5t6CKJKBcY1xHDjBeMxqiaCB596DQAdDcze0JtSEQiC\n4DRVqowF8OCa2ejpy+I7P6HDWGsTQTTKU/Bmbpfn3Oz8irk18/AfB7waVtgXRO4vtKmSv0HGJ1e2\n41C6Cn/3l9/S2vreSkQKlSAiYFbFItQnYmhqmownt+0AAHRIF+DPB16GfrAZlYE4VASRL8iqb6gK\n429WTwUAPPL7ndhDNmHgCP0+7URCVnhLkoiqaAB7u9KoiUcBZFCbDGLt1dNw198fhkZ0hHw+t2xN\n87lWuSW88/JR+MwoBomEusowqisCiAYV9FkKdHN1EpmfrKDZ95bw1vaNxQ2Xzsf33nvJWUvEHwKy\nAEwJzclq9B9ZjO3bTbCDD+0GUABQE6hBJrcPqYoAIr4Qcu92OmtrqY14OtyV8kCdSrjw5nBOkEVT\n6jB3Yo3nxpyI+j1lbCeKIov42KLjZ8WziIJQpCzceUUHfvjrbVi9dOywPsPObLdr4qsrgrj/xhlI\nJYZOAAr4ZM96L1swtMeDDKFNsKGOwph/U+oEhDfjHRAEAfWVYezrTjtVAYC342B1RRDLphe7Wz9x\n3hhURHx45jfuiNFCt73EBKf9igRBEHDeNO/3XxnzI5t3EylLVY7UV4Y8LYxTiSDyltIgiYITTrG/\np1ICgl1bwJJCqVA1OtLX4tUt3QAEREJey5uYIqL+EOY2XwIAeBJUeFcGE9D30BBAwCdjtrwKv9/3\nB+hdDWipD2HKqDqsWOy2Lp6gzMf2DRGQTBgVEZ/bvZFpOSwJIlKJIN4/2I9te445axZFAXXxJN4/\n2A9JVh3hrR9jEveY/IN0TxgNVWFMHZeEIAgY1xDH69uo7Z+I+jAqFcMHB/ud8aLQfFBVCS3pC7E9\nvRlmbxLxgAocA02OlETUSGOwLbcfpuRen+MrxqJmYB72Zt5Hjb8ehrkXAb8MVRFh9lY7e1MR8Xni\n/qcz0xzgMW8O50Nxul1kw6UqHsAXVk8ZdomhfbMdzLklOqProp4WuiytjXEkSvTLPx6TxyQxeUyy\n5IjccscCgKbqIfrrF+Av6O//wC0z8fefW+j06F8wufa4jUds5ILcg8LZAawQVctMJAwHFGfGQEWk\n/J6xseVURRA5S+CriugoCbblXSongl0bq6jQUbr09REr5t2SOR9GTwrmsSqnjJElyrQK9vskhOQo\ntA8mArqKjuBcrBy32JOYpSoyTRAkIpprIs4MbBZREFFfSRPm0paSaP9+quJUSRzIaBAJvQ7YLnxT\nk1Odv42uesydmHIUvI7RVHGdNDqJ2mQId17RgaZUGB35jyH37nRn4FQMNVZynIj6GM0kN3MBSJK7\nv6bpCm9BEJDQx0DbNRnr/+tdADRsweaD1FeFqLfGcu+b2eBpT1jjljeHcw5jC5XhCrX7rp02rBh3\nIaoilQ1rsCVLhZTqHliOQIGAlSUR4QCdoPfw7XM8oYDjkde8QqjQc5CI+hALq+gdyEMquGnXV4aw\nrzuN2soQRtVEsK9rADdcMH5Yx42HVWzfawtvCTdd2IbXth7GYsuql0rsVZhRflhBziY0Rq38iITQ\niPwOuei1D902G6IooDYVxaYdXdB0E8moHzJzvHiJGQCsEttcG/UkcWbeWAJB0hANiFg+sxG7DvTh\nje3dANySR7uawTAJRmfPx9b0RhjddZjfUYMrFo5GRUTFq8//GUQwYPYnPMrFgsm1CPoVTBlD3dzV\n8QC+esssvLGtC69toj3IVVXynGd7Yiyyby4GydN8BDtaYhZc1PY1uXU39RSMqYt5uhY2OLkpAjKv\nL6V14NUf5pfx4eHCm8M5h1kwuRa7Dw9g8TB7+wtCUW+sj4R4WHVcxADwrU/PR04zhhTshQxl+ZyI\nEgAA2by3WUhhCaAgCPjamtn43et7i9oQ33vtNBw6mnGszXuv9fbOL8WnLp+IlzbuR2tjHP+9iY4T\n9SkSZrWnPBULAVVGNKRixvgqbHn/KA72DGJMfQwz26rx6tbDqI6758l6D2zLmxX0rOVdm6RrTcYC\n+PTHJjmPs8pCLFwsvFmB1lITcQQlbQNLe6oLQQE+RcI1549zhLdNJVOKGEMNtPfoNRAJqY5gF96b\njVze9JwHXZuImW3FteYRRsD7FAkTRlXgxTdoHFy1ZibY+2NnlhcqZ+x1d97UOiyf2eixzhuq6H5V\nxf3oovLd8ZicLrjw5nDOYWRJxI3DtApPJd+8a76nmmsoN3M5BEHArRe3O41QTobR9dR1u3gqFcw1\nCXqzbh/l1neH/Aoum18c648EVY+QGQ6skLat/lLeEFEU8J2750MQBOiGiZ6+LKIhFXde0YFrB3Ke\n5ELWKrYrE8bUuy7pwlBAKVghVioUwx5jVE0EkaCKL141Fc21EXzv2U14d88xp01xZSyAZdMbPAqB\nnTUOFPTztbP5AAALG0lEQVQCKBDSdr/caOj4paC2lwEAfIqIqcwgJlbBkyXRSZxsLhh/zJaL1ViK\njSgKkCURumE6itmDt87G93/+Dl7behhZjQtvDodzjnEiFvZQzJ9Ue/wXDYOJzQk8eOss5+Y+ui6K\n/3UTHR98qrl0fjPe+eAoriloTGNju5xlSXTarQLFVQE6k+Fvl8GNa3SFd2GOQCn6Bt2536WGJtmu\n+cqY31FY7CTKOy6fiJ+9tMuxUgHguuWtnvezljcr1COMAGbDEoX16qVgFSdVpolx667rRF/aO8Nc\nFAQs6ayHIKCoHwO7FtZr41Ms4W25zVVFcsIJhS18TzVceHM4HE4J6gtq7ltqT34i33BoqY3in5hW\nwx8W27Ke11Hj/M0Kv+EkWI2tjwP4AFctHVuy9aedrNdcYm/iYR9uvqit6HEWtoMfux42tl1OqJeD\nVUpspZCtMrDJaQZEQcDSzoai51hlsoZR2MIBBX5V9lRI2Hub5W5zDofD4ZwsF8xqRKoiUDRP4H/d\nNAN96fywRldOGp3At++eX7Z6oSYRhCwJmMa4pk8Evyrj0nnNqK0Meloce93mdsa9NKxxwsMdyZkf\noqUyGwOvZFz7d1w+sWgimh3eGG5vhY8KLrw5HA7nr5CQXykZRjgRD4IgCEOWHVbFA3jyi+edVNjD\n7hdwbMCdu8pa2A1VYXT3ZpHJDd+yvfmitrJu7LrKEPZ3pxEZopXyzLZqHB3I4WMLR3vOrbmmeO+G\nkztwKuDCm8PhcDgfmo8qX4FVEti49az2ary5o7vUW8pSWAHAsvbqqXhzRzc6x1eVfU3H6OSQHQNZ\nJlhJjHZy4+mCC28Oh8PhnBU8dNts9PTnPFnsU8dVIuCTsWjKR5OMGA/7cN5JdEMspL4qjMc/u2BI\nS/5UwIU3h8PhcM4KapMhp+bcxq/KeOLzC0/rrOwTZThZ8B81Z2ePRw6Hw+FwLM5mwX2m4MKbw+Fw\nOJwRBhfeHA6Hw+GMMLjw5nA4HA5nhMGFN4fD4XA4IwwuvDkcDofDGWFw4c3hcDgczgiDC28Oh8Ph\ncEYYXHhzOBwOhzPC4MKbw+FwOJwRBhfeHA6Hw+GMMLjw5nA4HA5nhCEQcrpHiHM4HA6HwzkZuOXN\n4XA4HM4IgwtvDofD4XBGGFx4czgcDoczwuDCm8PhcDicEQYX3hwOh8PhjDC48OZwOBwOZ4Qhn+kF\nnAkefvhhbNy4EYIg4Etf+hImT558ppd0VrNt2zbcdddduPnmm3H99dfjwIEDuPfee2EYBqqqqvDY\nY49BVVU8//zzeOqppyCKIlavXo0rr7zyTC/9rOEb3/gGXn/9dei6jjvuuAOTJk3ie3gCZDIZrFu3\nDkeOHEEul8Ndd92FtrY2vocfkmw2i0suuQR33XUX5s6dy/fxBHjllVfwuc99DuPGjQMAtLa2Ys2a\nNad/D8k5xiuvvEJuv/12QgghO3bsIKtXrz7DKzq7SafT5Prrryf3338/efrppwkhhKxbt4784he/\nIIQQ8q1vfYs888wzJJ1OkxUrVpC+vj6SyWTIxRdfTI4ePXoml37W8PLLL5M1a9YQQgjp6ekhixcv\n5nt4gvz85z8n//Iv/0IIIWTv3r1kxYoVfA9Pgm9/+9tk1apV5Nlnn+X7eIL85S9/IZ/5zGc8j52J\nPTzn3OYvv/wyzj//fADAmDFj0Nvbi4GBgTO8qrMXVVXxr//6r6iurnYee+WVV7Bs2TIAwJIlS/Dy\nyy9j48aNmDRpEiKRCPx+Pzo7O7Fhw4YzteyzipkzZ+K73/0uACAajSKTyfA9PEFWrlyJ2267DQBw\n4MABpFIpvocfkp07d2LHjh0477zzAPDf80fBmdjDc054d3d3o6Kiwvk/kUigq6vrDK7o7EaWZfj9\nfs9jmUwGqqoCAJLJJLq6utDd3Y1EIuG8hu+riyRJCAaDAICf/vSnWLRoEd/DD8nVV1+NtWvX4ktf\n+hLfww/Jo48+inXr1jn/8308cXbs2IFPfepTuOaaa/CnP/3pjOzhORnzZiG8O+xJUW7/+L4W89vf\n/hY//elPsX79eqxYscJ5nO/h8PnRj36Ed955B/fcc49nf/geDo+f/exnmDp1KhobG0s+z/fx+DQ3\nN+Puu+/GRRddhD179uDGG2+EYRjO86drD8854V1dXY3u7m7n/8OHD6OqquoMrmjkEQwGkc1m4ff7\ncejQIVRXV5fc16lTp57BVZ5dvPTSS3jyySfx/e9/H5FIhO/hCfL2228jmUyitrYW7e3tMAwDoVCI\n7+EJ8uKLL2LPnj148cUXcfDgQaiqyq/FEySVSmHlypUAgKamJlRWVmLTpk2nfQ/PObf5/Pnz8atf\n/QoAsHnzZlRXVyMcDp/hVY0s5s2b5+zhr3/9ayxcuBBTpkzBpk2b0NfXh3Q6jQ0bNmDGjBlneKVn\nB/39/fjGN76Bf/7nf0Y8HgfA9/BEee2117B+/XoANPQ1ODjI9/BD8Pjjj+PZZ5/FT37yE1x55ZW4\n6667+D6eIM8//zx+8IMfAAC6urpw5MgRrFq16rTv4Tk5Veyb3/wmXnvtNQiCgAceeABtbW1nekln\nLW+//TYeffRR7Nu3D7IsI5VK4Zvf/CbWrVuHXC6Huro6fP3rX4eiKPjlL3+JH/zgBxAEAddffz0u\nu+yyM738s4If//jHeOKJJ9DS0uI89sgjj+D+++/nezhMstksvvzlL+PAgQPIZrO4++670dHRgfvu\nu4/v4YfkiSeeQH19PRYsWMD38QQYGBjA2rVr0dfXB03TcPfdd6O9vf207+E5Kbw5HA6HwxnJnHNu\ncw6Hw+FwRjpceHM4HA6HM8LgwpvD4XA4nBEGF94cDofD4YwwuPDmcDgcDmeEwYU3h8M5aZ577jms\nXbv2TC+Dwzln4MKbw+FwOJwRxjnXHpXDOZd5+umn8cILL8AwDIwePRpr1qzBHXfcgUWLFmHr1q0A\ngO985ztIpVJ48cUX8Q//8A/w+/0IBAJ48MEHkUqlsHHjRjz88MNQFAWxWAyPPvooALd5xc6dO1FX\nV4fvfe97EAThTJ4uh/NXC7e8OZxzhLfeegu/+c1v8Mwzz+DHP/4xIpEI/vznP2PPnj1YtWoV/u3f\n/g2zZs3C+vXrkclkcP/99+OJJ57A008/jUWLFuHxxx8HANxzzz148MEH8cMf/hAzZ87EH/7wBwB0\n0tKDDz6I5557Dtu3b8fmzZvP5OlyOH/VcMubwzlHeOWVV7B7927ceOONAIDBwUEcOnQI8XgcHR0d\nAIDOzk489dRTeP/995FMJlFTUwMAmDVrFn70ox+hp6cHfX19aG1tBQDcfPPNAGjMe9KkSQgEAgDo\n8Ib+/v7TfIYczrkDF94czjmCqqpYunQpvvKVrziP7d27F6tWrXL+J4RAEIQidzf7eLmOypIkFb2H\nw+GcGrjbnMM5R+js7MQf//hHpNNpAMAzzzyDrq4u9Pb2YsuWLQCADRs2YPz48WhubsaRI0ewf/9+\nAMDLL7+MKVOmoKKiAvF4HG+99RYAYP369XjmmWfOzAlxOOcw3PLmcM4RJk2ahOuuuw433HADfD4f\nqqurMXv2bKRSKTz33HN45JFHQAjBt7/9bfj9fjz00EP4whe+4Mx8fuihhwAAjz32GB5++GHIsoxI\nJILHHnsMv/71r8/w2XE45xZ8qhiHcw6zd+9eXHvttfjjH/94ppfC4XBOAO4253A4HA5nhMEtbw6H\nw+FwRhjc8uZwOBwOZ4TBhTeHw+FwOCMMLrw5HA6HwxlhcOHN4XA4HM4IgwtvDofD4XBGGFx4czgc\nDoczwvj//31pifepEvcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc4a1196b38>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}